import httpx
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse, JSONResponse, HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles
import sys
import json
import copy
import logging
import time
from datetime import datetime, timedelta
from openai_adapter import detect_and_convert_request, convert_response_to_openai, get_codex_direct_config
import os
import threading
from contextlib import asynccontextmanager
import gzip
import io
from typing import Any, Dict, List, Optional
from enum import Enum
from config_manager import get_config_manager
import uuid

# å¯¼å…¥å®æ—¶ç»Ÿè®¡ç®¡ç†å™¨
try:
    from token_stats import get_stats_manager
    stats_mgr = get_stats_manager()
except ImportError:
    stats_mgr = None
    print("è­¦å‘Š: æ— æ³•å¯¼å…¥token_statsï¼Œå®æ—¶ç»Ÿè®¡åŠŸèƒ½å°†ä¸å¯ç”¨", file=sys.stderr)

# ç»Ÿä¸€é…ç½®ç®¡ç† - æ‰€æœ‰é…ç½®ä»config_manageråŠ è½½
config_mgr = get_config_manager()

# é…ç½®ç±»å‹æšä¸¾
class ConfigType(Enum):
    API = "api"
    CODEX = "codex"

def _init_status_dict(configs: list) -> dict:
    """é€šç”¨çš„çŠ¶æ€å­—å…¸åˆå§‹åŒ–å‡½æ•°"""
    return {i: {"status": "normal", "error_count": 0, "cooldown_until": None} for i in range(len(configs))}

def _get_primary_indices(configs: list) -> List[int]:
    """é€šç”¨çš„è·å–ä¸»é…ç½®ç´¢å¼•å‡½æ•°"""
    return [i for i, cfg in enumerate(configs) if cfg.get("type", "primary") == "primary"]

def _get_backup_indices(configs: list) -> List[int]:
    """é€šç”¨çš„è·å–å¤‡ç”¨é…ç½®ç´¢å¼•å‡½æ•°"""
    return [i for i, cfg in enumerate(configs) if cfg.get("type") == "backup"]

def _record_error_core(api_index: int, error_code: int, silent: bool, 
                       status_dict: dict, configs: list, threshold: int, 
                       config_type_name: str) -> Optional[str]:
    """é€šç”¨çš„é”™è¯¯è®°å½•æ ¸å¿ƒå‡½æ•°"""
    now = datetime.now()
    
    if api_index not in status_dict:
        status_dict[api_index] = {"status": "normal", "error_count": 0, "cooldown_until": None}
    
    status_dict[api_index]["error_count"] += 1
    
    msg = None
    if status_dict[api_index]["error_count"] >= threshold:
        cooldown_seconds = TimeoutConfig.get_api_cooldown_seconds()
        status_dict[api_index]["cooldown_until"] = now + timedelta(seconds=cooldown_seconds)
        status_dict[api_index]["status"] = "warning"
        cooldown_end_time = (now + timedelta(seconds=cooldown_seconds)).strftime('%H:%M:%S')
        msg = f"[{now.strftime('%H:%M:%S')}] {config_type_name} {configs[api_index]['name']} è¿ç»­{threshold}æ¬¡é”™è¯¯ï¼Œè®¾ç½®{cooldown_seconds//60}åˆ†é’Ÿå†·å´(è‡³{cooldown_end_time})"
    else:
        msg = f"[{now.strftime('%H:%M:%S')}] {config_type_name} {configs[api_index]['name']} é”™è¯¯è®¡æ•°: {status_dict[api_index]['error_count']}/{threshold}ï¼Œç»§ç»­ä½¿ç”¨å½“å‰{config_type_name}"
    
    if not silent and msg:
        print(msg)
    return msg

def _init_activation_status_core(configs: list) -> dict:
    """é€šç”¨çš„æ¿€æ´»çŠ¶æ€åˆå§‹åŒ–å‡½æ•°"""
    status = {}
    for i, config in enumerate(configs):
        if config.get('activation_enabled', False):
            status[i] = {
                "retry_count": 0,
                "last_attempt_date": None,
                "activated_today": False,
                "last_attempt_time": None
            }
    return status

# åŠ è½½å„ç±»é…ç½®
API_CONFIGS = config_mgr.get_enabled_api_configs()
CODEX_CONFIGS = config_mgr.get_enabled_codex_configs()
CODEX_DIRECT_CONFIG = config_mgr.get_codex_config()  # å‘åå…¼å®¹ï¼Œè¿”å›ç¬¬ä¸€ä¸ªå¯ç”¨çš„é…ç½®
OPENAI_TO_CLAUDE_CONFIGS = config_mgr.get_openai_to_claude_configs()
READ_TIMEOUT_RETRY_CONFIGS = config_mgr.get_enabled_retry_configs()
MODEL_CONVERSIONS = config_mgr.get_enabled_model_conversions()

# Codexé…ç½®
CODEX_PATH_PREFIX = "openai"
codex_timeout_extra_seconds = 0  # é¢å¤–è¶…æ—¶ç§’æ•°ï¼ˆæ¯æ¬¡å¤±è´¥+60ï¼‰
codex_success_count = 0  # è¿ç»­æˆåŠŸè®¡æ•°
codex_timeout_lock = threading.Lock()  # ä¿æŠ¤Codexè¶…æ—¶å…¨å±€å˜é‡çš„çº¿ç¨‹é”

# Codex KEYè½®åŠ¨çŠ¶æ€ç®¡ç†
# codex_current_config_index ä¼šåœ¨åˆå§‹åŒ–é˜¶æ®µè®¡ç®—
codex_is_using_backup = False  # æ˜¯å¦æ­£åœ¨ä½¿ç”¨å¤‡ç”¨Codex KEY
codex_backup_start_time = None  # å¼€å§‹ä½¿ç”¨å¤‡ç”¨Codex KEYçš„æ—¶é—´
codex_last_primary_check_time = None  # ä¸Šæ¬¡æ£€æµ‹ä¸»Codex KEYçš„æ—¶é—´
codex_key_switch_lock = threading.Lock()  # Codex KEYåˆ‡æ¢çš„çº¿ç¨‹é”

# Codex APIçŠ¶æ€ç®¡ç†
def init_codex_api_status():
    """åˆå§‹åŒ–æˆ–åŒæ­¥Codex APIçŠ¶æ€å­—å…¸"""
    return _init_status_dict(CODEX_CONFIGS)

codex_api_status = init_codex_api_status()

# è½®åŠ¨çŠ¶æ€ç®¡ç†
last_primary_switch_time = datetime.now()  # ä¸Šæ¬¡ä¸»è¦APIåˆ‡æ¢æ—¶é—´
is_using_backup = False  # æ˜¯å¦æ­£åœ¨ä½¿ç”¨å¤‡ç”¨API
backup_start_time = None  # å¼€å§‹ä½¿ç”¨å¤‡ç”¨APIçš„æ—¶é—´
last_primary_check_time = None  # ä¸Šæ¬¡æ£€æµ‹ä¸»APIçš„æ—¶é—´
key_switch_lock = threading.Lock()  # çº¿ç¨‹é”ï¼Œç¡®ä¿åˆ‡æ¢çš„å®‰å…¨æ€§

# APIçŠ¶æ€ç®¡ç†
def init_api_status():
    """åˆå§‹åŒ–æˆ–åŒæ­¥APIçŠ¶æ€å­—å…¸"""
    return _init_status_dict(API_CONFIGS)

api_status = init_api_status()
current_api_key = ""

current_config_index: int = -1
codex_current_config_index: int = -1

def get_primary_api_indices() -> List[int]:
    return _get_primary_indices(API_CONFIGS)

def get_backup_api_indices() -> List[int]:
    return _get_backup_indices(API_CONFIGS)

def get_first_available_primary_api_index() -> Optional[int]:
    for idx in get_primary_api_indices():
        if is_api_available(idx):
            return idx
    return None

def get_expected_primary_index(current_time: Optional[datetime] = None) -> int:
    """è¿”å›ä¼˜å…ˆçº§æœ€é«˜çš„ä¸»APIç´¢å¼•ï¼ˆæŒ‰é…ç½®é¡ºåºï¼‰"""
    first_available = get_first_available_primary_api_index()
    if first_available is not None:
        return first_available
    primary_indices = get_primary_api_indices()
    if primary_indices:
        return primary_indices[0]
    return 0

def find_primary_api_for_time(current_time: Optional[datetime] = None) -> Optional[int]:
    primary_indices = get_primary_api_indices()
    if not primary_indices:
        return None
    first_available = get_first_available_primary_api_index()
    if first_available is not None:
        return first_available
    return primary_indices[0]

def ensure_current_api_index(current_time: Optional[datetime] = None, reset_backup_state: bool = False) -> None:
    global current_config_index, is_using_backup, backup_start_time, last_primary_check_time, last_primary_switch_time
    if current_time is None:
        current_time = datetime.now()
    if not API_CONFIGS:
        current_config_index = -1
        is_using_backup = False
        backup_start_time = None
        last_primary_check_time = None
        return

    preferred = find_primary_api_for_time(current_time)
    if preferred is None:
        preferred = 0 if API_CONFIGS else -1

    if preferred is not None and preferred < len(API_CONFIGS):
        current_config_index = preferred
        if reset_backup_state or is_using_backup:
            is_using_backup = False
            backup_start_time = None
            last_primary_check_time = None
        last_primary_switch_time = current_time



def refresh_api_runtime_state(reset_backup_state: bool = False) -> None:
    global API_CONFIGS, api_status
    API_CONFIGS = config_mgr.get_enabled_api_configs()
    api_status = init_api_status()
    ensure_current_api_index(datetime.now(), reset_backup_state=reset_backup_state)


def refresh_codex_runtime_state(reset_backup_state: bool = False) -> None:
    global CODEX_CONFIGS, CODEX_DIRECT_CONFIG, codex_api_status
    global codex_current_config_index, codex_is_using_backup, codex_backup_start_time, codex_last_primary_check_time
    CODEX_CONFIGS = config_mgr.get_enabled_codex_configs()
    CODEX_DIRECT_CONFIG = config_mgr.get_codex_config()
    codex_api_status = init_codex_api_status()
    if CODEX_CONFIGS:
        preferred = get_first_available_primary_codex_index()
        if preferred is not None:
            codex_current_config_index = preferred
        else:
            codex_current_config_index = 0
    else:
        codex_current_config_index = -1
    if reset_backup_state:
        codex_is_using_backup = False
        codex_backup_start_time = None
        codex_last_primary_check_time = None


def refresh_openai_runtime_state() -> None:
    global OPENAI_TO_CLAUDE_CONFIGS
    OPENAI_TO_CLAUDE_CONFIGS = config_mgr.get_openai_to_claude_configs()


def refresh_model_conversion_state() -> None:
    global MODEL_CONVERSIONS
    MODEL_CONVERSIONS = config_mgr.get_enabled_model_conversions()


def refresh_retry_configs() -> None:
    global READ_TIMEOUT_RETRY_CONFIGS
    READ_TIMEOUT_RETRY_CONFIGS = config_mgr.get_enabled_retry_configs()


async def refresh_timeout_client() -> None:
    """åˆ·æ–°å…¨å±€HTTPå®¢æˆ·ç«¯çš„è¶…æ—¶é…ç½®ï¼ˆä½¿è¶…æ—¶è®¾ç½®ç«‹å³ç”Ÿæ•ˆï¼‰"""
    global timeout, non_streaming_timeout, limits, client
    
    # å…³é—­æ—§çš„clientå®ä¾‹
    try:
        await client.aclose()
    except Exception as e:
        print(f"å…³é—­æ—§clientæ—¶å‡ºé”™: {e}")
    
    # é‡æ–°è¯»å–è¶…æ—¶é…ç½®
    timeout = TimeoutConfig.get_streaming_timeout()
    non_streaming_timeout = TimeoutConfig.get_non_streaming_timeout()
    
    # é‡æ–°åˆ›å»ºè¿æ¥é™åˆ¶ï¼ˆä¿æŒåŸé…ç½®ï¼‰
    limits = httpx.Limits(max_keepalive_connections=0, max_connections=100)
    
    # åˆ›å»ºæ–°çš„clientå®ä¾‹
    client = httpx.AsyncClient(timeout=timeout, limits=limits)

def get_primary_openai_to_claude_config() -> Dict[str, Any]:
    """è·å–é¦–é€‰çš„OpenAIè½¬Claudeé…ç½®"""
    for cfg in OPENAI_TO_CLAUDE_CONFIGS:
        if cfg.get("enabled", True):
            return cfg
    return OPENAI_TO_CLAUDE_CONFIGS[0] if OPENAI_TO_CLAUDE_CONFIGS else {}

# ========== Codex KEYåˆ‡æ¢é€»è¾‘ ==========
def is_codex_api_available(api_index):
    """æ£€æŸ¥Codex APIæ˜¯å¦å¯ç”¨ï¼ˆåŒ…æ‹¬enabledçŠ¶æ€å’Œæ—¶é—´ä½¿èƒ½æ£€æŸ¥ï¼‰"""
    if api_index >= len(CODEX_CONFIGS):
        return False
    
    # è·å–Codex APIé…ç½®
    codex_config = CODEX_CONFIGS[api_index]
    
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨
    if not codex_config.get("enabled", True):
        return False
    
    # æ£€æŸ¥æ—¶é—´ä½¿èƒ½
    time_enabled = codex_config.get("time_enabled", [1, 1, 1, 1, 1, 1, 1])
    if time_enabled:
        now = datetime.now()
        weekday = now.weekday()  # 0=å‘¨ä¸€, 1=å‘¨äºŒ, ..., 6=å‘¨æ—¥
        if weekday < len(time_enabled) and not time_enabled[weekday]:
            # å½“å‰æ˜ŸæœŸå‡ ä¸åœ¨ä½¿èƒ½èŒƒå›´å†…
            return False
    
    # æ£€æŸ¥Codex APIçŠ¶æ€å’Œå†·å´æ—¶é—´
    if api_index not in codex_api_status:
        return True
    
    status = codex_api_status[api_index]
    now = datetime.now()
    
    # æ£€æŸ¥å†·å´æ—¶é—´
    if status["cooldown_until"] and now < status["cooldown_until"]:
        return False
    
    # å†·å´æ—¶é—´è¿‡äº†ï¼Œé‡ç½®çŠ¶æ€
    if status["cooldown_until"]:
        codex_api_status[api_index].update({"status": "normal", "error_count": 0, "cooldown_until": None})
        print(f"[{now.strftime('%H:%M:%S')}] Codex {CODEX_CONFIGS[api_index]['name']} å†·å´æœŸç»“æŸï¼Œæ¢å¤å¯ç”¨")

    return True  # æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼ŒCodex APIå¯ç”¨

def get_primary_codex_indices() -> List[int]:
    return _get_primary_indices(CODEX_CONFIGS)

def get_first_available_primary_codex_index() -> Optional[int]:
    for idx in get_primary_codex_indices():
        if is_codex_api_available(idx):
            return idx
    return None

def get_codex_backup_api_indices():
    """è·å–å¤‡ç”¨Codex APIçš„ç´¢å¼•åˆ—è¡¨"""
    backup_indices = _get_backup_indices(CODEX_CONFIGS)
    return backup_indices if backup_indices else [len(CODEX_CONFIGS) - 1] if len(CODEX_CONFIGS) > 1 else []

def get_current_codex_config():
    """è·å–å½“å‰åº”è¯¥ä½¿ç”¨çš„Codexé…ç½®"""
    global codex_current_config_index, codex_is_using_backup, codex_backup_start_time, codex_last_primary_check_time
    
    # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œè¿”å›ç©ºé…ç½®
    if not CODEX_CONFIGS:
        return {"base_url": "", "key": "", "name": "æœªé…ç½®"}
    
    # å¦‚æœåªæœ‰ä¸€ä¸ªé…ç½®ï¼Œç›´æ¥è¿”å›
    if len(CODEX_CONFIGS) == 1:
        return CODEX_CONFIGS[0]
    
    with codex_key_switch_lock:
        now = datetime.now()
        primary_indices = get_primary_codex_indices()
        backup_indices = get_codex_backup_api_indices()

        if codex_current_config_index is None or codex_current_config_index < 0 or codex_current_config_index >= len(CODEX_CONFIGS):
            initial_primary = get_first_available_primary_codex_index()
            if initial_primary is not None:
                codex_current_config_index = initial_primary
            elif primary_indices:
                codex_current_config_index = primary_indices[0]
            else:
                codex_current_config_index = 0

        def _log_codex(message: str) -> None:
            print(f"[{now.strftime('%H:%M:%S')}] {message}")

        available_primary_indices = [idx for idx in primary_indices if is_codex_api_available(idx)]

        if codex_is_using_backup:
            check_interval = TimeoutConfig.get_primary_api_check_interval()
            should_check = False
            if codex_last_primary_check_time is None:
                should_check = True
            elif (now - codex_last_primary_check_time).total_seconds() >= check_interval:
                should_check = True
            if should_check:
                codex_last_primary_check_time = now
                print(f"[{now.strftime('%H:%M:%S')}] å¤‡ç”¨Codex KEYä½¿ç”¨ä¸­ï¼Œå¼€å§‹{check_interval}ç§’å®šæ—¶æ£€æµ‹ä¸»Codex KEYçŠ¶æ€...")
                if available_primary_indices:
                    target_idx = available_primary_indices[0]
                    codex_is_using_backup = False
                    codex_backup_start_time = None
                    codex_last_primary_check_time = None
                    codex_current_config_index = target_idx
                    _log_codex(f"ä¼˜å…ˆçº§è°ƒåº¦ï¼šä¸»Codex KEYæ¢å¤ï¼Œåˆ‡å› {CODEX_CONFIGS[target_idx]['name']}")
                    return CODEX_CONFIGS[codex_current_config_index]
                else:
                    print(f"[{now.strftime('%H:%M:%S')}] ä¸»Codex KEYä»ä¸å¯ç”¨ï¼Œç»§ç»­ä½¿ç”¨å¤‡ç”¨Codex KEY")

            for backup_idx in backup_indices:
                if is_codex_api_available(backup_idx):
                    if codex_current_config_index != backup_idx:
                        codex_backup_start_time = now
                        codex_last_primary_check_time = None
                        _log_codex(f"ä¼˜å…ˆçº§è°ƒåº¦ï¼šç»§ç»­ä½¿ç”¨å¤‡ç”¨Codex KEY {CODEX_CONFIGS[backup_idx]['name']}")
                    codex_current_config_index = backup_idx
                    codex_is_using_backup = True
                    return CODEX_CONFIGS[codex_current_config_index]

            print(f"[{now.strftime('%H:%M:%S')}] è­¦å‘Šï¼šæ‰€æœ‰å¤‡ç”¨Codex KEYéƒ½ä¸å¯ç”¨ï¼Œç»§ç»­ä½¿ç”¨å½“å‰Codex KEY")
            return CODEX_CONFIGS[codex_current_config_index]

        if available_primary_indices:
            selected_index = available_primary_indices[0]
            if codex_current_config_index != selected_index:
                _log_codex(f"ä¼˜å…ˆçº§è°ƒåº¦ï¼šåˆ‡æ¢åˆ°ä¸»Codex KEY {CODEX_CONFIGS[selected_index]['name']}")
            codex_current_config_index = selected_index

            codex_is_using_backup = False
            codex_backup_start_time = None
            codex_last_primary_check_time = None
            return CODEX_CONFIGS[codex_current_config_index]

        for backup_idx in backup_indices:
            if is_codex_api_available(backup_idx):
                if codex_current_config_index != backup_idx or not codex_is_using_backup:
                    _log_codex(f"ä¼˜å…ˆçº§è°ƒåº¦ï¼šæ— å¯ç”¨ä¸»Codex KEYï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨Codex KEY {CODEX_CONFIGS[backup_idx]['name']}")
                codex_is_using_backup = True
                codex_backup_start_time = now
                codex_last_primary_check_time = None
                codex_current_config_index = backup_idx
                return CODEX_CONFIGS[codex_current_config_index]

        print(f"[{now.strftime('%H:%M:%S')}] è­¦å‘Šï¼šæ‰€æœ‰Codex KEYéƒ½ä¸å¯ç”¨ï¼Œç»§ç»­ä½¿ç”¨å½“å‰Codex KEY")
        return CODEX_CONFIGS[codex_current_config_index]

def get_current_config():
    """è·å–å½“å‰åº”è¯¥ä½¿ç”¨çš„APIé…ç½®"""
    global current_config_index, last_primary_switch_time, is_using_backup, backup_start_time, last_primary_check_time

    with key_switch_lock:
        now = datetime.now()

        if not API_CONFIGS:
            return {"base_url": "", "key": "", "name": "æœªé…ç½®"}

        if current_config_index is None or current_config_index < 0 or current_config_index >= len(API_CONFIGS):
            ensure_current_api_index(now, reset_backup_state=True)
            if current_config_index is None or current_config_index < 0 or current_config_index >= len(API_CONFIGS):
                current_config_index = 0

        primary_indices = get_primary_api_indices()
        backup_indices = get_backup_api_indices()

        def _log_switch(message: str) -> None:
            print(f"[{now.strftime('%H:%M:%S')}] {message}")

        available_primary_indices = [idx for idx in primary_indices if is_api_available(idx)]

        if is_using_backup:
            check_interval = TimeoutConfig.get_primary_api_check_interval()
            should_check = False
            if last_primary_check_time is None:
                should_check = True
            elif (now - last_primary_check_time).total_seconds() >= check_interval:
                should_check = True
            if should_check:
                last_primary_check_time = now
                print(f"[{now.strftime('%H:%M:%S')}] å¤‡ç”¨APIä½¿ç”¨ä¸­ï¼Œå¼€å§‹{check_interval}ç§’å®šæ—¶æ£€æµ‹ä¸»APIçŠ¶æ€...")
                if available_primary_indices:
                    target_idx = available_primary_indices[0]
                    is_using_backup = False
                    backup_start_time = None
                    last_primary_check_time = None
                    last_primary_switch_time = now
                    current_config_index = target_idx
                    _log_switch(f"ä¼˜å…ˆçº§è°ƒåº¦ï¼šä¸»APIæ¢å¤ï¼Œåˆ‡å› {API_CONFIGS[target_idx]['name']}")
                    return API_CONFIGS[current_config_index]
                else:
                    print(f"[{now.strftime('%H:%M:%S')}] ä¸»APIä»ä¸å¯ç”¨ï¼Œç»§ç»­ä½¿ç”¨å¤‡ç”¨API")

            for backup_idx in backup_indices:
                if is_api_available(backup_idx):
                    if current_config_index != backup_idx:
                        backup_start_time = now
                        last_primary_check_time = None
                        _log_switch(f"ä¼˜å…ˆçº§è°ƒåº¦ï¼šç»§ç»­ä½¿ç”¨å¤‡ç”¨API {API_CONFIGS[backup_idx]['name']}")
                    current_config_index = backup_idx
                    is_using_backup = True
                    return API_CONFIGS[current_config_index]

            # æ²¡æœ‰å¯ç”¨çš„å¤‡ç”¨APIï¼Œä¿æŒå½“å‰ç´¢å¼•
            return API_CONFIGS[current_config_index]

        if available_primary_indices:
            selected_index = available_primary_indices[0]
            if current_config_index != selected_index:
                _log_switch(f"ä¼˜å…ˆçº§è°ƒåº¦ï¼šåˆ‡æ¢åˆ°ä¸»API {API_CONFIGS[selected_index]['name']}")
                last_primary_switch_time = now

            is_using_backup = False
            backup_start_time = None
            last_primary_check_time = None
            current_config_index = selected_index
            return API_CONFIGS[current_config_index]

        # ä¸»APIå‡ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨API
        for backup_idx in backup_indices:
            if is_api_available(backup_idx):
                if current_config_index != backup_idx or not is_using_backup:
                    _log_switch(f"ä¼˜å…ˆçº§è°ƒåº¦ï¼šæ— å¯ç”¨ä¸»APIï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨API {API_CONFIGS[backup_idx]['name']}")
                    last_primary_switch_time = now
                is_using_backup = True
                backup_start_time = now
                last_primary_check_time = None
                current_config_index = backup_idx
                return API_CONFIGS[current_config_index]

        # æ²¡æœ‰ä»»ä½•å¯ç”¨APIï¼Œè¿”å›å½“å‰é…ç½®
        return API_CONFIGS[current_config_index]
def get_current_api_key():
    """è·å–å½“å‰åº”è¯¥ä½¿ç”¨çš„API keyï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
    config = get_current_config()
    global current_api_key
    current_api_key = config["key"]
    return current_api_key

def get_current_api_info():
    """è·å–å½“å‰APIçš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä½¿ç”¨å“ªç»„KEYå’Œè¿˜æœ‰å¤šä¹…æ¢å¦ä¸€ä¸ªKEY"""
    config = get_current_config()
    now = datetime.now()
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºå¤‡ç”¨API
    backup_indices = get_backup_api_indices()
    current_index = API_CONFIGS.index(config)
    
    if current_index in backup_indices or is_using_backup:
        base_info = f"ä½¿ç”¨: {config['name']} (å¤‡ç”¨API)"
    else:
        primary_indices = get_primary_api_indices()
        priority_rank = primary_indices.index(current_index) + 1 if current_index in primary_indices else current_index + 1
        base_info = f"ä½¿ç”¨: {config['name']} (ä¸»APIï¼Œä¼˜å…ˆçº§#{priority_rank})"
    
    # æ·»åŠ APIå†·å´çŠ¶æ€ä¿¡æ¯
    cooldown_info = []
    for i, api_config in enumerate(API_CONFIGS):
        if i in api_status and api_status[i]["cooldown_until"]:
            cooldown_until = api_status[i]["cooldown_until"]
            if now < cooldown_until:
                remaining_seconds = int((cooldown_until - now).total_seconds())
                remaining_minutes = remaining_seconds // 60
                remaining_seconds = remaining_seconds % 60
                if remaining_minutes > 0:
                    cooldown_info.append(f"{api_config['name']}å†·å´ä¸­({remaining_minutes}åˆ†{remaining_seconds}ç§’)")
                else:
                    cooldown_info.append(f"{api_config['name']}å†·å´ä¸­({remaining_seconds}ç§’)")
    
    if cooldown_info:
        return f"{base_info} | {' '.join(cooldown_info)}"
    else:
        return base_info

def get_current_codex_info():
    """è·å–å½“å‰Codex APIçš„è¯¦ç»†ä¿¡æ¯"""
    config = get_current_codex_config()
    now = datetime.now()

    # æ£€æŸ¥æ˜¯å¦ä¸ºå¤‡ç”¨API
    backup_indices = get_codex_backup_api_indices()
    current_index = codex_current_config_index

    if current_index in backup_indices or codex_is_using_backup:
        base_info = f"ä½¿ç”¨: {config['name']} (å¤‡ç”¨Codex)"
    else:
        # ä¸»Codexï¼Œæ˜¾ç¤ºä¼˜å…ˆçº§æ’å
        primary_indices = get_primary_codex_indices()
        priority_rank = primary_indices.index(current_index) + 1 if current_index in primary_indices else current_index + 1
        base_info = f"ä½¿ç”¨: {config['name']} (ä¸»Codexï¼Œä¼˜å…ˆçº§#{priority_rank})"

    # æ·»åŠ Codex APIå†·å´çŠ¶æ€ä¿¡æ¯
    cooldown_info = []
    for i, codex_config in enumerate(CODEX_CONFIGS):
        if i in codex_api_status and codex_api_status[i]["cooldown_until"]:
            cooldown_until = codex_api_status[i]["cooldown_until"]
            if now < cooldown_until:
                remaining_seconds = int((cooldown_until - now).total_seconds())
                remaining_minutes = remaining_seconds // 60
                remaining_seconds = remaining_seconds % 60
                if remaining_minutes > 0:
                    cooldown_info.append(f"{codex_config['name']}å†·å´ä¸­({remaining_minutes}åˆ†{remaining_seconds}ç§’)")
                else:
                    cooldown_info.append(f"{codex_config['name']}å†·å´ä¸­({remaining_seconds}ç§’)")

    if cooldown_info:
        return f"{base_info} | {' '.join(cooldown_info)}"
    else:
        return base_info

def get_openai_to_claude_info():
    """è·å–OpenAIè½¬Claudeä¸“ç”¨é…ç½®çš„è¯¦ç»†ä¿¡æ¯"""
    # è·å–é¦–é€‰çš„OpenAIè½¬Claudeé…ç½®
    enabled_configs = [cfg for cfg in OPENAI_TO_CLAUDE_CONFIGS if cfg.get("enabled", True)]

    if not enabled_configs:
        return "ä½¿ç”¨: OpenAIè½¬Claude (æœªé…ç½®)"

    # è·å–ç¬¬ä¸€ä¸ªå¯ç”¨çš„é…ç½®
    config = enabled_configs[0]
    config_name = config.get("name", "OpenAIè½¬Claude")

    # è®¡ç®—ä¼˜å…ˆçº§æ’å
    priority_rank = enabled_configs.index(config) + 1 if config in enabled_configs else 1

    base_info = f"ä½¿ç”¨: {config_name} (#2 OpenAIè½¬Claudeä¸“ç”¨ï¼Œä¼˜å…ˆçº§#{priority_rank})"

    # æ˜¾ç¤ºURLä¿¡æ¯
    base_url = config.get("base_url", "")
    if base_url:
        base_info += f" âœ“ å·²å¯ç”¨\nğŸ”— {base_url}"
        key_preview = config.get("key", "")[:20] if config.get("key") else ""
        if key_preview:
            base_info += f"\nğŸ”‘ {key_preview}..."

    return base_info

USER_KEY_MAPPING = {
    "123": get_current_api_key,  # ç”¨æˆ·ä½¿ç”¨ç®€å•keyï¼Œæ˜ å°„åˆ°åŠ¨æ€è·å–çš„API key
    # å¯ä»¥æ·»åŠ æ›´å¤šç”¨æˆ·keyæ˜ å°„
}

# è°ƒè¯•å¼€å…³ - å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½® PROXY_DEBUG=1 æ¥å¯ç”¨è¯¦ç»†è°ƒè¯•
DEBUG = os.getenv("PROXY_DEBUG", "0") == "1"

# å®Œæ•´æ—¥å¿—è®°å½•å¼€å…³ - å¼ºåˆ¶å¯ç”¨APIè¾“å…¥è¾“å‡ºæ—¥å¿—
ENABLE_FULL_LOG = True  # å¼ºåˆ¶å¯ç”¨ï¼Œè®°å½•æ‰€æœ‰APIè¾“å…¥è¾“å‡º
MAX_LOG_SIZE = 3 * 1024 * 1024  # 3MB

# thinkingåŠŸèƒ½å¼€å…³å·²ç§»é™¤ - ç°åœ¨é€šè¿‡å‚æ•°è¿‡æ»¤å®ç°ç¨³å®šæ€§

def trim_log_file(log_filepath):
    """
    ä¿®å‰ªæ—¥å¿—æ–‡ä»¶ï¼Œä¿ç•™æœ€è¿‘3MBçš„å†…å®¹
    """
    try:
        if not os.path.exists(log_filepath):
            return
        
        file_size = os.path.getsize(log_filepath)
        if file_size <= MAX_LOG_SIZE:
            return
        
        # print(f"[æ—¥å¿—ç®¡ç†] æ—¥å¿—æ–‡ä»¶è¶…è¿‡{MAX_LOG_SIZE/1024/1024:.1f}MBï¼Œæ­£åœ¨ä¿®å‰ª...")
        
        # è¯»å–æœ€å3MBçš„å†…å®¹
        with open(log_filepath, 'rb') as f:
            f.seek(-MAX_LOG_SIZE, 2)  # ä»æ–‡ä»¶æœ«å°¾å‘å‰ç§»åŠ¨3MB
            content = f.read()
        
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæ¢è¡Œç¬¦ï¼Œç¡®ä¿ä»å®Œæ•´çš„ä¸€è¡Œå¼€å§‹
        first_newline = content.find(b'\n')
        if first_newline != -1:
            content = content[first_newline + 1:]
        
        # å†™å…¥ä¿®å‰ªåçš„å†…å®¹
        with open(log_filepath, 'wb') as f:
            f.write(content)
        
        # print(f"[æ—¥å¿—ç®¡ç†] æ—¥å¿—æ–‡ä»¶ä¿®å‰ªå®Œæˆï¼Œå‰©ä½™{len(content)/1024/1024:.1f}MB")
    except Exception as e:
        print(f"[æ—¥å¿—ç®¡ç†] ä¿®å‰ªæ—¥å¿—æ–‡ä»¶å‡ºé”™: {e}", file=sys.stderr)

def record_api_error(api_index, error_code, silent=False):
    """è®°å½•APIé”™è¯¯"""
    threshold = TimeoutConfig.get_api_error_threshold()
    return _record_error_core(api_index, error_code, silent, api_status, API_CONFIGS, threshold, "API")

def record_codex_error(api_index, error_code, silent=False):
    """è®°å½•Codex APIé”™è¯¯"""
    threshold = TimeoutConfig.get_codex_error_threshold()
    return _record_error_core(api_index, error_code, silent, codex_api_status, CODEX_CONFIGS, threshold, "Codex")

def get_error_strategy(error_code, error_type="http_status_code"):
    """
    è·å–é”™è¯¯çš„å¤„ç†ç­–ç•¥ï¼ˆå®Œå…¨ç”±Webé…ç½®æ§åˆ¶ï¼‰
    
    Args:
        error_code: é”™è¯¯ç ï¼ˆHTTPçŠ¶æ€ç çš„æ•°å­—æˆ–ç½‘ç»œé”™è¯¯ç±»å‹çš„å­—ç¬¦ä¸²ï¼‰
        error_type: é”™è¯¯ç±»å‹ ("http_status_code" æˆ– "network_error")
        
    Returns:
        strategy: "strategy_retry", "switch_api", "normal_retry", æˆ– Noneï¼ˆä¸å¤„ç†ï¼‰
    """
    strategies = config_mgr.get_error_handling_strategies()
    
    if error_type == "http_status_code":
        http_codes = strategies.get("http_status_codes", {})
        # å…ˆæŸ¥æ‰¾ç‰¹å®šé”™è¯¯ç ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™ä½¿ç”¨defaulté»˜è®¤ç­–ç•¥
        strategy = http_codes.get(str(error_code))
        if strategy is None:
            strategy = http_codes.get("default")
        return strategy
    elif error_type == "network_error":
        network_errors = strategies.get("network_errors", {})
        # å…ˆæŸ¥æ‰¾ç‰¹å®šé”™è¯¯ç±»å‹ï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™ä½¿ç”¨defaulté»˜è®¤ç­–ç•¥
        strategy = network_errors.get(error_code)
        if strategy is None:
            strategy = network_errors.get("default")
        return strategy

    return None

def is_api_available(api_index):
    """æ£€æŸ¥APIæ˜¯å¦å¯ç”¨ï¼ˆåŒ…æ‹¬enabledçŠ¶æ€å’Œæ—¶é—´ä½¿èƒ½æ£€æŸ¥ï¼‰"""

    if api_index >= len(API_CONFIGS):
        return False
    
    # è·å–APIé…ç½®
    api_config = API_CONFIGS[api_index]
    
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨
    if not api_config.get("enabled", True):
        return False
    
    # æ£€æŸ¥æ—¶é—´ä½¿èƒ½
    time_enabled = api_config.get("time_enabled", [1, 1, 1, 1, 1, 1, 1])
    if time_enabled:
        now = datetime.now()
        weekday = now.weekday()  # 0=å‘¨ä¸€, 1=å‘¨äºŒ, ..., 6=å‘¨æ—¥
        if weekday < len(time_enabled) and not time_enabled[weekday]:
            # å½“å‰æ˜ŸæœŸå‡ ä¸åœ¨ä½¿èƒ½èŒƒå›´å†…
            return False
    
    # æ£€æŸ¥APIçŠ¶æ€å’Œå†·å´æ—¶é—´
    if api_index not in api_status:
        return True
    
    status = api_status[api_index]
    now = datetime.now()
    
    # æ£€æŸ¥å†·å´æ—¶é—´
    if status["cooldown_until"] and now < status["cooldown_until"]:
        remaining_seconds = int((status["cooldown_until"] - now).total_seconds())
        remaining_minutes = remaining_seconds // 60
        remaining_seconds = remaining_seconds % 60
        # ä¸åœ¨è¿™é‡Œæ‰“å°ï¼Œé¿å…æ—¥å¿—è¿‡å¤šï¼Œå†·å´ä¿¡æ¯ä¼šåœ¨get_current_api_infoä¸­æ˜¾ç¤º
        return False
    
    # å†·å´æ—¶é—´è¿‡äº†ï¼Œé‡ç½®çŠ¶æ€
    if status["cooldown_until"]:
        api_status[api_index].update({"status": "normal", "error_count": 0, "cooldown_until": None})
        print(f"[{now.strftime('%H:%M:%S')}] API {API_CONFIGS[api_index]['name']} å†·å´æœŸç»“æŸï¼Œæ¢å¤å¯ç”¨")

    return True  # æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼ŒAPIå¯ç”¨

_initial_now = datetime.now()
ensure_current_api_index(_initial_now, reset_backup_state=True)

if CODEX_CONFIGS:
    initial_codex = get_first_available_primary_codex_index()
    if initial_codex is not None:
        codex_current_config_index = initial_codex
    else:
        codex_current_config_index = 0
else:
    codex_current_config_index = -1

if current_config_index >= 0 and API_CONFIGS:
    primary_indices = get_primary_api_indices()
    if current_config_index in primary_indices:
        priority_rank = primary_indices.index(current_config_index) + 1
        print(f"[å¯åŠ¨] å½“å‰ä¸»API: {API_CONFIGS[current_config_index]['name']} (ä¼˜å…ˆçº§#{priority_rank})")
    else:
        print(f"[å¯åŠ¨] å½“å‰ä½¿ç”¨å¤‡ç”¨API: {API_CONFIGS[current_config_index]['name']}")
elif not API_CONFIGS:
    print("[å¯åŠ¨] æœªæ£€æµ‹åˆ°å¯ç”¨çš„ä¸»APIé…ç½®ï¼Œè¯·åœ¨åå°è¡¥å……æˆ–å¯ç”¨é…ç½®")
else:
    print("[å¯åŠ¨] å°šæœªç¡®å®šä¸»APIç´¢å¼•ï¼Œå°†åœ¨é¦–æ¬¡è¯·æ±‚æ—¶è‡ªåŠ¨è®¡ç®—")

def smart_switch_api(current_api_index, error_code):
    """æ™ºèƒ½åˆ‡æ¢API - ä¸‰å±‚ç­–ç•¥ï¼ˆä¸è®°å½•é”™è¯¯ï¼Œç”±è°ƒç”¨æ–¹è´Ÿè´£ï¼‰"""
    global current_config_index, is_using_backup, backup_start_time, last_primary_check_time
    
    with key_switch_lock:
        now = datetime.now()
        
        # ä¸å†åœ¨è¿™é‡Œè®°å½•é”™è¯¯ï¼Œç”±è°ƒç”¨æ–¹è´Ÿè´£ï¼ˆé¿å…é‡å¤è®°å½•ï¼‰
        # record_api_error(current_api_index, error_code)
        
        threshold = TimeoutConfig.get_api_error_threshold()

        # æ£€æŸ¥é”™è¯¯è®¡æ•°æ˜¯å¦è¾¾åˆ°åˆ‡æ¢é˜ˆå€¼
        if api_status[current_api_index]["error_count"] < threshold:
            # é”™è¯¯æ¬¡æ•°ä¸è¶³ï¼Œä¸åˆ‡æ¢APIï¼Œè®©é‡è¯•é€»è¾‘ç»§ç»­ä½¿ç”¨å½“å‰API
            return False, current_api_index

        print(f"[{now.strftime('%H:%M:%S')}] API {API_CONFIGS[current_api_index]['name']} è¿ç»­{threshold}æ¬¡é”™è¯¯ï¼Œå¼€å§‹åˆ‡æ¢...")
        # å¦‚æœå½“å‰ä½¿ç”¨çš„æ˜¯å¤‡ç”¨APIï¼Œæ£€æŸ¥ä¸»APIæ˜¯å¦å·²æ¢å¤
        if is_using_backup:
            # å¦‚æœä¸»APIå·²æ¢å¤ï¼Œåˆ‡å›ä¸»APIç»§ç»­æ‰§è¡Œåç»­é€»è¾‘
            primary_index = get_first_available_primary_api_index()
            if primary_index is not None and is_api_available(primary_index):
                print(f"[{now.strftime('%H:%M:%S')}] å¤‡ç”¨APIå‡ºé”™ï¼Œä½†ä¼˜å…ˆçº§ä¸»APIå·²æ¢å¤ï¼Œå°è¯•åˆ‡å›ä¸»API {API_CONFIGS[primary_index]['name']}")
                is_using_backup = False
                backup_start_time = None
                current_config_index = primary_index
                return True, primary_index
            # å¦‚æœä¸»APIä»ä¸å¯ç”¨ï¼Œå°è¯•åˆ‡æ¢åˆ°å¦ä¸€ä¸ªå¤‡ç”¨API
        
        # ç¬¬ä¸€å±‚ï¼šå°è¯•åˆ‡æ¢åˆ°å¤‡ç”¨API
        backup_indices = get_backup_api_indices()
        for backup_idx in backup_indices:
            if is_api_available(backup_idx):
                old_api_name = API_CONFIGS[current_config_index]['name']
                is_using_backup = True
                backup_start_time = now
                last_primary_check_time = None
                current_config_index = backup_idx
                print(f"[{now.strftime('%H:%M:%S')}] é”™è¯¯åˆ‡æ¢ï¼šä» {old_api_name} åˆ‡æ¢åˆ°å¤‡ç”¨API {API_CONFIGS[backup_idx]['name']}")
                return True, backup_idx
        
        # ç¬¬ä¸‰å±‚ï¼šæ‰€æœ‰APIéƒ½åœ¨å†·å´ä¸­ï¼Œå¼ºåˆ¶ä½¿ç”¨å¤‡ç”¨API
        # æ”¶é›†æ‰€æœ‰APIçš„å†·å´ä¿¡æ¯
        cooldown_details = []
        for i, api_config in enumerate(API_CONFIGS):
            if i in api_status and api_status[i]["cooldown_until"] and now < api_status[i]["cooldown_until"]:
                remaining_seconds = int((api_status[i]["cooldown_until"] - now).total_seconds())
                remaining_minutes = remaining_seconds // 60
                remaining_seconds = remaining_seconds % 60
                if remaining_minutes > 0:
                    cooldown_details.append(f"{api_config['name']}({remaining_minutes}åˆ†{remaining_seconds}ç§’)")
                else:
                    cooldown_details.append(f"{api_config['name']}({remaining_seconds}ç§’)")
        
        cooldown_info = ", ".join(cooldown_details) if cooldown_details else "å„APIå†·å´ä¸­"
        print(f"[{now.strftime('%H:%M:%S')}] æ‰€æœ‰APIéƒ½åœ¨å†·å´ä¸­({cooldown_info})ï¼Œå¼ºåˆ¶åˆ‡æ¢åˆ°å¤‡ç”¨API")
        
        is_using_backup = True
        backup_start_time = now
        last_primary_check_time = None  # é‡ç½®æ£€æµ‹æ—¶é—´ï¼Œç¡®ä¿ç«‹å³æ£€æµ‹
        
        # å¼ºåˆ¶ä½¿ç”¨ç¬¬ä¸€ä¸ªå¤‡ç”¨API
        backup_idx = backup_indices[0] if backup_indices else len(API_CONFIGS) - 1
        current_config_index = backup_idx
        print(f"[{now.strftime('%H:%M:%S')}] å¼ºåˆ¶ä½¿ç”¨å¤‡ç”¨API: {API_CONFIGS[backup_idx]['name']}")
        return True, backup_idx

def smart_codex_switch_api(current_api_index, error_code):
    """æ™ºèƒ½åˆ‡æ¢Codex API - ä¸‰å±‚ç­–ç•¥ï¼ˆä¸è®°å½•é”™è¯¯ï¼Œç”±è°ƒç”¨æ–¹è´Ÿè´£ï¼‰"""
    global codex_current_config_index, codex_is_using_backup, codex_backup_start_time, codex_last_primary_check_time
    
    with codex_key_switch_lock:
        now = datetime.now()
        
        # ä¸å†å†…éƒ¨è®°å½•é”™è¯¯ï¼Œç”±è°ƒç”¨æ–¹è´Ÿè´£
        # record_codex_error(current_api_index, error_code)
        codex_threshold = TimeoutConfig.get_codex_error_threshold()

        if codex_api_status[current_api_index]["error_count"] < codex_threshold:
            return False, current_api_index

        print(f"[{now.strftime('%H:%M:%S')}] Codex API {CODEX_CONFIGS[current_api_index]['name']} è¿ç»­{codex_threshold}æ¬¡é”™è¯¯ï¼Œå¼€å§‹åˆ‡æ¢...")
        if codex_is_using_backup:
            primary_index = get_first_available_primary_codex_index()
            if primary_index is not None and is_codex_api_available(primary_index):
                print(f"[{now.strftime('%H:%M:%S')}] å¤‡ç”¨Codex APIå‡ºé”™ï¼Œä½†ä¼˜å…ˆçº§ä¸»APIå·²æ¢å¤ï¼Œå°è¯•åˆ‡å›ä¸»API {CODEX_CONFIGS[primary_index]['name']}")
                codex_is_using_backup = False
                codex_backup_start_time = None
                codex_current_config_index = primary_index
                return True, primary_index
        
        backup_indices = get_codex_backup_api_indices()
        for backup_idx in backup_indices:
            if is_codex_api_available(backup_idx):
                old_api_name = CODEX_CONFIGS[codex_current_config_index]['name']
                codex_is_using_backup = True
                codex_backup_start_time = now
                codex_last_primary_check_time = None
                codex_current_config_index = backup_idx
                print(f"[{now.strftime('%H:%M:%S')}] é”™è¯¯åˆ‡æ¢ï¼šä» {old_api_name} åˆ‡æ¢åˆ°å¤‡ç”¨Codex API {CODEX_CONFIGS[backup_idx]['name']}")
                return True, backup_idx
        
        cooldown_details = []
        for i, codex_config in enumerate(CODEX_CONFIGS):
            if i in codex_api_status and codex_api_status[i]["cooldown_until"] and now < codex_api_status[i]["cooldown_until"]:
                remaining_seconds = int((codex_api_status[i]["cooldown_until"] - now).total_seconds())
                remaining_minutes = remaining_seconds // 60
                remaining_seconds = remaining_seconds % 60
                if remaining_minutes > 0:
                    cooldown_details.append(f"{codex_config['name']}({remaining_minutes}åˆ†{remaining_seconds}ç§’)")
                else:
                    cooldown_details.append(f"{codex_config['name']}({remaining_seconds}ç§’)")
        
        cooldown_info = ", ".join(cooldown_details) if cooldown_details else "å„Codex APIå†·å´ä¸­"
        print(f"[{now.strftime('%H:%M:%S')}] æ‰€æœ‰Codex APIéƒ½åœ¨å†·å´ä¸­({cooldown_info})ï¼Œå¼ºåˆ¶åˆ‡æ¢åˆ°å¤‡ç”¨API")
        
        codex_is_using_backup = True
        codex_backup_start_time = now
        codex_last_primary_check_time = None
        
        backup_idx = backup_indices[0] if backup_indices else len(CODEX_CONFIGS) - 1
        codex_current_config_index = backup_idx
        print(f"[{now.strftime('%H:%M:%S')}] å¼ºåˆ¶ä½¿ç”¨å¤‡ç”¨Codex API: {CODEX_CONFIGS[backup_idx]['name']}")
        return True, backup_idx

def switch_to_backup_api():
    """åˆ‡æ¢åˆ°å¤‡ç”¨APIï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
    current_api_index = current_config_index
    success, new_index = smart_switch_api(current_api_index, 429)  # é»˜è®¤429é”™è¯¯
    return success

# ä¿æŒå‘åå…¼å®¹
switch_to_backup_key = switch_to_backup_api

# è®¾ç½®å®Œæ•´è¾“å…¥è¾“å‡ºæ—¥å¿—è®°å½•
def setup_full_logger():
    """è®¾ç½®å®Œæ•´è¾“å…¥è¾“å‡ºçš„ä¸“ç”¨æ—¥å¿—è®°å½•å™¨"""
    if not ENABLE_FULL_LOG:
        return None
        
    full_logger = logging.getLogger('full_io_log')
    full_logger.setLevel(logging.INFO)
    
    # é¿å…é‡å¤æ·»åŠ å¤„ç†å™¨
    if not full_logger.handlers:
        try:
            # ä½¿ç”¨è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
            import os
            script_dir = os.path.dirname(os.path.abspath(__file__))
            log_filename = os.path.join(script_dir, "logs", "api_full_io.log")
            
            print(f"[æ—¥å¿—åˆå§‹åŒ–] æ—¥å¿—æ–‡ä»¶è·¯å¾„: {log_filename}")
            
            # æ£€æŸ¥å¹¶ä¿®å‰ªæ—¥å¿—æ–‡ä»¶
            trim_log_file(log_filename)
            
            file_handler = logging.FileHandler(log_filename, encoding='utf-8', mode='a')
            file_handler.setLevel(logging.INFO)
            
            # åˆ›å»ºæ ¼å¼åŒ–å™¨
            formatter = logging.Formatter(
                '%(asctime)s - %(levelname)s - %(message)s',
                datefmt='%Y-%m-%d %H:%M:%S'
            )
            file_handler.setFormatter(formatter)
            
            full_logger.addHandler(file_handler)
            full_logger.propagate = False  # é˜²æ­¢ä¼ æ’­åˆ°æ ¹æ—¥å¿—å™¨
            
            print(f"[æ—¥å¿—åˆå§‹åŒ–] æ—¥å¿—è®°å½•å™¨åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"[æ—¥å¿—åˆå§‹åŒ–] æ—¥å¿—è®°å½•å™¨åˆå§‹åŒ–å¤±è´¥: {e}", file=sys.stderr)
            return None
    
    return full_logger

# åˆå§‹åŒ–å®Œæ•´æ—¥å¿—è®°å½•å™¨
full_logger = setup_full_logger()

# è®¾ç½®æ—¥å¿—æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ï¼ˆç”¨äºå…¶ä»–å‡½æ•°å¼•ç”¨ï¼‰
LOG_FILE_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), "logs", "api_full_io.log")

def setup_original_data_logger():
    """è®¾ç½®å‘APIå‰åŸæ•°æ®çš„ä¸“ç”¨æ—¥å¿—è®°å½•å™¨"""
    if not ENABLE_FULL_LOG:
        return None
        
    orig_logger = logging.getLogger('original_data_log')
    orig_logger.setLevel(logging.INFO)
    
    # é¿å…é‡å¤æ·»åŠ å¤„ç†å™¨
    if not orig_logger.handlers:
        try:
            # ä½¿ç”¨è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
            script_dir = os.path.dirname(os.path.abspath(__file__))
            log_filename = os.path.join(script_dir, "logs", "api_original_data.log")
            
            print(f"[åŸæ•°æ®æ—¥å¿—åˆå§‹åŒ–] æ—¥å¿—æ–‡ä»¶è·¯å¾„: {log_filename}")
            
            # æ£€æŸ¥å¹¶ä¿®å‰ªæ—¥å¿—æ–‡ä»¶
            trim_log_file(log_filename)
            
            file_handler = logging.FileHandler(log_filename, encoding='utf-8', mode='a')
            file_handler.setLevel(logging.INFO)
            
            # åˆ›å»ºæ ¼å¼åŒ–å™¨
            formatter = logging.Formatter(
                '%(asctime)s - %(levelname)s - %(message)s',
                datefmt='%Y-%m-%d %H:%M:%S'
            )
            file_handler.setFormatter(formatter)
            
            orig_logger.addHandler(file_handler)
            orig_logger.propagate = False  # é˜²æ­¢ä¼ æ’­åˆ°æ ¹æ—¥å¿—å™¨
            
            print(f"[åŸæ•°æ®æ—¥å¿—åˆå§‹åŒ–] åŸæ•°æ®æ—¥å¿—è®°å½•å™¨åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"[åŸæ•°æ®æ—¥å¿—åˆå§‹åŒ–] åŸæ•°æ®æ—¥å¿—è®°å½•å™¨åˆå§‹åŒ–å¤±è´¥: {e}", file=sys.stderr)
            return None
    
    return orig_logger

# åˆå§‹åŒ–åŸæ•°æ®æ—¥å¿—è®°å½•å™¨
original_data_logger = setup_original_data_logger()

# è®¾ç½®åŸæ•°æ®æ—¥å¿—æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
ORIGINAL_DATA_LOG_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), "logs", "api_original_data.log")

def log_original_data(request_id, body, headers, method, path, is_codex_request=False):
    """è®°å½•å‘APIå‰çš„å®Œæ•´åŸæ•°æ®å†…å®¹ï¼ˆä¸æˆªæ–­ï¼‰"""
    if not ENABLE_FULL_LOG or not original_data_logger:
        return
    
    try:
        original_data_logger.info("="*40)
        request_type = "[Codexç›´è¿]" if is_codex_request else ""
        original_data_logger.info(f"ã€è¾“å…¥ã€‘{request_type} è¯·æ±‚ID: {request_id} | {method} {path}")
        
        # è®°å½•å®Œæ•´è¯·æ±‚ä½“
        if body and method == "POST":
            try:
                request_data = json.loads(body.decode('utf-8'))
                # ç›´æ¥è®°å½•å®Œæ•´æ•°æ®ï¼Œä¸è¿›è¡Œä»»ä½•æˆªæ–­
                original_data_logger.info(f"å®Œæ•´è¾“å…¥æ•°æ®: {json.dumps(request_data, ensure_ascii=False)}")
            except Exception as e:
                # éJSONæ ¼å¼ï¼Œç›´æ¥è®°å½•å®Œæ•´å†…å®¹
                original_data_logger.info(f"å®Œæ•´è¾“å…¥æ•°æ®(éJSON): {body.decode('utf-8', errors='ignore')}")
        
        trim_log_file(ORIGINAL_DATA_LOG_PATH)
        
    except Exception as e:
        print(f"è®°å½•è¾“å…¥æ•°æ®æ—¶å‡ºé”™: {e}", file=sys.stderr)

def log_original_response(request_id, response_chunks, is_codex_request=False):
    """è®°å½•APIå“åº”çš„å®Œæ•´è¾“å‡ºå†…å®¹ï¼ˆä¸æˆªæ–­ï¼‰"""
    if not ENABLE_FULL_LOG or not original_data_logger:
        return
    
    try:
        request_type = "[Codexç›´è¿]" if is_codex_request else ""
        original_data_logger.info(f"ã€è¾“å‡ºã€‘{request_type} è¯·æ±‚ID: {request_id}")
        
        # åˆå¹¶æ‰€æœ‰å“åº”å—
        if response_chunks:
            full_response = b''.join(response_chunks)
            try:
                # å°è¯•è§£æä¸ºæ–‡æœ¬
                response_text = full_response.decode('utf-8', errors='ignore')
                original_data_logger.info(f"å®Œæ•´è¾“å‡ºæ•°æ®: {response_text}")
            except Exception as e:
                # è§£ç å¤±è´¥ï¼Œè®°å½•åå…­è¿›åˆ¶
                original_data_logger.info(f"å®Œæ•´è¾“å‡ºæ•°æ®(åå…­è¿›åˆ¶): {full_response.hex()}")
        else:
            original_data_logger.info("å®Œæ•´è¾“å‡ºæ•°æ®: [ç©ºå“åº”]")
        
        original_data_logger.info("="*40)
        trim_log_file(ORIGINAL_DATA_LOG_PATH)

    except Exception as e:
        print(f"è®°å½•è¾“å‡ºæ•°æ®æ—¶å‡ºé”™: {e}", file=sys.stderr)

def extract_usage_from_chunks(response_chunks, is_codex_request=False):
    """
    ä»å“åº”chunksä¸­æå–usageæ•°æ®

    Args:
        response_chunks: å“åº”æ•°æ®å—åˆ—è¡¨
        is_codex_request: æ˜¯å¦ä¸ºCodexè¯·æ±‚

    Returns:
        dict: usageæ•°æ®ï¼Œæ ¼å¼ç»Ÿä¸€ä¸ºï¼š
            {input_tokens, output_tokens, cache_creation_input_tokens, cache_read_input_tokens, total_tokens}
    """
    try:
        # åˆå¹¶æ‰€æœ‰chunks
        complete_response = b''.join(response_chunks)
        response_text = complete_response.decode('utf-8', errors='ignore')

        # æŸ¥æ‰¾usageæ•°æ®
        lines = response_text.split('\n')
        usage_lines_found = 0
        for line in lines:
            if line.startswith('data: ') and line != 'data: [DONE]':
                try:
                    json_str = line[6:]
                    data = json.loads(json_str)

                    # æ£€æŸ¥æ˜¯å¦åŒ…å«usage
                    if 'usage' in data:
                        usage_lines_found += 1

                    if is_codex_request:
                        # Codex APIæ ¼å¼ï¼šresponse.completedäº‹ä»¶ä¸­åŒ…å«usage
                        if data.get('type') == 'response.completed':
                            codex_usage = data.get('response', {}).get('usage', {})
                            if codex_usage:
                                # æå–ç¼“å­˜tokenï¼ˆCodexä½¿ç”¨input_tokens_details.cached_tokensï¼‰
                                input_tokens_details = codex_usage.get('input_tokens_details', {})
                                cached_tokens = input_tokens_details.get('cached_tokens', 0)

                                # Codexçš„input_tokensåŒ…å«äº†æ–°è¾“å…¥+ç¼“å­˜è¾“å…¥
                                # éœ€è¦åˆ†ç¦»å‡ºçœŸæ­£çš„æ–°è¾“å…¥å’Œç¼“å­˜è¯»å–
                                total_input = codex_usage.get('input_tokens', 0)
                                new_input = total_input - cached_tokens

                                result = {
                                    'input_tokens': new_input,  # æ–°è¾“å…¥ï¼ˆéç¼“å­˜ï¼‰
                                    'output_tokens': codex_usage.get('output_tokens', 0),
                                    'cache_creation_input_tokens': 0,  # Codexç¼“å­˜åˆ›å»ºä¸å•ç‹¬è®¡è´¹
                                    'cache_read_input_tokens': cached_tokens,  # ç¼“å­˜è¯»å–
                                    'total_tokens': (
                                        new_input +
                                        codex_usage.get('output_tokens', 0) +
                                        cached_tokens
                                    )
                                }
                                return result
                    else:
                        # Claude APIæ ¼å¼ï¼šmessage_deltaæˆ–message_stopäº‹ä»¶ä¸­åŒ…å«usage
                        if 'usage' in data:
                            usage = data['usage']
                            # å®Œæ•´è®¡ç®—ï¼šåŒ…æ‹¬æ‰€æœ‰tokensï¼ˆinput + output + cache_creation + cache_readï¼‰
                            result = {
                                'input_tokens': usage.get('input_tokens', 0),
                                'output_tokens': usage.get('output_tokens', 0),
                                'cache_creation_input_tokens': usage.get('cache_creation_input_tokens', 0),
                                'cache_read_input_tokens': usage.get('cache_read_input_tokens', 0),
                                'total_tokens': (
                                    usage.get('input_tokens', 0) +
                                    usage.get('output_tokens', 0) +
                                    usage.get('cache_creation_input_tokens', 0) +
                                    usage.get('cache_read_input_tokens', 0)
                                )
                            }
                            return result
                except Exception as parse_error:
                    continue

        return None
    except Exception as e:
        return None

def validate_and_replace_user_key(authorization_header):
    """
    éªŒè¯ç”¨æˆ·Keyå¹¶æ›¿æ¢ä¸ºçœŸæ­£çš„API Key
    
    Args:
        authorization_header: ç”¨æˆ·æä¾›çš„Authorizationå¤´
        
    Returns:
        tuple: (is_valid, real_api_key_header, error_message)
    """
    if not authorization_header:
        return False, None, "ç¼ºå°‘Authorizationå¤´"
    
    # è§£æBearer token
    if not authorization_header.startswith('Bearer '):
        return False, None, "Authorizationå¤´æ ¼å¼é”™è¯¯ï¼Œéœ€è¦Bearer token"
    
    user_key = authorization_header[7:]  # å»æ‰'Bearer 'å‰ç¼€
    
    # éªŒè¯ç”¨æˆ·keyæ˜¯å¦å­˜åœ¨äºæ˜ å°„ä¸­
    if user_key not in USER_KEY_MAPPING:
        return False, None, f"æ— æ•ˆçš„ç”¨æˆ·Key: {user_key}"
    
    # è·å–çœŸæ­£çš„API keyï¼ˆæ”¯æŒåŠ¨æ€è·å–ï¼‰
    key_source = USER_KEY_MAPPING[user_key]
    if callable(key_source):
        real_api_key = key_source()  # è°ƒç”¨å‡½æ•°è·å–å½“å‰key
    else:
        real_api_key = key_source  # ç›´æ¥ä½¿ç”¨é™æ€key
    
    real_auth_header = f"Bearer {real_api_key}"
    
    return True, real_auth_header, None

def get_exact_test_headers():
    """è·å–éªŒè¯æˆåŠŸçš„sonnet-4è¯·æ±‚å¤´é…ç½®ï¼ˆä½¿ç”¨åŠ¨æ€API keyå’Œé˜²ç¼“å­˜å¤´éƒ¨ï¼‰"""
    current_key = get_current_api_key()
    # æ·»åŠ æ—¶é—´æˆ³å’Œéšæœºæ•°ä»¥é¿å…ç½‘ç»œç¼“å­˜
    import time
    import random
    timestamp = int(time.time() * 1000)  # æ¯«ç§’çº§æ—¶é—´æˆ³
    rand_id = random.randint(1000, 9999)
    return {
        'connection': 'keep-alive',
        'accept': 'application/json',
        'x-stainless-retry-count': '0',
        'x-stainless-timeout': '600',
        'x-stainless-lang': 'js',
        'x-stainless-package-version': '0.55.1',
        'x-stainless-os': 'Windows',
        'x-stainless-arch': 'x64',
        'x-stainless-runtime': 'node',
        'x-stainless-runtime-version': 'v22.17.0',
        'anthropic-dangerous-direct-browser-access': 'true',
        'anthropic-version': '2023-06-01',
        'x-app': 'cli',
        'user-agent': f'claude-cli/1.0.77 (external, cli, id-{rand_id})',
        'authorization': f'Bearer {current_key}',
        'content-type': 'application/json',
        'anthropic-beta': 'claude-code-20250219,interleaved-thinking-2025-05-14,fine-grained-tool-streaming-2025-05-14',
        'x-stainless-helper-method': 'stream',
        'accept-language': '*',
        'sec-fetch-mode': 'cors',
        'accept-encoding': 'gzip, deflate',
        # æ·»åŠ å¼ºåŒ–é˜²ç¼“å­˜å¤´éƒ¨
        'cache-control': 'no-cache, no-store, must-revalidate',
        'pragma': 'no-cache',
        'expires': '0',
        'x-request-id': f'{timestamp}-{rand_id}',
        'x-cache-bypass': f'{rand_id}'
    }

def debug_print(*args, **kwargs):
    """è°ƒè¯•ä¿¡æ¯æ‰“å°å‡½æ•°"""
    if DEBUG:
        print(*args, **kwargs, file=sys.stderr)

def detect_compressed_error(chunk_data):
    """
    æ£€æµ‹å¹¶å¤„ç†å‹ç¼©çš„é”™è¯¯å“åº”æ•°æ®
    
    Args:
        chunk_data: åŸå§‹chunkæ•°æ®ï¼ˆbytesï¼‰
        
    Returns:
        tuple: (is_error, error_info, decompressed_content)
    """
    try:
        # å°†bytesè½¬æ¢ä¸ºå­—ç¬¦ä¸²è¿›è¡Œåˆ†æ
        if isinstance(chunk_data, bytes):
            chunk_text = chunk_data.decode('utf-8', errors='ignore')
        else:
            chunk_text = str(chunk_data)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«erroräº‹ä»¶
        if 'event: error' in chunk_text:
            print(f"[é”™è¯¯æ£€æµ‹] å‘ç°erroräº‹ä»¶")
            
            # æå–dataéƒ¨åˆ†
            lines = chunk_text.strip().split('\n')
            for line in lines:
                if line.startswith('data: '):
                    try:
                        data_json = line[6:]  # å»æ‰'data: 'å‰ç¼€
                        error_data = json.loads(data_json)
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰å‹ç¼©çš„details
                        details = error_data.get('details', '')
                        if details and isinstance(details, str):
                            # æ£€æµ‹gzipå‹ç¼©ç‰¹å¾ï¼ˆä»¥\x1f\x8bå¼€å¤´æˆ–åŒ…å«è¿™äº›è½¬ä¹‰å­—ç¬¦ï¼‰
                            if details.startswith('\x1f\x8b') or '\\u001f\\u008b' in details:
                                print(f"[é”™è¯¯æ£€æµ‹] å‘ç°å‹ç¼©çš„é”™è¯¯è¯¦æƒ…æ•°æ®")
                                
                                try:
                                    # å¤„ç†Unicodeè½¬ä¹‰çš„å‹ç¼©æ•°æ®
                                    if '\\u001f\\u008b' in details:
                                        # å°†Unicodeè½¬ä¹‰åºåˆ—è½¬æ¢ä¸ºå®é™…å­—èŠ‚
                                        import codecs
                                        unescaped = codecs.decode(details, 'unicode_escape')
                                        compressed_data = unescaped.encode('latin-1')
                                    else:
                                        compressed_data = details.encode('latin-1')
                                    
                                    # å°è¯•è§£å‹ç¼©
                                    decompressed = gzip.decompress(compressed_data).decode('utf-8')
                                    print(f"[é”™è¯¯æ£€æµ‹] è§£å‹ç¼©æˆåŠŸï¼Œå†…å®¹: {decompressed[:200]}...")
                                    
                                    # æ›´æ–°é”™è¯¯æ•°æ®
                                    error_data['details'] = decompressed
                                    error_data['details_decompressed'] = True
                                    
                                    return True, error_data, decompressed
                                    
                                except Exception as decompress_error:
                                    print(f"[é”™è¯¯æ£€æµ‹] è§£å‹ç¼©å¤±è´¥: {decompress_error}")
                                    return True, error_data, details
                            else:
                                # æœªå‹ç¼©çš„é”™è¯¯è¯¦æƒ…
                                return True, error_data, details
                        
                        # æ²¡æœ‰detailså­—æ®µä½†æœ‰error
                        return True, error_data, error_data.get('error', 'Unknown error')
                        
                    except json.JSONDecodeError as e:
                        print(f"[é”™è¯¯æ£€æµ‹] JSONè§£æå¤±è´¥: {e}")
                        return True, {'error': 'JSON parse error', 'details': chunk_text}, chunk_text
            
            # æœ‰erroräº‹ä»¶ä½†æ— æ³•è§£ædata
            return True, {'error': 'Error event detected', 'details': chunk_text}, chunk_text
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«403æˆ–å…¶ä»–å…³é”®é”™è¯¯ä¿¡æ¯
        error_keywords = ['401', '403', 'forbidden', 'unauthorized', 'access denied', 'invalid key', 'api key']
        if any(keyword in chunk_text.lower() for keyword in error_keywords):
            print(f"[é”™è¯¯æ£€æµ‹] å‘ç°å…³é”®é”™è¯¯è¯: {chunk_text[:200]}...")
            return True, {'error': 'Access error detected', 'details': chunk_text}, chunk_text
        
        return False, None, None
        
    except Exception as e:
        print(f"[é”™è¯¯æ£€æµ‹] å¤„ç†å¼‚å¸¸: {e}")
        return False, None, None

def should_trigger_api_switch(error_info):
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥è§¦å‘APIåˆ‡æ¢
    
    Args:
        error_info: é”™è¯¯ä¿¡æ¯å­—å…¸
        
    Returns:
        tuple: (should_switch, error_code)
    """
    if not error_info:
        return False, None
    
    # æ£€æŸ¥çŠ¶æ€ç 
    status = error_info.get('status')
    if status in [401, 403, 429, 502, 503, 500]:
        return True, status
    
    # æ£€æŸ¥é”™è¯¯å†…å®¹
    error_msg = str(error_info.get('error', '')) + str(error_info.get('details', ''))
    error_msg_lower = error_msg.lower()
    
    # å®šä¹‰é”™è¯¯ç±»å‹æ˜ å°„ï¼Œå‡å°‘é‡å¤ä»£ç 
    error_patterns = {
        401: ['401', 'unauthorized', 'invalid key', 'authentication', 'bearer token', 'not authorized'],
        403: ['403', 'forbidden', 'access denied', 'invalid key', 'unauthorized', 'authentication'],
        429: ['429', 'rate limit', 'too many requests'],
        502: ['502', 'bad gateway', '500', 'internal server'],
        503: ['503', 'service unavailable', 'unavailable', 'server unavailable', 'overloaded', 'temporarily unavailable']
    }
    
    for error_code, keywords in error_patterns.items():
        if any(keyword in error_msg_lower for keyword in keywords):
            return True, error_code
    
    return False, None

def handle_detected_error(request_id, error_info, decompressed_content, context=""):
    """
    ç»Ÿä¸€å¤„ç†æ£€æµ‹åˆ°çš„é”™è¯¯ï¼Œé¿å…ä»£ç é‡å¤
    
    Args:
        request_id: è¯·æ±‚ID
        error_info: é”™è¯¯ä¿¡æ¯
        decompressed_content: è§£å‹åå†…å®¹
        context: ä¸Šä¸‹æ–‡è¯´æ˜ï¼ˆå¦‚"æµå¼"æˆ–"éæµå¼"ï¼‰
    """
    should_switch, error_code = should_trigger_api_switch(error_info)
    
    # å¦‚æœéœ€è¦åˆ‡æ¢APIï¼Œè§¦å‘åˆ‡æ¢é€»è¾‘
    if should_switch:
        print(f"[{context}é”™è¯¯åˆ‡æ¢][{request_id}] æ£€æµ‹åˆ°é”™è¯¯ç {error_code}ï¼Œå‡†å¤‡åˆ‡æ¢API")
        # è·å–å½“å‰APIç´¢å¼•
        current_api_index = current_config_index
        
        # å°è¯•æ™ºèƒ½åˆ‡æ¢API
        switch_success, new_api_index = smart_switch_api(current_api_index, error_code)
        
        if switch_success:
            if context == "æµå¼":
                print(f"[{context}é”™è¯¯åˆ‡æ¢][{request_id}] åˆ‡æ¢æˆåŠŸï¼Œä½†æµå¼å“åº”å·²å¼€å§‹ï¼Œå»ºè®®å®¢æˆ·ç«¯é‡è¯•")
            else:
                print(f"[{context}é”™è¯¯åˆ‡æ¢][{request_id}] åˆ‡æ¢æˆåŠŸï¼Œå»ºè®®å®¢æˆ·ç«¯é‡è¯•")

# ä½¿ç”¨åŠ¨æ€APIç«¯ç‚¹é…ç½®
def build_upstream_url(clean_path, query_string=None, is_openai_format=False, base_url=None):
    """æ„å»ºä¸Šæ¸¸APIçš„å®Œæ•´URL"""
    if base_url is None:
        config = get_current_config()
        base_url = config["base_url"]

    url = f"{base_url}/{clean_path}"
    
    if query_string:
        if is_openai_format:
            url += f"?{query_string}&beta=true"
        else:
            url += f"?{query_string}"
    elif is_openai_format:
        url += "?beta=true"
    
    return url

# ä¿æŒå‘åå…¼å®¹
def get_current_base_url():
    """è·å–å½“å‰åº”è¯¥ä½¿ç”¨çš„åŸºç¡€URLï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
    config = get_current_config()
    return config["base_url"]

# ===============================================
# ç»Ÿä¸€è¶…æ—¶é…ç½®ç®¡ç† - æå‰å®šä¹‰ä»¥ä¾›å…¨å±€ä½¿ç”¨
# ===============================================
class TimeoutConfig:
    """ç»Ÿä¸€çš„è¶…æ—¶é…ç½®ç®¡ç†ç±»"""
    
    @classmethod
    def _get_settings(cls):
        """è·å–è¶…æ—¶é…ç½®è®¾ç½®"""
        return config_mgr.get_timeout_settings()
    
    @classmethod
    def get_connect_timeout(cls):
        return cls._get_settings().get("connect_timeout", 60.0)
    
    @classmethod
    def get_write_timeout(cls):
        return cls._get_settings().get("write_timeout", 60.0)
    
    @classmethod
    def get_pool_timeout(cls):
        return cls._get_settings().get("pool_timeout", 120.0)
    
    @classmethod
    def get_streaming_read_timeout(cls):
        return cls._get_settings().get("streaming_read_timeout", 60.0)
    
    @classmethod
    def get_non_streaming_read_timeout(cls):
        return cls._get_settings().get("non_streaming_read_timeout", 60.0)
    
    @classmethod
    def get_extended_connect_timeout(cls):
        return cls._get_settings().get("extended_connect_timeout", 45.0)
    
    @classmethod
    def get_retry_read_timeout(cls):
        """è·å–é‡è¯•è¯·æ±‚çš„è¯»å–è¶…æ—¶ï¼ˆé»˜è®¤60ç§’ï¼‰"""
        return cls._get_settings().get("retry_read_timeout", 60.0)
    
    @classmethod
    def get_api_cooldown_seconds(cls):
        return cls._get_settings().get("api_cooldown_seconds", 600)

    @classmethod
    def get_api_error_threshold(cls):
        value = cls._get_settings().get("api_error_threshold", 3)
        try:
            threshold = int(value)
        except (TypeError, ValueError):
            return 3
        return threshold if threshold > 0 else 1

    @classmethod
    def get_codex_error_threshold(cls):
        value = cls._get_settings().get("codex_error_threshold", 3)
        try:
            threshold = int(value)
        except (TypeError, ValueError):
            return 3
        return threshold if threshold > 0 else 1

    
    @classmethod
    def get_codex_base_timeout(cls):
        return cls._get_settings().get("codex_base_timeout", 60)
    
    @classmethod
    def get_codex_timeout_increment(cls):
        return cls._get_settings().get("codex_timeout_increment", 60)
    
    @classmethod
    def get_codex_connect_timeout(cls):
        return cls._get_settings().get("codex_connect_timeout", 30.0)
    
    @classmethod
    def get_primary_api_check_interval(cls):
        return cls._get_settings().get("primary_api_check_interval", 30)
    
    @classmethod
    def get_billing_cycle_delay(cls):
        return cls._get_settings().get("billing_cycle_delay", 60)
    
    @classmethod
    def get_health_check_interval(cls):
        return cls._get_settings().get("health_check_interval", 0.5)
    
    @classmethod
    def get_billing_send_interval(cls):
        return cls._get_settings().get("billing_send_interval", 1.0)
    
    @classmethod
    def get_stream_retry_wait(cls):
        return cls._get_settings().get("stream_retry_wait", 1.0)
    
    @classmethod
    def get_max_retries(cls):
        """è·å–æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆswitch_apiç­–ç•¥ä½¿ç”¨ï¼‰"""
        value = cls._get_settings().get("max_retries", 4)
        try:
            retries = int(value)
        except (TypeError, ValueError):
            retries = 4
        return retries if retries > 0 else 1
    
    @classmethod
    def get_modify_retry_headers(cls):
        """è·å–æ˜¯å¦åœ¨é‡è¯•æ—¶ä¿®æ”¹è¯·æ±‚å¤´ï¼ˆé»˜è®¤Trueï¼‰"""
        return cls._get_settings().get("modify_retry_headers", True)
    
    @classmethod
    def get_strategy_retry_status_codes(cls):
        """è·å–ç­–ç•¥é‡è¯•çŠ¶æ€ç é›†åˆï¼ˆä»é”™è¯¯å¤„ç†ç­–ç•¥é…ç½®è¯»å–ï¼‰"""
        strategies = config_mgr.get_error_handling_strategies()
        http_codes = strategies.get("http_status_codes", {})
        # è·³è¿‡"default"é”®ï¼Œåªå¤„ç†æ•°å­—çŠ¶æ€ç 
        retry_codes = [int(code) for code, strategy in http_codes.items()
                      if strategy == "strategy_retry" and code != "default"]
        return set(retry_codes) if retry_codes else {400, 404, 429, 500, 502, 503, 520, 521, 522, 524}
    
    @classmethod
    def get_network_error_strategy(cls, error_type: str) -> str:
        """è·å–ç½‘ç»œé”™è¯¯çš„å¤„ç†ç­–ç•¥
        
        Args:
            error_type: é”™è¯¯ç±»å‹ ("ReadError", "ConnectError", "ReadTimeout")
            
        Returns:
            ç­–ç•¥ç±»å‹: "strategy_retry", "switch_api", "normal_retry"
        """
        strategies = config_mgr.get_error_handling_strategies()
        network_errors = strategies.get("network_errors", {})
        return network_errors.get(error_type, "switch_api")  # é»˜è®¤åˆ‡æ¢API
    
    @classmethod
    def get_streaming_timeout(cls):
        """è·å–æµå¼è¯·æ±‚è¶…æ—¶é…ç½®"""
        return httpx.Timeout(
            connect=cls.get_connect_timeout(),
            read=cls.get_streaming_read_timeout(),
            write=cls.get_write_timeout(),
            pool=cls.get_pool_timeout()
        )
    
    @classmethod
    def get_non_streaming_timeout(cls):
        """è·å–éæµå¼è¯·æ±‚è¶…æ—¶é…ç½®"""
        return httpx.Timeout(
            connect=cls.get_connect_timeout(),
            read=cls.get_non_streaming_read_timeout(),
            write=cls.get_write_timeout(),
            pool=cls.get_pool_timeout()
        )
    
    @classmethod
    def get_retry_timeout(cls, is_non_streaming=False):
        """è·å–é‡è¯•è¯·æ±‚è¶…æ—¶é…ç½®"""
        read_timeout = cls.get_non_streaming_read_timeout() if is_non_streaming else cls.get_retry_read_timeout()
        return httpx.Timeout(
            connect=cls.get_extended_connect_timeout(),
            read=read_timeout,
            write=cls.get_write_timeout(),
            pool=cls.get_pool_timeout()
        )
    
    @classmethod
    def get_strategy_retry_read_timeout(cls):
        """è·å–ç­–ç•¥é‡è¯•çš„è¯»å–è¶…æ—¶ï¼ˆé»˜è®¤200ç§’ï¼‰"""
        return cls._get_settings().get("strategy_retry_read_timeout", 200.0)
    
    @classmethod
    def get_strategy_retry_timeout(cls):
        """è·å–ç­–ç•¥é‡è¯•ä¸“ç”¨çš„è¶…æ—¶é…ç½®"""
        return httpx.Timeout(
            connect=cls.get_extended_connect_timeout(),
            read=cls.get_strategy_retry_read_timeout(),
            write=cls.get_write_timeout(),
            pool=cls.get_pool_timeout()
        )

# è®¡è´¹ä¼˜åŒ–åŠŸèƒ½ - å®šæ—¶å¯åŠ¨è®¡è´¹å‘¨æœŸ
import time
import json

# ä¸ºè®¡è´¹å¯åŠ¨åŠŸèƒ½åˆ›å»ºåŒæ­¥HTTPå®¢æˆ·ç«¯ï¼Œç¦ç”¨è¿æ¥å¤ç”¨
billing_limits = httpx.Limits(max_keepalive_connections=0, max_connections=10)
billing_client = httpx.Client(
    timeout=TimeoutConfig.get_non_streaming_timeout(),  # ä½¿ç”¨ç»Ÿä¸€çš„éæµå¼è¶…æ—¶é…ç½®
    limits=billing_limits
)

def send_billing_activation_message(api_index):
    """å‘æŒ‡å®šAPIå‘é€è®¡è´¹å¯åŠ¨æ¶ˆæ¯ï¼ˆä½¿ç”¨OpenAIæ ¼å¼å’Œé”™è¯¯æ£€æµ‹ï¼‰"""
    try:
        config = API_CONFIGS[api_index]
        url = f"{config['base_url']}/v1/messages"
        
        # ä½¿ç”¨OpenAIæ ¼å¼çš„æµ‹è¯•æ¶ˆæ¯ï¼Œè½¬æ¢ä¸ºClaudeæ ¼å¼ï¼ˆå¢åŠ è¾“å‡ºé•¿åº¦ä»¥ç¡®ä¿è®¡è´¹ï¼‰
        openai_payload = {
            "model": "claude-sonnet-4-5-20250929",
            "max_tokens": 200,
            "messages": [{"role": "user", "content": "è¯·ç”¨100å­—å·¦å³ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±çš„èƒ½åŠ›å’Œç‰¹ç‚¹"}],
            "stream": False
        }
        
        # ä½¿ç”¨å·²æœ‰çš„OpenAIè½¬æ¢åŠŸèƒ½
        from openai_adapter import detect_and_convert_request
        is_openai, converted_payload, conversion_headers = detect_and_convert_request(openai_payload)
        
        # ä½¿ç”¨è½¬æ¢åçš„å¤´å’Œè´Ÿè½½
        headers = conversion_headers.copy()
        headers['authorization'] = f"Bearer {config['key']}"
        
        response = billing_client.post(url, json=converted_payload, headers=headers)
        
        # ä½¿ç”¨å¢å¼ºçš„é”™è¯¯æ£€æµ‹åŠŸèƒ½
        response_text = response.text
        response_content = response_text.encode('utf-8')
        
        # æ£€æµ‹é”™è¯¯
        is_error, error_info, decompressed_content = detect_compressed_error(response_content)
        
        if response.status_code == 200 and not is_error:
            # æ£€æŸ¥å“åº”å†…å®¹æ˜¯å¦æ­£å¸¸
            try:
                response_data = response.json()
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„å†…å®¹
                if 'content' in response_data and response_data['content']:
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] âœ… APIå¥åº·: {config['name']} - å“åº”æ­£å¸¸")
                    return True
                else:
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] âš ï¸ APIå¼‚å¸¸: {config['name']} - å“åº”å†…å®¹ä¸ºç©º")
                    return False
            except Exception as json_error:
                # JSONè§£æå¤±è´¥ï¼Œæ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
                content_type = response.headers.get('content-type', 'Unknown')
                response_preview = response_text[:200].replace('\n', '\\n').replace('\r', '\\r')
                
                # æ£€æŸ¥ä¸åŒç±»å‹çš„æµå¼å“åº”
                if content_type == 'text/event-stream':
                    # SSE (Server-Sent Events) æ ¼å¼
                    if 'event:' in response_text or 'data:' in response_text:
                        print(f"[{datetime.now().strftime('%H:%M:%S')}] âœ… APIå¥åº·: {config['name']} - SSEæµå¼å“åº”æ­£å¸¸")
                        return True
                elif 'content' in response_text and 'text' in response_text:
                    # ä¼ ç»Ÿæµå¼å“åº”æ ¼å¼
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] âœ… APIå¥åº·: {config['name']} - æµå¼å“åº”æ­£å¸¸")
                    return True
                
                # æ— æ³•è¯†åˆ«çš„å“åº”æ ¼å¼
                print(f"[{datetime.now().strftime('%H:%M:%S')}] âš ï¸ APIå¼‚å¸¸: {config['name']} - å“åº”æ ¼å¼å¼‚å¸¸")
                print(f"    JSONè§£æé”™è¯¯: {str(json_error)}")
                print(f"    å†…å®¹ç±»å‹: {content_type}")
                print(f"    å“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
                print(f"    å“åº”é¢„è§ˆ: {response_preview}{'...' if len(response_text) > 200 else ''}")
                return False
        else:
            # æœ‰é”™è¯¯æˆ–çŠ¶æ€ç å¼‚å¸¸
            status_msg = f"çŠ¶æ€ç :{response.status_code}"
            error_msg = ""
            
            if is_error:
                error_msg = f" | é”™è¯¯:{error_info.get('error', 'Unknown')}"
                if 'details' in error_info:
                    details = str(error_info['details'])[:100]
                    error_msg += f" | è¯¦æƒ…:{details}"
            
            print(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ APIæ•…éšœ: {config['name']} - {status_msg}{error_msg}")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘APIåˆ‡æ¢é€»è¾‘
            should_switch, error_code = should_trigger_api_switch(error_info)
            if should_switch:
                print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ”„ APIéœ€è¦åˆ‡æ¢: {config['name']} - é”™è¯¯ç :{error_code}")
            
            return False
            
    except Exception as e:
        print(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ APIå¼‚å¸¸: {config['name']} - è¿æ¥é”™è¯¯: {e}")
        return False

def send_codex_billing_activation_message(api_index):
    """å‘æŒ‡å®šCodex APIå‘é€è®¡è´¹å¯åŠ¨æ¶ˆæ¯ï¼ˆä½¿ç”¨Codexæ ¼å¼ï¼‰"""
    try:
        config = CODEX_CONFIGS[api_index]
        base_url = config['base_url']
        # ç›´æ¥ä½¿ç”¨é…ç½®çš„base_urlï¼Œä¸åšå¤„ç†
        # æ­£å¸¸Codexè¯·æ±‚ä¼šå‘é€åˆ° base_url + /responses
        url = f"{base_url}/responses"
        
        # Codexèº«ä»½è¯†åˆ«æŒ‡ä»¤ï¼ˆä»çœŸå®Codex CLIæå–ï¼‰
        codex_instructions = """You are Codex, based on GPT-5. You are running as a coding agent in the Codex CLI on a user's computer.

## General

- The arguments to `shell` will be passed to execvp(). Most terminal commands should be prefixed with ["bash", "-lc"].
- Always set the `workdir` param when using the shell function. Do not use `cd` unless absolutely necessary.
- When searching for text or files, prefer using `rg` or `rg --files` respectively because `rg` is much faster than alternatives like `grep`. (If the `rg` command is not found, then use alternatives.)

## Editing constraints

- Default to ASCII when editing or creating files. Only introduce non-ASCII or other Unicode characters when there is a clear justification and the file already uses them.
- Add succinct code comments that explain what is going on if code is not self-explanatory. You should not add comments like "Assigns the value to the variable", but a brief comment might be useful ahead of a complex code block that the user would otherwise have to spend time parsing out. Usage of these comments should be rare.
- You may be in a dirty git worktree.
    * NEVER revert existing changes you did not make unless explicitly requested, since these changes were made by the user.
    * If asked to make a commit or code edits and there are unrelated changes to your work or changes that you didn't make in those files, don't revert those changes.
    * If the changes are in files you've touched recently, you should read carefully and understand how you can work with the changes rather than reverting them.
    * If the changes are in unrelated files, just ignore them and don't revert them.
- While you are working, you might notice unexpected changes that you didn't make. If this happens, STOP IMMEDIATELY and ask the user how they would like to proceed.

## Plan tool

When using the planning tool:
- Skip using the planning tool for straightforward tasks (roughly the easiest 25%).
- Do not make single-step plans.
- When you made a plan, update it after having performed one of the sub-tasks that you shared on the plan.

## Codex CLI harness, sandboxing, and approvals

The Codex CLI harness supports several different configurations for sandboxing and escalation approvals that the user can choose from.

Filesystem sandboxing defines which files can be read or written. The options for `sandbox_mode` are:
- **read-only**: The sandbox only permits reading files.
- **workspace-write**: The sandbox permits reading files, and editing files in `cwd` and `writable_roots`. Editing files in other directories requires approval.
- **danger-full-access**: No filesystem sandboxing - all commands are permitted.

Network sandboxing defines whether network can be accessed without approval. Options for `network_access` are:
- **restricted**: Requires approval
- **enabled**: No approval needed

Approvals are your mechanism to get user consent to run shell commands without the sandbox. Possible configuration options for `approval_policy` are
- **untrusted**: The harness will escalate most commands for user approval, apart from a limited allowlist of safe "read" commands.
- **on-failure**: The harness will allow all commands to run in the sandbox (if enabled), and failures will be escalated to the user for approval to run again without the sandbox.
- **on-request**: Commands will be run in the sandbox by default, and you can specify in your tool call if you want to escalate a command to run without sandboxing. (Note that this mode is not always available. If it is, you'll see parameters for it in the `shell` command description.)
- **never**: This is a non-interactive mode where you may NEVER ask the user for approval to run commands. Instead, you must always persist and work around constraints to solve the task for the user. You MUST do your utmost best to finish the task and validate your work before yielding. If this mode is paired with `danger-full-access`, take advantage of it to deliver the best outcome for the user. Further, in this mode, your default testing philosophy is overridden: Even if you don't see local patterns for testing, you may add tests and scripts to validate your work. Just remove them before yielding.

When you are running with `approval_policy == on-request`, and sandboxing enabled, here are scenarios where you'll need to request approval:
- You need to run a command that writes to a directory that requires it (e.g. running tests that write to /var)
- You need to run a GUI app (e.g., open/xdg-open/osascript) to open browsers or files.
- You are running sandboxed and need to run a command that requires network access (e.g. installing packages)
- If you run a command that is important to solving the user's query, but it fails because of sandboxing, rerun the command with approval. ALWAYS proceed to use the `with_escalated_permissions` and `justification` parameters - do not message the user before requesting approval for the command.
- You are about to take a potentially destructive action such as an `rm` or `git reset` that the user did not explicitly ask for
- (for all of these, you should weigh alternative paths that do not require approval)

When `sandbox_mode` is set to read-only, you'll need to request approval for any command that isn't a read.

You will be told what filesystem sandboxing, network sandboxing, and approval mode are active in a developer or user message. If you are not told about this, assume that you are running with workspace-write, network sandboxing enabled, and approval on-failure.

Although they introduce friction to the user because your work is paused until the user responds, you should leverage them when necessary to accomplish important work. If the completing the task requires escalated permissions, Do not let these settings or the sandbox deter you from attempting to accomplish the user's task unless it is set to "never", in which case never ask for approvals.

When requesting approval to execute a command that will require escalated privileges:
  - Provide the `with_escalated_permissions` parameter with the boolean value true
  - Include a short, 1 sentence explanation for why you need to enable `with_escalated_permissions` in the justification parameter

## Special user requests

- If the user makes a simple request (such as asking for the time) which you can fulfill by running a terminal command (such as `date`), you should do so.
- If the user asks for a "review", default to a code review mindset: prioritise identifying bugs, risks, behavioural regressions, and missing tests. Findings must be the primary focus of the response - keep summaries or overviews brief and only after enumerating the issues. Present findings first (ordered by severity with file/line references), follow with open questions or assumptions, and offer a change-summary only as a secondary detail. If no findings are discovered, state that explicitly and mention any residual risks or testing gaps.

## Presenting your work and final message

You are producing plain text that will later be styled by the CLI. Follow these rules exactly. Formatting should make results easy to scan, but not feel mechanical. Use judgment to decide how much structure adds value.

- Default: be very concise; friendly coding teammate tone.
- Ask only when needed; suggest ideas; mirror the user's style.
- For substantial work, summarize clearly; follow finalâ€‘answer formatting.
- Skip heavy formatting for simple confirmations.
- Don't dump large files you've written; reference paths only.
- No "save/copy this file" - User is on the same machine.
- Offer logical next steps (tests, commits, build) briefly; add verify steps if you couldn't do something.
- For code changes:
  * Lead with a quick explanation of the change, and then give more details on the context covering where and why a change was made. Do not start this explanation with "summary", just jump right in.
  * If there are natural next steps the user may want to take, suggest them at the end of your response. Do not make suggestions if there are no natural next steps.
  * When suggesting multiple options, use numeric lists for the suggestions so the user can quickly respond with a single number.
- The user does not command execution outputs. When asked to show the output of a command (e.g. `git show`), relay the important details in your answer or summarize the key lines so the user understands the result.

### Final answer structure and style guidelines

- Plain text; CLI handles styling. Use structure only when it helps scanability.
- Headers: optional; short Title Case (1-3 words) wrapped in **â€¦**; no blank line before the first bullet; add only if they truly help.
- Bullets: use - ; merge related points; keep to one line when possible; 4â€“6 per list ordered by importance; keep phrasing consistent.
- Monospace: backticks for commands/paths/env vars/code ids and inline examples; use for literal keyword bullets; never combine with **.
- Code samples or multi-line snippets should be wrapped in fenced code blocks; add a language hint whenever obvious.
- Structure: group related bullets; order sections general â†’ specific â†’ supporting; for subsections, start with a bolded keyword bullet, then items; match complexity to the task.
- Tone: collaborative, concise, factual; present tense, active voice; selfâ€‘contained; no "above/below"; parallel wording.
- Don'ts: no nested bullets/hierarchies; no ANSI codes; don't cram unrelated keywords; keep keyword lists shortâ€”wrap/reformat if long; avoid naming formatting styles in answers.
- Adaptation: code explanations â†’ precise, structured with code refs; simple tasks â†’ lead with outcome; big changes â†’ logical walkthrough + rationale + next actions; casual one-offs â†’ plain sentences, no headers/bullets.
- File References: When referencing files in your response, make sure to include the relevant start line and always follow the below rules:
  * Use inline code to make file paths clickable.
  * Each reference should have a stand alone path. Even if it's the same file.
  * Accepted: absolute, workspaceâ€‘relative, a/ or b/ diff prefixes, or bare filename/suffix.
  * Line/column (1â€‘based, optional): :line[:column] or #Lline[Ccolumn] (column defaults to 1).
  * Do not use URIs like file://, vscode://, or https://.
  * Do not provide range of lines
  * Examples: src/app.ts, src/app.ts:42, b/server/index.js#L10, C:\\\\repo\\\\project\\\\main.rs:12:5"""
        
        # æ„å»ºç¯å¢ƒä¸Šä¸‹æ–‡ï¼ˆCodex CLIå¿…éœ€ï¼‰
        import os
        env_context = {
            'cwd': os.path.abspath('.'),
            'approval_policy': 'on-request',
            'sandbox_mode': 'workspace-write',
            'network_access': 'enabled',
            'shell': 'powershell.exe' if os.name == 'nt' else 'bash'
        }
        
        env_text = f"<environment_context>\n  <cwd>{env_context['cwd']}</cwd>\n  <approval_policy>{env_context['approval_policy']}</approval_policy>\n  <sandbox_mode>{env_context['sandbox_mode']}</sandbox_mode>\n  <network_access>{env_context['network_access']}</network_access>\n  <shell>{env_context['shell']}</shell>\n</environment_context>"
        
        # æ„å»ºCodexæ ¼å¼çš„è¾“å…¥æ¶ˆæ¯ï¼ˆç¬¬ä¸€æ¡å¿…é¡»æ˜¯ç¯å¢ƒä¸Šä¸‹æ–‡ï¼‰
        codex_input = [
            {
                "type": "message",
                "role": "user",
                "content": [{
                    "type": "input_text",
                    "text": env_text
                }]
            },
            {
                "type": "message",
                "role": "user",
                "content": [{
                    "type": "input_text",
                    "text": "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"
                }]
            }
        ]
        
        # å®Œæ•´çš„Codexæ ¼å¼payloadï¼ˆåŒ…å«èº«ä»½è¯†åˆ«ï¼‰
        payload = {
            "model": "gpt-5-codex",
            "instructions": codex_instructions,
            "input": codex_input,
            "tools": [
                {
                    "type": "function",
                    "name": "shell",
                    "description": "Runs a shell command and returns its output.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "command": {
                                "type": "array",
                                "items": {"type": "string"},
                                "description": "The command to execute"
                            },
                            "justification": {
                                "type": "string",
                                "description": "Only set if with_escalated_permissions is true. 1-sentence explanation of why we want to run this command."
                            },
                            "timeout_ms": {
                                "type": "number",
                                "description": "The timeout for the command in milliseconds"
                            },
                            "with_escalated_permissions": {
                                "type": "boolean",
                                "description": "Whether to request escalated permissions. Set to true if command needs to be run without sandbox restrictions"
                            },
                            "workdir": {
                                "type": "string",
                                "description": "The working directory to execute the command in"
                            }
                        },
                        "required": ["command"],
                        "additionalProperties": False
                    },
                    "strict": False
                },
                {
                    "type": "function",
                    "name": "update_plan",
                    "description": "Updates the task plan.\\nProvide an optional explanation and a list of plan items, each with a step and status.\\nAt most one step can be in_progress at a time.\\n",
                    "strict": False,
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "explanation": {"type": "string"},
                            "plan": {
                                "type": "array",
                                "items": {
                                    "type": "object",
                                    "properties": {
                                        "status": {
                                            "type": "string",
                                            "description": "One of: pending, in_progress, completed"
                                        },
                                        "step": {"type": "string"}
                                    },
                                    "required": ["step", "status"],
                                    "additionalProperties": False
                                },
                                "description": "The list of steps"
                            }
                        },
                        "required": ["plan"],
                        "additionalProperties": False
                    }
                },
                {
                    "type": "function",
                    "name": "view_image",
                    "description": "Attach a local image (by filesystem path) to the conversation context for this turn.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "path": {
                                "type": "string",
                                "description": "Local filesystem path to an image file"
                            }
                        },
                        "required": ["path"],
                        "additionalProperties": False
                    },
                    "strict": False
                }
            ],
            "tool_choice": "auto",
            "parallel_tool_calls": False,
            "stream": True,
            "store": False,
            "include": ["reasoning.encrypted_content"],
            "prompt_cache_key": str(uuid.uuid4())
        }
        
        # ç”Ÿæˆä¼šè¯IDï¼ˆæ¯æ¬¡è¯·æ±‚ç”Ÿæˆæ–°çš„UUIDï¼‰
        import uuid as uuid_module
        session_id = str(uuid_module.uuid4())
        
        # ä»base_urlæå–host
        from urllib.parse import urlparse
        parsed_url = urlparse(base_url if base_url.startswith('http') else f"https://{base_url}")
        actual_host = parsed_url.netloc
        
        # æ„å»ºå®Œæ•´çš„Codex CLI headersï¼ˆæ¨¡æ‹ŸçœŸå®Codex CLIï¼‰
        headers = {
            "authorization": f"Bearer {config['key']}",
            "version": "0.42.0",
            "openai-beta": "responses=experimental",
            "conversation_id": session_id,
            "session_id": session_id,
            "accept": "text/event-stream",
            "content-type": "application/json",
            "user-agent": "codex_cli_rs/0.42.0 (Windows 10.0.19045; x86_64) unknown",
            "originator": "codex_cli_rs",
            "host": actual_host  # ä½¿ç”¨å®é™…çš„hostï¼Œè€Œä¸æ˜¯chatgpt.com
        }
        
        timeout_config = httpx.Timeout(
            connect=TimeoutConfig.get_connect_timeout(),
            read=30.0,
            write=TimeoutConfig.get_write_timeout(),
            pool=TimeoutConfig.get_pool_timeout()
        )

        resp = billing_client.post(url, json=payload, headers=headers, timeout=timeout_config)
        
        # æ‰“å°è¯¦ç»†çš„å“åº”ä¿¡æ¯
        print(f"[RESPONSE STATUS] {resp.status_code}")
        print(f"[RESPONSE HEADERS]")
        for key, value in resp.headers.items():
            print(f"  {key}: {value}")
        print(f"[RESPONSE BODY]")
        response_preview = resp.text[:1000] if len(resp.text) > 1000 else resp.text
        print(f"{response_preview}")
        if len(resp.text) > 1000:
            print(f"... (æ€»é•¿åº¦: {len(resp.text)} å­—ç¬¦)")
        print("=" * 80)
        
        if resp.status_code == 200:
            try:
                response_text = resp.text
                
                # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ç®€å•çš„successå“åº”ï¼ˆæŸäº›é…ç½®ä¸‹çš„æ¿€æ´»ç¡®è®¤ï¼‰
                try:
                    simple_json = json.loads(response_text)
                    if simple_json.get("success") == True:
                        print(f"[{datetime.now().strftime('%H:%M:%S')}] [OK] Codexæ­£å¸¸: {config['name']} (çŠ¶æ€ç : 200, æ¿€æ´»ç¡®è®¤: success=true)")
                        return True
                except (json.JSONDecodeError, ValueError):
                    pass
                
                # Codexè¿”å›æµå¼å“åº”ï¼Œéœ€è¦è§£æSSEæ ¼å¼
                has_content = False
                content_pieces = []
                
                for line in response_text.split('\n'):
                    if line.startswith('data: '):
                        data = line[6:]
                        if data == '[DONE]':
                            break
                        try:
                            event = json.loads(data)
                            # æ£€æŸ¥output_text.deltaäº‹ä»¶
                            if event.get("type") == "response.output_text.delta":
                                delta = event.get("delta", "")
                                if delta:
                                    content_pieces.append(delta)
                                    has_content = True
                        except json.JSONDecodeError:
                            continue
                
                if has_content:
                    content = ''.join(content_pieces)
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] [OK] Codexæ­£å¸¸: {config['name']} (çŠ¶æ€ç : 200, å†…å®¹é•¿åº¦: {len(content)})")
                    return True
                else:
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] [WARN] Codexå“åº”å¼‚å¸¸: {config['name']} - çŠ¶æ€ç 200ä½†å†…å®¹ä¸ºç©º")
                    return False
                    
            except Exception as parse_error:
                print(f"[{datetime.now().strftime('%H:%M:%S')}] [WARN] Codexå“åº”å¼‚å¸¸: {config['name']} - è§£æå¤±è´¥: {parse_error}")
                return False
        else:
            print(f"[{datetime.now().strftime('%H:%M:%S')}] [ERROR] Codexé”™è¯¯: {config['name']} - çŠ¶æ€ç : {resp.status_code}")
            return False
            
    except Exception as e:
        print(f"[{datetime.now().strftime('%H:%M:%S')}] [ERROR] Codexå¼‚å¸¸: {config['name']} - è¿æ¥é”™è¯¯: {e}")
        return False

def startup_api_health_check():
    """å¯åŠ¨æ—¶å¯¹æ‰€æœ‰APIè¿›è¡Œå¥åº·æ£€æŸ¥"""
    print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ” å¼€å§‹å¯åŠ¨æ—¶APIå¥åº·æ£€æŸ¥...")
    print("=" * 60)
    
    healthy_apis = []
    failed_apis = []
    
    # æ£€æŸ¥æ‰€æœ‰APIé…ç½®
    for i, config in enumerate(API_CONFIGS):
        print(f"[{datetime.now().strftime('%H:%M:%S')}] æ£€æŸ¥ {config['name']}...")
        
        is_healthy = send_billing_activation_message(i)
        if is_healthy:
            healthy_apis.append(config['name'])
        else:
            failed_apis.append(config['name'])
        
        time.sleep(TimeoutConfig.get_health_check_interval())  # ä»é…ç½®è¯»å–å¥åº·æ£€æŸ¥é—´éš”
    
    # æ€»ç»“æŠ¥å‘Š
    print("=" * 60)
    print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ“Š APIå¥åº·æ£€æŸ¥ç»“æœ:")
    
    if healthy_apis:
        print(f"âœ… å¥åº·API ({len(healthy_apis)}ä¸ª): {', '.join(healthy_apis)}")
    
    if failed_apis:
        print(f"âŒ æ•…éšœAPI ({len(failed_apis)}ä¸ª): {', '.join(failed_apis)}")
    
    if not failed_apis:
        print("ğŸ‰ æ‰€æœ‰APIè¿è¡Œæ­£å¸¸!")
    else:
        print(f"âš ï¸  {len(failed_apis)}/{len(API_CONFIGS)} APIå­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥")
    
    print("=" * 60)
    return len(healthy_apis), len(failed_apis)

# APIå®šæ—¶æ¿€æ´»çŠ¶æ€ç®¡ç†
api_activation_status = {}
codex_activation_status = {}

def init_activation_status():
    """åˆå§‹åŒ–APIæ¿€æ´»çŠ¶æ€"""
    return _init_activation_status_core(API_CONFIGS)

def init_codex_activation_status():
    """åˆå§‹åŒ–Codexæ¿€æ´»çŠ¶æ€"""
    return _init_activation_status_core(CODEX_CONFIGS)

def api_activation_scheduler():
    """APIå®šæ—¶æ¿€æ´»è°ƒåº¦å™¨ - æ¯åˆ†é’Ÿæ£€æŸ¥æ˜¯å¦éœ€è¦æ¿€æ´»ï¼Œå¤±è´¥åˆ™é‡è¯•æœ€å¤š20æ¬¡"""
    global api_activation_status, codex_activation_status
    print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ• APIå®šæ—¶æ¿€æ´»è°ƒåº¦å™¨å·²å¯åŠ¨ï¼ˆClaude + Codexï¼‰")
    
    last_check_date = None
    
    while True:
        try:
            now = datetime.now()
            current_date = now.date()
            current_time = now.strftime('%H:%M')
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„ä¸€å¤©ï¼Œå¦‚æœæ˜¯åˆ™é‡ç½®æ‰€æœ‰çŠ¶æ€
            if last_check_date != current_date:
                api_activation_status = init_activation_status()
                codex_activation_status = init_codex_activation_status()
                last_check_date = current_date
                if api_activation_status or codex_activation_status:
                    print(f"[{now.strftime('%H:%M:%S')}] ğŸ”„ æ–°çš„ä¸€å¤©ï¼Œé‡ç½®APIæ¿€æ´»çŠ¶æ€ï¼ˆClaude: {len(api_activation_status)}ä¸ª, Codex: {len(codex_activation_status)}ä¸ªï¼‰")
            
            # æ£€æŸ¥æ¯ä¸ªå¯ç”¨æ¿€æ´»çš„Claude API
            for i, config in enumerate(API_CONFIGS):
                if not config.get('activation_enabled', False):
                    continue
                
                activation_time = config.get('activation_time', '08:00')
                
                # ç¡®ä¿è¯¥APIæœ‰çŠ¶æ€è®°å½•
                if i not in api_activation_status:
                    api_activation_status[i] = {
                        "retry_count": 0,
                        "last_attempt_date": None,
                        "activated_today": False,
                        "last_attempt_time": None
                    }
                
                status = api_activation_status[i]
                
                # å¦‚æœä»Šå¤©å·²æˆåŠŸæ¿€æ´»ï¼Œè·³è¿‡
                if status['activated_today']:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾æ¿€æ´»æ—¶é—´æˆ–éœ€è¦é‡è¯•
                should_try = False
                
                # æƒ…å†µ1ï¼šåˆ°è¾¾æŒ‡å®šæ¿€æ´»æ—¶é—´ï¼Œä¸”ä»Šå¤©è¿˜æ²¡å°è¯•è¿‡
                if current_time == activation_time and status['last_attempt_date'] != current_date:
                    should_try = True
                    reason = "åˆ°è¾¾æ¿€æ´»æ—¶é—´"
                
                # æƒ…å†µ2ï¼šå·²ç»å°è¯•è¿‡ä½†å¤±è´¥ï¼Œéœ€è¦é‡è¯•ï¼ˆæ¯åˆ†é’Ÿé‡è¯•ä¸€æ¬¡ï¼‰
                elif (status['retry_count'] > 0 and 
                      status['retry_count'] < 20 and 
                      status['last_attempt_time'] is not None and
                      (now - status['last_attempt_time']).total_seconds() >= 60):
                    should_try = True
                    reason = f"é‡è¯•ç¬¬{status['retry_count']}æ¬¡"
                
                if should_try:
                    print(f"[{now.strftime('%H:%M:%S')}] ğŸ”” Claude APIæ¿€æ´»: {config['name']} - {reason}")
                    
                    # å‘é€æ¿€æ´»æ¶ˆæ¯
                    result = send_billing_activation_message(i)
                    status['last_attempt_time'] = now
                    status['last_attempt_date'] = current_date
                    
                    if result:
                        # æ¿€æ´»æˆåŠŸ
                        status['activated_today'] = True
                        status['retry_count'] = 0
                        
                        # è®¡ç®—ä¸‹æ¬¡æ¿€æ´»æ—¶é—´(æˆåŠŸæ—¶é—´+1åˆ†é’Ÿ)
                        next_activation_time = (now + timedelta(minutes=1)).strftime('%H:%M')
                        
                        # æ‰¾åˆ°å½“å‰é…ç½®åœ¨å…¨éƒ¨é…ç½®ä¸­çš„åŸå§‹ç´¢å¼•ï¼ˆé¿å…ç´¢å¼•é”™ä½ï¼‰
                        all_api_configs = config_mgr.get_api_configs()
                        original_index = None
                        for idx, cfg in enumerate(all_api_configs):
                            if cfg.get('name') == config.get('name'):
                                original_index = idx
                                break
                        
                        # åªæ›´æ–°æ¿€æ´»æ—¶é—´å­—æ®µ
                        if original_index is not None:
                            config_mgr.update_api_config(original_index, {'activation_time': next_activation_time})
                        
                        print(f"[{now.strftime('%H:%M:%S')}] âœ… Claude APIæ¿€æ´»æˆåŠŸ: {config['name']}")
                        print(f"[{now.strftime('%H:%M:%S')}] â° ä¸‹æ¬¡æ¿€æ´»æ—¶é—´å·²æ›´æ–°ä¸º: {next_activation_time}")
                    else:
                        # æ¿€æ´»å¤±è´¥ï¼Œå¢åŠ é‡è¯•è®¡æ•°
                        status['retry_count'] += 1
                        if status['retry_count'] >= 20:
                            print(f"[{now.strftime('%H:%M:%S')}] âŒ Claude APIæ¿€æ´»å¤±è´¥: {config['name']} - å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°(20æ¬¡)ï¼Œæ˜å¤©ç»§ç»­")
                        else:
                            print(f"[{now.strftime('%H:%M:%S')}] âš ï¸ Claude APIæ¿€æ´»å¤±è´¥: {config['name']} - 1åˆ†é’Ÿåé‡è¯• (å·²é‡è¯•{status['retry_count']}/20æ¬¡)")
                    
                    time.sleep(TimeoutConfig.get_billing_send_interval())
            
            # æ£€æŸ¥æ¯ä¸ªå¯ç”¨æ¿€æ´»çš„Codex API
            for i, config in enumerate(CODEX_CONFIGS):
                if not config.get('activation_enabled', False):
                    continue
                
                activation_time = config.get('activation_time', '08:00')
                
                # ç¡®ä¿è¯¥Codex APIæœ‰çŠ¶æ€è®°å½•
                if i not in codex_activation_status:
                    codex_activation_status[i] = {
                        "retry_count": 0,
                        "last_attempt_date": None,
                        "activated_today": False,
                        "last_attempt_time": None
                    }
                
                status = codex_activation_status[i]
                
                # å¦‚æœä»Šå¤©å·²æˆåŠŸæ¿€æ´»ï¼Œè·³è¿‡
                if status['activated_today']:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾æ¿€æ´»æ—¶é—´æˆ–éœ€è¦é‡è¯•
                should_try = False
                
                # æƒ…å†µ1ï¼šåˆ°è¾¾æŒ‡å®šæ¿€æ´»æ—¶é—´ï¼Œä¸”ä»Šå¤©è¿˜æ²¡å°è¯•è¿‡
                if current_time == activation_time and status['last_attempt_date'] != current_date:
                    should_try = True
                    reason = "åˆ°è¾¾æ¿€æ´»æ—¶é—´"
                
                # æƒ…å†µ2ï¼šå·²ç»å°è¯•è¿‡ä½†å¤±è´¥ï¼Œéœ€è¦é‡è¯•ï¼ˆæ¯åˆ†é’Ÿé‡è¯•ä¸€æ¬¡ï¼‰
                elif (status['retry_count'] > 0 and 
                      status['retry_count'] < 20 and 
                      status['last_attempt_time'] is not None and
                      (now - status['last_attempt_time']).total_seconds() >= 60):
                    should_try = True
                    reason = f"é‡è¯•ç¬¬{status['retry_count']}æ¬¡"
                
                if should_try:
                    print(f"[{now.strftime('%H:%M:%S')}] ğŸ”” Codex APIæ¿€æ´»: {config['name']} - {reason}")
                    
                    # å‘é€æ¿€æ´»æ¶ˆæ¯ï¼ˆä½¿ç”¨Codexçš„sendå‡½æ•°ï¼‰
                    result = send_codex_billing_activation_message(i)
                    status['last_attempt_time'] = now
                    status['last_attempt_date'] = current_date
                    
                    if result:
                        # æ¿€æ´»æˆåŠŸ
                        status['activated_today'] = True
                        status['retry_count'] = 0
                        
                        # è®¡ç®—ä¸‹æ¬¡æ¿€æ´»æ—¶é—´(æˆåŠŸæ—¶é—´+1åˆ†é’Ÿ)
                        next_activation_time = (now + timedelta(minutes=1)).strftime('%H:%M')
                        
                        # æ‰¾åˆ°å½“å‰é…ç½®åœ¨å…¨éƒ¨é…ç½®ä¸­çš„åŸå§‹ç´¢å¼•ï¼ˆé¿å…ç´¢å¼•é”™ä½ï¼‰
                        all_codex_configs = config_mgr.get_codex_configs()
                        original_index = None
                        for idx, cfg in enumerate(all_codex_configs):
                            if cfg.get('name') == config.get('name'):
                                original_index = idx
                                break
                        
                        # åªæ›´æ–°æ¿€æ´»æ—¶é—´å­—æ®µ
                        if original_index is not None:
                            config_mgr.update_codex_config(original_index, {'activation_time': next_activation_time})
                        
                        print(f"[{now.strftime('%H:%M:%S')}] âœ… Codex APIæ¿€æ´»æˆåŠŸ: {config['name']}")
                        print(f"[{now.strftime('%H:%M:%S')}] â° ä¸‹æ¬¡æ¿€æ´»æ—¶é—´å·²æ›´æ–°ä¸º: {next_activation_time}")
                    else:
                        # æ¿€æ´»å¤±è´¥ï¼Œå¢åŠ é‡è¯•è®¡æ•°
                        status['retry_count'] += 1
                        if status['retry_count'] >= 20:
                            print(f"[{now.strftime('%H:%M:%S')}] âŒ Codex APIæ¿€æ´»å¤±è´¥: {config['name']} - å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°(20æ¬¡)ï¼Œæ˜å¤©ç»§ç»­")
                        else:
                            print(f"[{now.strftime('%H:%M:%S')}] âš ï¸ Codex APIæ¿€æ´»å¤±è´¥: {config['name']} - 1åˆ†é’Ÿåé‡è¯• (å·²é‡è¯•{status['retry_count']}/20æ¬¡)")
                    
                    time.sleep(TimeoutConfig.get_billing_send_interval())
            
        except Exception as e:
            print(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ æ¿€æ´»è°ƒåº¦å™¨é”™è¯¯: {e}")
        
        # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
        time.sleep(60)

def billing_scheduler():
    """è®¡è´¹å‘¨æœŸè°ƒåº¦å™¨ - åœ¨4ã€5ã€6ã€9ã€10ã€11ç‚¹å‘é€å¯åŠ¨æ¶ˆæ¯"""
    print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ• è®¡è´¹è°ƒåº¦å™¨å·²å¯åŠ¨")
    
    while True:
        now = datetime.now()
        current_hour = now.hour
        current_minute = now.minute
        
        # æ£€æŸ¥æ˜¯å¦ä¸º4ã€5ã€6ã€9ã€10ã€11ç‚¹çš„ç¬¬0åˆ†é’Ÿ
        if (current_hour in [4, 5, 6, 9, 10, 11]) and current_minute == 0:
            print(f"[{now.strftime('%H:%M:%S')}] ğŸ”„ å¼€å§‹è®¡è´¹å‘¨æœŸå¯åŠ¨æ£€æŸ¥ ({current_hour}ç‚¹)")
            print("-" * 40)
            
            healthy_count = 0
            # å‘æ‰€æœ‰APIå‘é€å¯åŠ¨æ¶ˆæ¯ï¼ˆåŒ…æ‹¬å¤‡ç”¨APIï¼‰
            for i in range(len(API_CONFIGS)):
                result = send_billing_activation_message(i)
                if result:
                    healthy_count += 1
                time.sleep(TimeoutConfig.get_billing_send_interval())  # ä»é…ç½®è¯»å–è®¡è´¹å‘é€é—´éš”
            
            print("-" * 40)
            print(f"[{now.strftime('%H:%M:%S')}] âœ… è®¡è´¹å‘¨æœŸæ£€æŸ¥å®Œæˆ: {healthy_count}/{len(API_CONFIGS)} APIæ­£å¸¸")
            
            # ç­‰å¾…æŒ‡å®šç§’æ•°ï¼Œé¿å…åœ¨åŒä¸€åˆ†é’Ÿå†…é‡å¤å‘é€
            delay = TimeoutConfig.get_billing_cycle_delay()
            time.sleep(delay + 1)
        else:
            # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
            delay = TimeoutConfig.get_billing_cycle_delay()
            time.sleep(delay)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç† - å¯åŠ¨å’Œå…³é—­äº‹ä»¶å¤„ç†"""
    # å¯åŠ¨æ—¶æ‰§è¡Œ - å…ˆè¿›è¡ŒAPIå¥åº·æ£€æŸ¥
    print(f"[{datetime.now().strftime('%H:%M:%S')}] Claude Code API Server starting...")
    
    # ã€å·²æ³¨é‡Šã€‘æ‰§è¡Œå¯åŠ¨æ—¶APIå¥åº·æ£€æŸ¥
    # healthy_count, failed_count = startup_api_health_check()
    
    # ã€å·²æ³¨é‡Šã€‘å¯åŠ¨è®¡è´¹è°ƒåº¦å™¨
    # billing_thread = threading.Thread(target=billing_scheduler, daemon=True)
    # billing_thread.start()
    # print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ• è®¡è´¹ä¼˜åŒ–è°ƒåº¦å™¨å·²å¯åŠ¨ - å°†åœ¨æ¯å¤©4ã€5ã€6ã€9ã€10ã€11ç‚¹å‘é€è®¡è´¹å¯åŠ¨æ¶ˆæ¯")
    
    # å¯åŠ¨APIå®šæ—¶æ¿€æ´»è°ƒåº¦å™¨
    activation_thread = threading.Thread(target=api_activation_scheduler, daemon=True)
    activation_thread.start()
    print(f"[{datetime.now().strftime('%H:%M:%S')}] APIå®šæ—¶æ¿€æ´»è°ƒåº¦å™¨å·²å¯åŠ¨")
    
    print(f"[{datetime.now().strftime('%H:%M:%S')}] [OK] æœåŠ¡å™¨å¯åŠ¨å®Œæˆ")
    
    yield
    
    # å…³é—­æ—¶æ‰§è¡Œï¼ˆå¦‚æœéœ€è¦çš„è¯ï¼‰
    pass

app = FastAPI(lifespan=lifespan)

# é™æ€æ–‡ä»¶æœåŠ¡ - æä¾› chart.min.js
@app.get("/chart.min.js")
async def get_chart_js():
    """æä¾› Chart.js é™æ€æ–‡ä»¶"""
    chart_file = os.path.join(os.path.dirname(__file__), "chart.min.js")
    if os.path.exists(chart_file):
        return FileResponse(chart_file, media_type="application/javascript")
    return JSONResponse({"error": "Chart.js file not found"}, status_code=404)

# Webç®¡ç†APIç«¯ç‚¹
@app.get("/", response_class=HTMLResponse)
async def admin_page():
    html_file = os.path.join(os.path.dirname(__file__), "admin.html")
    if os.path.exists(html_file):
        with open(html_file, 'r', encoding='utf-8') as f:
            return f.read()
    return "<h1>ç®¡ç†é¡µé¢æœªæ‰¾åˆ°</h1>"

@app.get("/token-stats.html", response_class=HTMLResponse)
async def token_stats_page():
    """Tokenç»Ÿè®¡é¡µé¢"""
    html_file = os.path.join(os.path.dirname(__file__), "token_stats.html")
    if os.path.exists(html_file):
        with open(html_file, 'r', encoding='utf-8') as f:
            return f.read()
    return "<h1>ç»Ÿè®¡é¡µé¢æœªæ‰¾åˆ°</h1>"

@app.post("/api/token-stats/generate")
async def generate_token_stats():
    """
    ç”ŸæˆTokenç»Ÿè®¡æ•°æ®ï¼ˆå·²æ”¹ä¸ºå®æ—¶ç»Ÿè®¡æ¨¡å¼ï¼‰

    æ³¨æ„ï¼šç»Ÿè®¡åŠŸèƒ½å·²æ”¹ä¸ºå®æ—¶è®°å½•æ¨¡å¼ï¼Œæ— éœ€æ‰‹åŠ¨è§¦å‘ç”Ÿæˆã€‚
    æ¯æ¬¡APIè°ƒç”¨éƒ½ä¼šè‡ªåŠ¨è®°å½•usageæ•°æ®å¹¶æ›´æ–°token_stats.jsonæ–‡ä»¶ã€‚
    """
    return {
        "success": True,
        "message": "ç»Ÿè®¡åŠŸèƒ½å·²æ”¹ä¸ºå®æ—¶è®°å½•æ¨¡å¼ï¼Œæ•°æ®è‡ªåŠ¨æ›´æ–°",
        "note": "æ¯æ¬¡APIè°ƒç”¨éƒ½ä¼šè‡ªåŠ¨è®°å½•ï¼Œæ— éœ€æ‰‹åŠ¨åˆ·æ–°"
    }

@app.get("/api/token-stats")
async def get_token_stats():
    """è·å–Tokenç»Ÿè®¡æ•°æ®ï¼ˆå®æ—¶ç»Ÿè®¡æ¨¡å¼ï¼‰"""
    try:
        stats_file = os.path.join(os.path.dirname(__file__), "json_data", "token_stats.json")

        if not os.path.exists(stats_file):
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›ç©ºç»Ÿè®¡æ•°æ®ç»“æ„
            return {
                "summary": {
                    "total_requests": 0,
                    "total_tokens": 0,
                    "total_input_tokens": 0,
                    "total_output_tokens": 0,
                    "total_cache_creation_tokens": 0,
                    "total_cache_read_tokens": 0,
                    "unique_models": []
                },
                "by_model": {},
                "daily": {},
                "generated_at": "æœªç”Ÿæˆï¼ˆç­‰å¾…é¦–æ¬¡APIè°ƒç”¨ï¼‰"
            }

        with open(stats_file, 'r', encoding='utf-8') as f:
            stats_data = json.load(f)

        return stats_data
    except Exception as e:
        return {"error": f"è¯»å–ç»Ÿè®¡æ•°æ®å¤±è´¥: {str(e)}"}

@app.post("/api/token-stats/reset")
async def reset_token_stats():
    """é‡ç½®/æ¸…ç©ºTokenç»Ÿè®¡æ•°æ®"""
    try:
        stats_file = os.path.join(os.path.dirname(__file__), "json_data", "token_stats.json")

        if os.path.exists(stats_file):
            os.remove(stats_file)
            return {"success": True, "message": "ç»Ÿè®¡æ•°æ®å·²æ¸…ç©º"}
        else:
            return {"success": True, "message": "ç»Ÿè®¡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç©º"}
    except Exception as e:
        return {"success": False, "message": f"æ¸…ç©ºå¤±è´¥: {str(e)}"}

# ========== APIé…ç½®ç®¡ç†ç«¯ç‚¹ ==========
@app.get("/api/configs")
async def get_api_configs():
    return {"configs": config_mgr.get_api_configs()}

@app.post("/api/configs")
async def add_api_config(config: dict):
    success = config_mgr.add_api_config(config)
    if success:
        refresh_api_runtime_state(reset_backup_state=True)
        return {"success": True, "message": "é…ç½®å·²æ·»åŠ "}
    return {"success": False, "message": "é…ç½®æ·»åŠ å¤±è´¥"}

@app.put("/api/configs/{index}")
async def update_api_config(index: int, config: dict):
    success = config_mgr.update_api_config(index, config)
    if success:
        refresh_api_runtime_state()
        return {"success": True, "message": "é…ç½®å·²æ›´æ–°"}
    return {"success": False, "message": "é…ç½®æ›´æ–°å¤±è´¥"}

@app.delete("/api/configs/{index}")
async def delete_api_config(index: int):
    success = config_mgr.delete_api_config(index)
    if success:
        refresh_api_runtime_state(reset_backup_state=True)
        return {"success": True, "message": "é…ç½®å·²åˆ é™¤"}
    return {"success": False, "message": "é…ç½®åˆ é™¤å¤±è´¥"}

@app.post("/api/configs/{index}/toggle")
async def toggle_api_config(index: int):
    enabled = config_mgr.toggle_api_config(index)
    if enabled is not None:
        refresh_api_runtime_state(reset_backup_state=not enabled)
        return {"success": True, "enabled": enabled, "message": f"é…ç½®å·²{'å¯ç”¨' if enabled else 'ç¦ç”¨'}"}
    return {"success": False, "message": "åˆ‡æ¢å¤±è´¥"}

@app.post("/api/configs/{index}/move")
async def move_api_config(index: int, direction: dict):
    success = config_mgr.move_api_config(index, direction.get("direction"))
    if success:
        refresh_api_runtime_state()
        return {"success": True, "message": "é…ç½®å·²ç§»åŠ¨"}
    return {"success": False, "message": "é…ç½®ç§»åŠ¨å¤±è´¥"}

@app.post("/api/configs/{index}/duplicate")
async def duplicate_api_config(index: int):
    success = config_mgr.duplicate_api_config(index)
    if success:
        refresh_api_runtime_state()
        return {"success": True, "message": "é…ç½®å·²å¤åˆ¶"}
    return {"success": False, "message": "é…ç½®å¤åˆ¶å¤±è´¥"}

# ========== Codexé…ç½®ç®¡ç†ç«¯ç‚¹ ==========
@app.get("/api/codex")
async def get_codex_configs():
    return {"configs": config_mgr.get_codex_configs()}

@app.post("/api/codex")
async def add_codex_config(config: dict):
    success = config_mgr.add_codex_config(config)
    if success:
        refresh_codex_runtime_state(reset_backup_state=True)
        return {"success": True, "message": "Codexé…ç½®å·²æ·»åŠ "}
    return {"success": False, "message": "Codexé…ç½®æ·»åŠ å¤±è´¥"}

@app.put("/api/codex/{index}")
async def update_codex_config(index: int, config: dict):
    success = config_mgr.update_codex_config(index, config)
    if success:
        refresh_codex_runtime_state()
        return {"success": True, "message": "Codexé…ç½®å·²æ›´æ–°"}
    return {"success": False, "message": "Codexé…ç½®æ›´æ–°å¤±è´¥"}

@app.delete("/api/codex/{index}")
async def delete_codex_config(index: int):
    success = config_mgr.delete_codex_config(index)
    if success:
        refresh_codex_runtime_state(reset_backup_state=True)
        return {"success": True, "message": "Codexé…ç½®å·²åˆ é™¤"}
    return {"success": False, "message": "Codexé…ç½®åˆ é™¤å¤±è´¥"}

@app.post("/api/codex/{index}/toggle")
async def toggle_codex_config(index: int):
    enabled = config_mgr.toggle_codex_config(index)
    if enabled is not None:
        refresh_codex_runtime_state(reset_backup_state=not enabled)
        return {"success": True, "enabled": enabled, "message": f"Codexé…ç½®å·²{'å¯ç”¨' if enabled else 'ç¦ç”¨'}"}
    return {"success": False, "message": "åˆ‡æ¢å¤±è´¥"}

@app.post("/api/codex/{index}/move")
async def move_codex_config(index: int, direction: dict):
    success = config_mgr.move_codex_config(index, direction.get("direction"))
    if success:
        refresh_codex_runtime_state()
        return {"success": True, "message": "Codexé…ç½®å·²ç§»åŠ¨"}
    return {"success": False, "message": "Codexé…ç½®ç§»åŠ¨å¤±è´¥"}

@app.post("/api/codex/{index}/duplicate")
async def duplicate_codex_config(index: int):
    success = config_mgr.duplicate_codex_config(index)
    if success:
        refresh_codex_runtime_state()
        return {"success": True, "message": "Codexé…ç½®å·²å¤åˆ¶"}
    return {"success": False, "message": "Codexé…ç½®å¤åˆ¶å¤±è´¥"}

# ========== OpenAIè½¬Claudeé…ç½®ç®¡ç†ç«¯ç‚¹ ==========
@app.get("/api/openai-to-claude")
async def get_openai_to_claude():
    return {"configs": config_mgr.get_openai_to_claude_configs()}


@app.post("/api/openai-to-claude")
async def add_openai_to_claude(config: dict):
    success = config_mgr.add_openai_to_claude_config(config)
    if success:
        refresh_openai_runtime_state()
        return {"success": True, "message": "OpenAIè½¬Claudeé…ç½®å·²æ·»åŠ "}
    return {"success": False, "message": "OpenAIè½¬Claudeé…ç½®æ·»åŠ å¤±è´¥"}


@app.put("/api/openai-to-claude/{index}")
async def update_openai_to_claude(index: int, config: dict):
    success = config_mgr.update_openai_to_claude_config(index, config)
    if success:
        refresh_openai_runtime_state()
        return {"success": True, "message": "OpenAIè½¬Claudeé…ç½®å·²æ›´æ–°"}
    return {"success": False, "message": "OpenAIè½¬Claudeé…ç½®æ›´æ–°å¤±è´¥"}


@app.delete("/api/openai-to-claude/{index}")
async def delete_openai_to_claude(index: int):
    success = config_mgr.delete_openai_to_claude_config(index)
    if success:
        refresh_openai_runtime_state()
        return {"success": True, "message": "OpenAIè½¬Claudeé…ç½®å·²åˆ é™¤"}
    return {"success": False, "message": "OpenAIè½¬Claudeé…ç½®åˆ é™¤å¤±è´¥"}


@app.post("/api/openai-to-claude/{index}/toggle")
async def toggle_openai_to_claude(index: int):
    result = config_mgr.toggle_openai_to_claude_config(index)
    if result is not None:
        refresh_openai_runtime_state()
        status_text = "å¯ç”¨" if result else "ç¦ç”¨"
        return {"success": True, "message": f"OpenAIè½¬Claudeé…ç½®å·²{status_text}"}
    return {"success": False, "message": "OpenAIè½¬Claudeé…ç½®åˆ‡æ¢å¤±è´¥"}


@app.post("/api/openai-to-claude/{index}/move")
async def move_openai_to_claude(index: int, payload: dict):
    direction = payload.get("direction")
    success = config_mgr.move_openai_to_claude_config(index, direction)
    if success:
        refresh_openai_runtime_state()
        return {"success": True, "message": "OpenAIè½¬Claudeé…ç½®å·²ç§»åŠ¨"}
    return {"success": False, "message": "OpenAIè½¬Claudeé…ç½®ç§»åŠ¨å¤±è´¥"}

@app.post("/api/openai-to-claude/{index}/duplicate")
async def duplicate_openai_to_claude_config(index: int):
    success = config_mgr.duplicate_openai_to_claude_config(index)
    if success:
        refresh_openai_runtime_state()
        return {"success": True, "message": "OpenAIè½¬Claudeé…ç½®å·²å¤åˆ¶"}
    return {"success": False, "message": "OpenAIè½¬Claudeé…ç½®å¤åˆ¶å¤±è´¥"}

# ========== è¶…æ—¶é‡è¯•é…ç½®ç®¡ç†ç«¯ç‚¹ ==========
@app.get("/api/retry")
async def get_retry_configs():
    return {"configs": config_mgr.get_retry_configs()}

@app.post("/api/retry")
async def add_retry_config(config: dict):
    success = config_mgr.add_retry_config(config)
    if success:
        refresh_retry_configs()
        return {"success": True, "message": "é‡è¯•é…ç½®å·²æ·»åŠ "}
    return {"success": False, "message": "é‡è¯•é…ç½®æ·»åŠ å¤±è´¥"}

@app.put("/api/retry/{index}")
async def update_retry_config(index: int, config: dict):
    success = config_mgr.update_retry_config(index, config)
    if success:
        refresh_retry_configs()
        return {"success": True, "message": "é‡è¯•é…ç½®å·²æ›´æ–°"}
    return {"success": False, "message": "é‡è¯•é…ç½®æ›´æ–°å¤±è´¥"}

@app.delete("/api/retry/{index}")
async def delete_retry_config(index: int):
    success = config_mgr.delete_retry_config(index)
    if success:
        refresh_retry_configs()
        return {"success": True, "message": "é‡è¯•é…ç½®å·²åˆ é™¤"}
    return {"success": False, "message": "é‡è¯•é…ç½®åˆ é™¤å¤±è´¥"}

@app.post("/api/retry/{index}/toggle")
async def toggle_retry_config(index: int):
    enabled = config_mgr.toggle_retry_config(index)
    if enabled is not None:
        refresh_retry_configs()
        return {"success": True, "enabled": enabled, "message": f"é‡è¯•é…ç½®å·²{'å¯ç”¨' if enabled else 'ç¦ç”¨'}"}
    return {"success": False, "message": "åˆ‡æ¢å¤±è´¥"}

@app.post("/api/retry/{index}/move")
async def move_retry_config(index: int, direction: dict):
    success = config_mgr.move_retry_config(index, direction.get("direction"))
    if success:
        refresh_retry_configs()
        return {"success": True, "message": "é‡è¯•é…ç½®å·²ç§»åŠ¨"}
    return {"success": False, "message": "é‡è¯•é…ç½®ç§»åŠ¨å¤±è´¥"}

@app.post("/api/retry/{index}/duplicate")
async def duplicate_retry_config(index: int):
    success = config_mgr.duplicate_retry_config(index)
    if success:
        refresh_retry_configs()
        return {"success": True, "message": "é‡è¯•é…ç½®å·²å¤åˆ¶"}
    return {"success": False, "message": "é‡è¯•é…ç½®å¤åˆ¶å¤±è´¥"}

# ========== æ¨¡å‹è½¬æ¢é…ç½®ç®¡ç†ç«¯ç‚¹ ==========
@app.get("/api/model-conversion")
async def get_model_conversions():
    return {"configs": config_mgr.get_model_conversions()}

@app.post("/api/model-conversion")
async def add_model_conversion(config: dict):
    success = config_mgr.add_model_conversion(config)
    if success:
        refresh_model_conversion_state()
        return {"success": True, "message": "æ¨¡å‹è½¬æ¢é…ç½®å·²æ·»åŠ "}
    return {"success": False, "message": "æ¨¡å‹è½¬æ¢é…ç½®æ·»åŠ å¤±è´¥"}

@app.put("/api/model-conversion/{index}")
async def update_model_conversion(index: int, config: dict):
    success = config_mgr.update_model_conversion(index, config)
    if success:
        refresh_model_conversion_state()
        return {"success": True, "message": "æ¨¡å‹è½¬æ¢é…ç½®å·²æ›´æ–°"}
    return {"success": False, "message": "æ¨¡å‹è½¬æ¢é…ç½®æ›´æ–°å¤±è´¥"}

@app.delete("/api/model-conversion/{index}")
async def delete_model_conversion(index: int):
    success = config_mgr.delete_model_conversion(index)
    if success:
        refresh_model_conversion_state()
        return {"success": True, "message": "æ¨¡å‹è½¬æ¢é…ç½®å·²åˆ é™¤"}
    return {"success": False, "message": "æ¨¡å‹è½¬æ¢é…ç½®åˆ é™¤å¤±è´¥"}

@app.post("/api/model-conversion/{index}/toggle")
async def toggle_model_conversion(index: int):
    enabled = config_mgr.toggle_model_conversion(index)
    if enabled is not None:
        refresh_model_conversion_state()
        return {"success": True, "enabled": enabled, "message": f"æ¨¡å‹è½¬æ¢é…ç½®å·²{'å¯ç”¨' if enabled else 'ç¦ç”¨'}"}
    return {"success": False, "message": "åˆ‡æ¢å¤±è´¥"}

@app.post("/api/model-conversion/{index}/move")
async def move_model_conversion(index: int, direction: dict):
    success = config_mgr.move_model_conversion(index, direction.get("direction"))
    if success:
        refresh_model_conversion_state()
        return {"success": True, "message": "æ¨¡å‹è½¬æ¢é…ç½®å·²ç§»åŠ¨"}
    return {"success": False, "message": "æ¨¡å‹è½¬æ¢é…ç½®ç§»åŠ¨å¤±è´¥"}

# ========== é”™è¯¯å¤„ç†ç­–ç•¥ç®¡ç†ç«¯ç‚¹ ==========
@app.get("/api/error-strategies")
async def get_error_strategies():
    """è·å–é”™è¯¯å¤„ç†ç­–ç•¥é…ç½®"""
    return {"strategies": config_mgr.get_error_handling_strategies()}

@app.put("/api/error-strategies")
async def update_error_strategies(strategies: dict):
    """æ›´æ–°é”™è¯¯å¤„ç†ç­–ç•¥é…ç½®"""
    success = config_mgr.update_error_handling_strategies(strategies)
    if success:
        return {"success": True, "message": "é”™è¯¯å¤„ç†ç­–ç•¥å·²æ›´æ–°"}
    return {"success": False, "message": "é”™è¯¯å¤„ç†ç­–ç•¥æ›´æ–°å¤±è´¥"}


@app.post("/api/model-conversion/{index}/duplicate")
async def duplicate_model_conversion(index: int):
    success = config_mgr.duplicate_model_conversion(index)
    if success:
        refresh_model_conversion_state()
        return {"success": True, "message": "æ¨¡å‹è½¬æ¢é…ç½®å·²å¤åˆ¶"}
    return {"success": False, "message": "æ¨¡å‹è½¬æ¢é…ç½®å¤åˆ¶å¤±è´¥"}

# ========== è¶…æ—¶è®¾ç½®ç®¡ç†ç«¯ç‚¹ ==========
@app.get("/api/timeout")
async def get_timeout_settings():
    return {"settings": config_mgr.get_timeout_settings()}

@app.put("/api/timeout")
async def update_timeout_settings(settings: dict):
    success = config_mgr.update_timeout_settings(settings)
    if success:
        # åˆ·æ–°å…¨å±€HTTPå®¢æˆ·ç«¯ï¼Œä½¿è¶…æ—¶è®¾ç½®ç«‹å³ç”Ÿæ•ˆ
        await refresh_timeout_client()
        return {"success": True, "message": "è¶…æ—¶è®¾ç½®å·²æ›´æ–°"}
    return {"success": False, "message": "è¶…æ—¶è®¾ç½®æ›´æ–°å¤±è´¥"}

# ========== ä¼˜åŒ–è®¾ç½®ç«¯ç‚¹ ==========
@app.get("/api/optimization")
async def get_optimization_settings():
    return {"settings": config_mgr.get_optimization_settings()}

@app.put("/api/optimization")
async def update_optimization_settings(settings: dict):
    success = config_mgr.update_optimization_settings(settings)
    if success:
        return {"success": True, "message": "ä¼˜åŒ–è®¾ç½®å·²æ›´æ–°"}
    return {"success": False, "message": "ä¼˜åŒ–è®¾ç½®æ›´æ–°å¤±è´¥"}

# ========== é‡ç½®å†·å´ç«¯ç‚¹ ==========
@app.post("/api/reset-api-cooldown")
async def reset_api_cooldown(data: dict = None):
    """é‡ç½®APIå†·å´çŠ¶æ€"""
    global api_status
    now = datetime.now()
    
    if data and "index" in data:
        # é‡ç½®å•ä¸ªAPIçš„å†·å´
        index = data["index"]
        if 0 <= index < len(API_CONFIGS):
            if index in api_status and api_status[index]["cooldown_until"]:
                api_status[index] = {"status": "normal", "error_count": 0, "cooldown_until": None}
                api_name = API_CONFIGS[index]['name']
                print(f"[{now.strftime('%H:%M:%S')}] æ‰‹åŠ¨é‡ç½®APIå†·å´: {api_name}")
                return {"success": True, "message": f"å·²é‡ç½® {api_name} çš„å†·å´çŠ¶æ€"}
            else:
                return {"success": False, "message": f"API {API_CONFIGS[index]['name']} æœªå¤„äºå†·å´çŠ¶æ€"}
        return {"success": False, "message": "æ— æ•ˆçš„APIç´¢å¼•"}
    else:
        # é‡ç½®æ‰€æœ‰APIçš„å†·å´
        reset_count = 0
        reset_names = []
        for i in range(len(API_CONFIGS)):
            if i in api_status and api_status[i]["cooldown_until"]:
                api_status[i] = {"status": "normal", "error_count": 0, "cooldown_until": None}
                reset_names.append(API_CONFIGS[i]['name'])
                reset_count += 1
        
        if reset_count > 0:
            print(f"[{now.strftime('%H:%M:%S')}] æ‰‹åŠ¨é‡ç½®æ‰€æœ‰APIå†·å´: {', '.join(reset_names)}")
            return {"success": True, "message": f"å·²é‡ç½® {reset_count} ä¸ªAPIçš„å†·å´çŠ¶æ€"}
        else:
            return {"success": False, "message": "æ²¡æœ‰APIå¤„äºå†·å´çŠ¶æ€"}

@app.post("/api/reset-codex-cooldown")
async def reset_codex_cooldown(data: dict = None):
    """é‡ç½®Codexå†·å´çŠ¶æ€"""
    global codex_api_status
    now = datetime.now()
    
    if data and "index" in data:
        # é‡ç½®å•ä¸ªCodexçš„å†·å´
        index = data["index"]
        if 0 <= index < len(CODEX_CONFIGS):
            if index in codex_api_status and codex_api_status[index]["cooldown_until"]:
                codex_api_status[index] = {"status": "normal", "error_count": 0, "cooldown_until": None}
                codex_name = CODEX_CONFIGS[index]['name']
                print(f"[{now.strftime('%H:%M:%S')}] æ‰‹åŠ¨é‡ç½®Codexå†·å´: {codex_name}")
                return {"success": True, "message": f"å·²é‡ç½® {codex_name} çš„å†·å´çŠ¶æ€"}
            else:
                return {"success": False, "message": f"Codex {CODEX_CONFIGS[index]['name']} æœªå¤„äºå†·å´çŠ¶æ€"}
        return {"success": False, "message": "æ— æ•ˆçš„Codexç´¢å¼•"}
    else:
        # é‡ç½®æ‰€æœ‰Codexçš„å†·å´
        reset_count = 0
        reset_names = []
        for i in range(len(CODEX_CONFIGS)):
            if i in codex_api_status and codex_api_status[i]["cooldown_until"]:
                codex_api_status[i] = {"status": "normal", "error_count": 0, "cooldown_until": None}
                reset_names.append(CODEX_CONFIGS[i]['name'])
                reset_count += 1
        
        if reset_count > 0:
            print(f"[{now.strftime('%H:%M:%S')}] æ‰‹åŠ¨é‡ç½®æ‰€æœ‰Codexå†·å´: {', '.join(reset_names)}")
            return {"success": True, "message": f"å·²é‡ç½® {reset_count} ä¸ªCodexçš„å†·å´çŠ¶æ€"}
        else:
            return {"success": False, "message": "æ²¡æœ‰Codexå¤„äºå†·å´çŠ¶æ€"}

# ========== é…ç½®é‡æ–°åŠ è½½ç«¯ç‚¹ ==========

@app.post("/api/reload")
async def reload_configs():
    """é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶ï¼ˆç”¨äºæ‰‹åŠ¨ä¿®æ”¹é…ç½®ååŒæ­¥ï¼‰"""
    previous_snapshot = {
        "api": copy.deepcopy(config_mgr.get_api_configs()),
        "codex": copy.deepcopy(config_mgr.get_codex_configs()),
        "openai": copy.deepcopy(config_mgr.get_openai_to_claude_configs()),
        "retry": copy.deepcopy(config_mgr.get_retry_configs()),
        "model": copy.deepcopy(config_mgr.get_model_conversions()),
    }

    success = config_mgr.reload_all_configs()
    if success:
        now = datetime.now()
        latest_snapshot = {
            "api": config_mgr.get_api_configs(),
            "codex": config_mgr.get_codex_configs(),
            "openai": config_mgr.get_openai_to_claude_configs(),
            "retry": config_mgr.get_retry_configs(),
            "model": config_mgr.get_model_conversions(),
        }

        changed_sections = {key: previous_snapshot[key] != latest_snapshot[key] for key in previous_snapshot}
        if not any(changed_sections.values()):
            # ä¸æ˜¾ç¤ºæ— å˜åŒ–çš„æ—¥å¿—
            return {"success": True, "message": "é…ç½®æœªå˜åŒ–ï¼Œæ— éœ€é‡æ–°åŠ è½½"}

        if changed_sections["api"]:
            refresh_api_runtime_state(reset_backup_state=True)
        if changed_sections["codex"]:
            refresh_codex_runtime_state(reset_backup_state=True)
        if changed_sections["openai"]:
            refresh_openai_runtime_state()
        if changed_sections["retry"]:
            refresh_retry_configs()
        if changed_sections["model"]:
            refresh_model_conversion_state()

        section_labels = {
            "api": "APIä¸»é…ç½®",
            "codex": "Codexé…ç½®",
            "openai": "OpenAIè½¬Claude",
            "retry": "è¶…æ—¶é‡è¯•é…ç½®",
            "model": "æ¨¡å‹è½¬æ¢é…ç½®",
        }
        updated_sections = [label for key, label in section_labels.items() if changed_sections.get(key)]
        sections_text = "ã€".join(updated_sections)

        api_index_info = current_config_index if current_config_index is not None and current_config_index >= 0 else "-"
        codex_index_info = codex_current_config_index if 'codex_current_config_index' in globals() and codex_current_config_index is not None and codex_current_config_index >= 0 else "-"
        print(f"[{now.strftime('%H:%M:%S')}] é…ç½®é‡æ–°åŠ è½½ï¼šæ›´æ–°é¡¹={sections_text}ï¼›ä¸»APIç´¢å¼•={api_index_info}ï¼ŒCodexç´¢å¼•={codex_index_info}")

        return {"success": True, "message": f"å·²åˆ·æ–°ï¼š{sections_text}"}
    return {"success": False, "message": "é…ç½®é‡æ–°åŠ è½½å¤±è´¥"}


# ========== cache_control æ•°é‡é™åˆ¶å‡½æ•° ==========
def limit_cache_control_blocks(request_data: Dict[str, Any], max_blocks: int = 4) -> Dict[str, Any]:
    """
    é™åˆ¶è¯·æ±‚ä¸­ cache_control å—çš„æ•°é‡ï¼Œé¿å…è¶…è¿‡ Claude API çš„é™åˆ¶

    Args:
        request_data: è¯·æ±‚æ•°æ®
        max_blocks: æœ€å¤§å…è®¸çš„ cache_control å—æ•°é‡ï¼ˆé»˜è®¤ 4ï¼‰

    Returns:
        ä¿®å¤åçš„è¯·æ±‚æ•°æ®
    """
    try:
        import copy
        fixed_request = copy.deepcopy(request_data)
        cache_control_count = 0

        # ç»Ÿè®¡å¹¶é™åˆ¶ system ä¸­çš„ cache_control
        system_items = fixed_request.get("system", [])
        if system_items:
            fixed_system = []
            for item in system_items:
                if isinstance(item, dict) and "cache_control" in item:
                    if cache_control_count < max_blocks:
                        # ä¿ç•™ cache_control
                        fixed_system.append(item)
                        cache_control_count += 1
                    else:
                        # ç§»é™¤ cache_control
                        item_copy = item.copy()
                        del item_copy["cache_control"]
                        fixed_system.append(item_copy)
                        print(f"[cache_controlé™åˆ¶] ç§»é™¤systemä¸­ç¬¬{cache_control_count + 1}ä¸ªcache_control", file=sys.stderr)
                else:
                    fixed_system.append(item)
            fixed_request["system"] = fixed_system

        # ç»Ÿè®¡å¹¶é™åˆ¶ messages ä¸­çš„ cache_control
        messages = fixed_request.get("messages", [])
        if messages:
            fixed_messages = []
            for msg in messages:
                if isinstance(msg, dict):
                    msg_copy = msg.copy()
                    content = msg_copy.get("content", [])

                    # å¤„ç†åˆ—è¡¨æ ¼å¼çš„ content
                    if isinstance(content, list):
                        fixed_content = []
                        for item in content:
                            if isinstance(item, dict) and "cache_control" in item:
                                if cache_control_count < max_blocks:
                                    fixed_content.append(item)
                                    cache_control_count += 1
                                else:
                                    item_copy = item.copy()
                                    del item_copy["cache_control"]
                                    fixed_content.append(item_copy)
                                    print(f"[cache_controlé™åˆ¶] ç§»é™¤messagesä¸­ç¬¬{cache_control_count + 1}ä¸ªcache_control", file=sys.stderr)
                            else:
                                fixed_content.append(item)
                        msg_copy["content"] = fixed_content

                    fixed_messages.append(msg_copy)
                else:
                    fixed_messages.append(msg)
            fixed_request["messages"] = fixed_messages

        if cache_control_count > max_blocks:
            print(f"[cache_controlé™åˆ¶] æ£€æµ‹åˆ°{cache_control_count}ä¸ªcache_controlå—ï¼Œå·²é™åˆ¶ä¸º{max_blocks}ä¸ª", file=sys.stderr)

        return fixed_request
    except Exception as e:
        print(f"[cache_controlé™åˆ¶] å¤„ç†å¤±è´¥: {e}", file=sys.stderr)
        return request_data  # å‡ºé”™æ—¶è¿”å›åŸå§‹æ•°æ®


# åœ¨åˆå§‹åŒ–å®¢æˆ·ç«¯æ—¶ï¼Œæˆ‘ä»¬ä¸è®¾ç½® base_urlï¼Œä»¥ä¾¿åœ¨è¯·æ±‚æ—¶æ„å»ºå®Œæ•´çš„ URL

# é¢„å®šä¹‰çš„è¶…æ—¶é…ç½®å¯¹è±¡
timeout = TimeoutConfig.get_streaming_timeout()
non_streaming_timeout = TimeoutConfig.get_non_streaming_timeout()

# ç¦ç”¨è¿æ¥å¤ç”¨ï¼Œé¿å…å¼‚å¸¸è¿æ¥å½±å“åç»­è¯·æ±‚
limits = httpx.Limits(max_keepalive_connections=0, max_connections=100)
client = httpx.AsyncClient(timeout=timeout, limits=limits)

@app.api_route("/{path:path}", methods=["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS"])
async def reverse_proxy(request: Request, path: str):
    """
    ä¸€ä¸ªé«˜ä¿çœŸå¼‚æ­¥åå‘ä»£ç†ï¼Œæ”¯æŒOpenAIåˆ°Claudeæ ¼å¼çš„è‡ªåŠ¨è½¬æ¢ã€‚
    æ ¸å¿ƒç‰¹æ€§æ˜¯"ç»å¯¹é€ä¼ "å“åº”å¤´ï¼Œä»¥åº”å¯¹å…·æœ‰éæ ‡å‡†å¤´ä¾èµ–çš„å®¢æˆ·ç«¯ã€‚
    """
    # è·³è¿‡éAPIè·¯å¾„çš„è¯·æ±‚ï¼ˆæµè§ˆå™¨è‡ªåŠ¨è¯·æ±‚çš„èµ„æºï¼‰
    skip_paths = ['favicon.ico', 'robots.txt', 'sitemap.xml', 'apple-touch-icon', '.well-known']
    if any(skip_path in path for skip_path in skip_paths):
        return JSONResponse(content={"error": "Not Found"}, status_code=404)
    
    # ç”Ÿæˆè¯·æ±‚IDç”¨äºæ—¥å¿—è·Ÿè¸ª
    request_id = f"{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
    
    # å£°æ˜å…¨å±€å˜é‡ï¼ˆCodexè‡ªé€‚åº”è¶…æ—¶ï¼‰
    global codex_timeout_extra_seconds, codex_success_count

    # 1. è¯»å–åŸå§‹è¯·æ±‚ä½“
    body = await request.body()

    # è·¯å¾„å½’ä¸€åŒ–ä¸Codexç›´è¿è¯†åˆ«
    normalized_path = path.lstrip('/')
    is_codex_request = normalized_path == CODEX_PATH_PREFIX or normalized_path.startswith(f"{CODEX_PATH_PREFIX}/")
    base_url_override = get_current_codex_config()["base_url"] if is_codex_request else None

    # ç®€åŒ–æ—¥å¿—è®°å½•ï¼šä»…è®°å½•åŸºæœ¬ä¿¡æ¯å’Œç”¨æˆ·æ¨¡å‹
    if ENABLE_FULL_LOG and full_logger:
        try:
            full_logger.info("="*40)
            full_logger.info(f"è¯·æ±‚ - ID: {request_id}")
            # è®°å½•ç”¨æˆ·è¾“å…¥çš„æ¨¡å‹ä¿¡æ¯å’Œé—®é¢˜å†…å®¹
            if body and request.method == "POST":
                try:
                    request_data = json.loads(body.decode('utf-8'))
                    user_model = request_data.get("model", "unknown")
                    full_logger.info(f"ç”¨æˆ·ä½¿ç”¨æ¨¡å‹: {user_model}")
                    
                    # è®°å½•ç”¨æˆ·å‘å‡ºçš„é—®é¢˜å†…å®¹
                    messages = request_data.get("messages", [])
                    if messages:
                        # æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
                        for message in reversed(messages):
                            if message.get("role") == "user":
                                content = message.get("content", "")
                                if isinstance(content, str):
                                    full_logger.info(f"ç”¨æˆ·é—®é¢˜: {content}")
                                elif isinstance(content, list):
                                    # å¤„ç†å¤šæ¨¡æ€å†…å®¹
                                    text_parts = []
                                    for part in content:
                                        if isinstance(part, dict) and part.get("type") == "text":
                                            text_parts.append(part.get("text", ""))
                                    if text_parts:
                                        full_logger.info(f"ç”¨æˆ·é—®é¢˜: {' '.join(text_parts)}")
                                break
                except:
                    pass
        except Exception as log_error:
            print(f"è®°å½•è¯·æ±‚æ—¥å¿—æ—¶å‡ºé”™: {log_error}", file=sys.stderr)
    
    # 2. éªŒè¯ç”¨æˆ·Keyå¹¶æ›¿æ¢ä¸ºçœŸæ­£çš„API Key
    user_auth_header = request.headers.get('authorization')
    is_valid, real_auth_header, error_msg = validate_and_replace_user_key(user_auth_header)
    
    if not is_valid:
        print(f"KeyéªŒè¯å¤±è´¥: {error_msg}", file=sys.stderr)
        error_response = {
            "error": {
                "message": error_msg,
                "type": "authentication_error", 
                "code": "invalid_api_key"
            }
        }
        return JSONResponse(
            content=error_response,
            status_code=401,
            headers={"content-type": "application/json"}
        )

    # æå‰æ£€æµ‹æ˜¯å¦ä¸ºOpenAIå®¢æˆ·ç«¯ï¼ˆç”¨äºæ­£ç¡®æ˜¾ç¤ºAPIä¿¡æ¯ï¼‰
    is_openai_client_early = (path == "v1/chat/completions" or path.endswith("/v1/chat/completions")) and not is_codex_request

    print(f"\n" + "=" * 50)
    print(f"KeyéªŒè¯æˆåŠŸï¼Œç”¨æˆ·Key: {user_auth_header[7:] if user_auth_header else 'None'}")
    if is_codex_request:
        print(f"{get_current_codex_info()}")
    elif is_openai_client_early:
        print(f"{get_openai_to_claude_info()}")
    else:
        print(f"{get_current_api_info()}")
    print()

    if is_codex_request:
        current_codex_config = get_current_codex_config()
        real_auth_header = f"Bearer {current_codex_config['key']}"

    # 3. æ£€æµ‹æ˜¯å¦ä¸ºOpenAIå®¢æˆ·ç«¯ï¼ˆé€šè¿‡è·¯å¾„åˆ¤æ–­ï¼‰
    is_openai_client = is_openai_client_early

    # 3. å¤„ç†OpenAIæ ¼å¼è½¬æ¢
    original_request_data = None
    is_openai_format = False
    converted_body = body
    user_wants_stream = True  # è®°å½•ç”¨æˆ·åŸå§‹çš„streamè®¾ç½®
    original_model = None  # ç”¨æˆ·è¾“å…¥çš„åŸå§‹æ¨¡å‹
    converted_model = None  # è½¬æ¢åçš„æ¨¡å‹
    model_conversion_info = ""  # æ¨¡å‹è½¬æ¢ä¿¡æ¯
    
    if request.method == "POST" and body:
        try:
            original_request_data = json.loads(body.decode('utf-8'))
            
            # ç»Ÿä¸€çš„æ¨¡å‹è½¬æ¢ - ä½¿ç”¨é…ç½®é©±åŠ¨ï¼ˆCodexå’ŒClaudeéƒ½é€‚ç”¨ï¼‰
            user_original_model = original_request_data.get("model", "unknown")
            
            # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºå½“å‰è¯·æ±‚çš„æ¨¡å‹
            if is_codex_request:
                print(f"[æ¨¡å‹è½¬æ¢è°ƒè¯•] Codexè¯·æ±‚ï¼ŒåŸå§‹æ¨¡å‹: {user_original_model}", file=sys.stderr)
            
            # éå†æ¨¡å‹è½¬æ¢é…ç½®ï¼ŒæŸ¥æ‰¾åŒ¹é…çš„è§„åˆ™
            for conversion in MODEL_CONVERSIONS:
                if user_original_model == conversion.get("source_model"):
                    target_model = conversion.get("target_model")
                    conversion_name = conversion.get("name", "æœªå‘½åè½¬æ¢")
                    conversion_type = conversion.get("conversion_type", "simple_rename")  # é»˜è®¤ç®€å•æ›¿æ¢
                    
                    # æ ¹æ®é…ç½®çš„è½¬æ¢ç±»å‹é€‰æ‹©è½¬æ¢é€»è¾‘
                    if conversion_type == "full_format":
                        # Claude 3.5 -> Claude 4 å®Œæ•´æ ¼å¼è½¬æ¢
                        converted_request = {
                            "model": target_model,
                            "max_tokens": original_request_data.get("max_tokens", 8192),
                            "temperature": original_request_data.get("temperature", 1),
                            "stream": original_request_data.get("stream", True)
                        }
                        
                        # è½¬æ¢messagesæ ¼å¼ï¼šå­—ç¬¦ä¸² -> å¯¹è±¡æ•°ç»„
                        original_messages = original_request_data.get("messages", [])
                        converted_messages = []
                        for msg in original_messages:
                            converted_msg = {"role": msg.get("role", "user")}
                            content = msg.get("content", "")
                            if isinstance(content, str):
                                # 3.5æ ¼å¼ï¼šå­—ç¬¦ä¸² -> 4æ ¼å¼ï¼šå¯¹è±¡æ•°ç»„
                                converted_msg["content"] = [{"type": "text", "text": content}]
                            else:
                                # å·²ç»æ˜¯å¯¹è±¡æ ¼å¼ï¼Œä¿æŒä¸å˜
                                converted_msg["content"] = content
                            converted_messages.append(converted_msg)
                        converted_request["messages"] = converted_messages
                        
                        # è½¬æ¢systemæ ¼å¼ï¼šæ·»åŠ Claude 4å¿…éœ€çš„å…³é”®æç¤ºè¯å’Œcache_control
                        converted_system = []
                        
                        # å®Œæ•´æ ¼å¼è½¬æ¢ï¼šæ·»åŠ Claude Codeå…³é”®æç¤ºè¯
                        converted_system.append({
                            "type": "text",
                            "text": "You are Claude Code, Anthropic's official CLI for Claude.",
                            "cache_control": {"type": "ephemeral"}
                        })
                        
                        # å¤„ç†åŸå§‹systemé¡¹
                        original_system = original_request_data.get("system", [])
                        for sys_item in original_system:
                            if isinstance(sys_item, dict) and "type" in sys_item:
                                # æ·»åŠ cache_controlåˆ°ç°æœ‰systemé¡¹
                                converted_sys_item = sys_item.copy()
                                converted_sys_item["cache_control"] = {"type": "ephemeral"}
                                converted_system.append(converted_sys_item)
                            else:
                                # å¤„ç†å…¶ä»–æ ¼å¼
                                converted_system.append(sys_item)
                        
                        converted_request["system"] = converted_system
                        
                        # ä¿ç•™å…¶ä»–å¯èƒ½çš„å‚æ•°
                        for key in ["metadata", "top_p", "top_k"]:
                            if key in original_request_data:
                                converted_request[key] = original_request_data[key]
                        
                        converted_body = json.dumps(converted_request, ensure_ascii=False).encode('utf-8')
                        model_conversion_info = f"{user_original_model} â†’ {target_model}"
                    else:
                        # ç®€å•æ¨¡å‹åæ›¿æ¢
                        import copy
                        converted_request = copy.deepcopy(original_request_data)
                        converted_request["model"] = target_model
                        converted_body = json.dumps(converted_request, ensure_ascii=False).encode('utf-8')
                        model_conversion_info = f"{user_original_model} â†’ {target_model}"
                        
                        # è°ƒè¯•æ—¥å¿—ï¼šç¡®è®¤è½¬æ¢æ‰§è¡Œ
                        if is_codex_request:
                            print(f"[æ¨¡å‹è½¬æ¢è°ƒè¯•] âœ… è½¬æ¢æˆåŠŸ: {user_original_model} â†’ {target_model}", file=sys.stderr)
                    
                    # æ‰¾åˆ°åŒ¹é…è§„åˆ™åï¼Œé€€å‡ºå¾ªç¯
                    break
            openai_config_for_request: Dict[str, Any] = {}

            if is_openai_client:
                openai_config_for_request = get_primary_openai_to_claude_config()
                if not openai_config_for_request or not openai_config_for_request.get("base_url") or not openai_config_for_request.get("key"):
                    error_response = {
                        "error": {
                            "message": "OpenAIè½¬Claudeé…ç½®ç¼ºå¤±æˆ–æœªå¯ç”¨ï¼Œè¯·åœ¨ç®¡ç†åå°é…ç½®æœ‰æ•ˆçš„Key",
                            "type": "configuration_error",
                            "code": "invalid_configuration"
                        }
                    }
                    return JSONResponse(
                        content=error_response,
                        status_code=500,
                        headers={"content-type": "application/json"}
                    )

                is_openai_format = True
                # OpenAIè½¬Claudeæ—¶ï¼Œå¼ºåˆ¶ä½¿ç”¨ä¸“ç”¨é…ç½®
                base_url_override = openai_config_for_request.get("base_url", base_url_override)
                # è®°å½•ç”¨æˆ·åŸå§‹çš„streamè®¾ç½®å’Œæ¨¡å‹
                user_wants_stream = original_request_data.get("stream", False)
                original_model = user_original_model  # ä½¿ç”¨ä¿å­˜çš„åŸå§‹æ¨¡å‹å
                
                try:
                    # è½¬æ¢OpenAIè¯·æ±‚ä¸ºClaudeæ ¼å¼ï¼Œè·å–è½¬æ¢ç»“æœå’Œå¯¹åº”çš„è¯·æ±‚å¤´
                    _, converted_request, conversion_headers = detect_and_convert_request(original_request_data)
                    
                    # è·å–è½¬æ¢åçš„æ¨¡å‹å
                    converted_model = converted_request.get("model", original_model)
                    
                    # ç”Ÿæˆæ¨¡å‹è½¬æ¢ä¿¡æ¯ï¼ˆåªæœ‰åœ¨æœªè®¾ç½®æ—¶æ‰ç”Ÿæˆï¼‰
                    if not model_conversion_info:
                        if original_model != converted_model:
                            # æ£€æµ‹æ˜¯å¦æ˜¯æ€è€ƒæ¨¡å¼
                            is_thinking_mode = "-thinking" in original_model
                            thinking_suffix = " (æ€è€ƒæ¨¡å¼)" if is_thinking_mode else ""
                            model_conversion_info = f"{original_model} â†’ {converted_model}{thinking_suffix}"
                        else:
                            model_conversion_info = f"{original_model}"
                    
                    # éªŒè¯è½¬æ¢åçš„è¯·æ±‚æ˜¯å¦æœ‰æ•ˆ
                    if not converted_request.get("model"):
                        converted_request["model"] = original_model
                    if not converted_request.get("messages"):
                        raise ValueError("è½¬æ¢åçš„è¯·æ±‚ç¼ºå°‘messageså­—æ®µ")
                    if "max_tokens" not in converted_request:
                        converted_request["max_tokens"] = 32000  # OpenAIæ–¹å¼é»˜è®¤32000
                    
                    # ç§»é™¤thinkingåŠŸèƒ½ï¼Œä½¿ç”¨exact_test.pyéªŒè¯æˆåŠŸçš„ç®€æ´æ ¼å¼
                    # exact_test.pyä¸­çš„æˆåŠŸè¯·æ±‚æ²¡æœ‰ä½¿ç”¨thinkingåŠŸèƒ½
                    
                    converted_body = json.dumps(converted_request, ensure_ascii=False).encode('utf-8')
                    
                    # OpenAIæ ¼å¼è¾“å…¥è¯·æ±‚æ—¥å¿—å·²åˆ é™¤
                    
                    # å¯¹äºOpenAIæ ¼å¼è¯·æ±‚ï¼Œè½¬æ¢è·¯å¾„ä¸º v1/messages
                    path = "v1/messages"
                    
                except Exception as convert_error:
                    import traceback
                    error_msg = f"OpenAIè¯·æ±‚è½¬æ¢å¤±è´¥: {convert_error}"
                    print(error_msg, file=sys.stderr)
                    print(f"è½¬æ¢é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}", file=sys.stderr)
                    
                    # è½¬æ¢å¤±è´¥æ—¶è¿”å›é”™è¯¯å“åº”
                    error_response = {
                        "error": {
                            "message": f"Request conversion failed: {str(convert_error)}",
                            "type": "conversion_error",
                            "code": "invalid_request_error"
                        }
                    }
                    return JSONResponse(
                        content=error_response,
                        status_code=400,
                        headers={"content-type": "application/json"}
                    )
                
                # åˆ é™¤æ¨¡å‹è½¬æ¢æ—¥å¿—è®°å½•
            else:
                # éOpenAIè·¯å¾„ï¼ˆç›´è¿Claude APIï¼‰
                # å¦‚æœå‘ç”Ÿäº†æ¨¡å‹è½¬æ¢ï¼Œè®¾ç½®ç›¸åº”ä¿¡æ¯ç”¨äºæ—¥å¿—è®°å½•
                if model_conversion_info:
                    # æ¨¡å‹è½¬æ¢ä¿¡æ¯å·²åœ¨ä¸Šé¢è®¾ç½®ï¼Œè¿™é‡Œä»…ç”¨äºæ—¥å¿—
                    pass
                    
        except json.JSONDecodeError:
            # ä¸æ˜¯JSONè¯·æ±‚ï¼Œä¿æŒåŸæ ·
            pass
        except Exception as e:
            import traceback
            print(f"è½¬æ¢è¯·æ±‚æ—¶å‡ºé”™: {e}")
            print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            # åˆ é™¤åŸå§‹è¯·æ±‚æ•°æ®è®°å½•
    
    # 5. å¤åˆ¶è¯·æ±‚å¤´ï¼Œæ’é™¤ host å¤´å’Œ authorization å¤´ï¼ˆå°†ä½¿ç”¨éªŒè¯åçš„çœŸæ­£API keyï¼‰
    headers = {key: value for key, value in request.headers.items() 
               if key.lower() not in ['host', 'authorization']}
    
    # æ·»åŠ éªŒè¯åçš„çœŸæ­£API key
    headers['authorization'] = real_auth_header
    
    # å¯¹äºOpenAIæ ¼å¼è¯·æ±‚ï¼Œä½¿ç”¨ä»è½¬æ¢å‡½æ•°è¿”å›çš„å¤´ä¿¡æ¯é…ç½®
    if is_openai_format:
        successful_headers = conversion_headers if 'conversion_headers' in locals() else get_exact_test_headers()
        
        # OpenAIè½¬Claudeæ—¶ï¼Œå¼ºåˆ¶ä½¿ç”¨ä¸“ç”¨é…ç½®çš„key
        if openai_config_for_request and openai_config_for_request.get("key"):
            successful_headers['authorization'] = f"Bearer {openai_config_for_request['key']}"
        
        # æ›´æ–°ä¸ºæˆåŠŸçš„å¤´ä¿¡æ¯
        headers.update(successful_headers)
        
        # å¤„ç†å¤–éƒ¨è¯·æ±‚è·¯å¾„ï¼šæå–æ ¸å¿ƒAPIè·¯å¾„ï¼Œå»æ‰æ‰€æœ‰å‰ç¼€
        # ä¸ç®¡æ˜¯ api/v1/messages è¿˜æ˜¯ ao/api2/v1/messagesï¼Œéƒ½æå–å‡º v1/messages
        import re
        # åŒ¹é…æœ€åçš„ v1/... éƒ¨åˆ†
        path_match = re.search(r'(v1/(?:messages|chat/completions).*?)(?:\?|$)', path)
        if path_match:
            clean_path = path_match.group(1)
        else:
            # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°æ ‡å‡†è·¯å¾„ï¼Œå»æ‰å¼€å¤´çš„ä»»ä½•è·¯å¾„æ®µç›´åˆ°é‡åˆ°v1
            parts = path.split('/')
            v1_index = -1
            for i, part in enumerate(parts):
                if part == 'v1':
                    v1_index = i
                    break
            if v1_index >= 0:
                clean_path = '/'.join(parts[v1_index:])
            else:
                clean_path = path  # ä¿æŒåŸæ ·
        
        # æ·»åŠ queryå‚æ•° - exact_test.pyä¸­ä½¿ç”¨äº†beta=true
        upstream_url = build_upstream_url(clean_path, request.url.query, is_openai_format, base_url_override)
    else:
        # éOpenAIè¯·æ±‚ä¿æŒåŸæœ‰é€»è¾‘
        # ç¡®ä¿å¿…è¦çš„é»˜è®¤å¤´ä¿¡æ¯å­˜åœ¨
        default_headers = {
            'content-type': 'application/json',
            'accept': 'application/json, text/event-stream',
            'user-agent': headers.get('user-agent', 'Claude-Proxy/1.0')
        }
        
        # æ·»åŠ ç¼ºå¤±çš„é»˜è®¤å¤´ä¿¡æ¯
        for key, value in default_headers.items():
            if key.lower() not in {h.lower() for h in headers.keys()}:
                headers[key] = value
        
        # å¤„ç†å¤–éƒ¨è¯·æ±‚è·¯å¾„ï¼šæå–æ ¸å¿ƒAPIè·¯å¾„ï¼Œå»æ‰æ‰€æœ‰å‰ç¼€
        # ä¸ç®¡æ˜¯ api/v1/messages è¿˜æ˜¯ ao/api2/v1/messagesï¼Œéƒ½æå–å‡º v1/messages
        import re
        # åŒ¹é…æœ€åçš„ v1/... éƒ¨åˆ†  
        path_match = re.search(r'(v1/(?:messages|chat/completions).*?)(?:\?|$)', path)
        if path_match:
            clean_path = path_match.group(1)
        else:
            # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°æ ‡å‡†è·¯å¾„ï¼Œå»æ‰å¼€å¤´çš„ä»»ä½•è·¯å¾„æ®µç›´åˆ°é‡åˆ°v1
            parts = path.split('/')
            v1_index = -1
            for i, part in enumerate(parts):
                if part == 'v1':
                    v1_index = i
                    break
            if v1_index >= 0:
                clean_path = '/'.join(parts[v1_index:])
            else:
                # å¯¹äº Codex è¯·æ±‚ï¼Œå»æ‰ openai/ å‰ç¼€ï¼ˆå› ä¸º base_url å·²åŒ…å«ï¼‰
                if is_codex_request and normalized_path.startswith(f"{CODEX_PATH_PREFIX}/"):
                    clean_path = normalized_path[len(CODEX_PATH_PREFIX)+1:]  # å»æ‰ "openai/"
                else:
                    clean_path = path  # ä¿æŒåŸæ ·
        
        # å®Œæ•´åœ°é‡å»ºä¸Šæ¸¸ URLï¼ŒåŒ…æ‹¬æŸ¥è¯¢å‚æ•°
        upstream_url = build_upstream_url(clean_path, request.url.query, is_openai_format, base_url_override)
    
    # å¦‚æœè½¬æ¢äº†è¯·æ±‚ä½“ï¼Œéœ€è¦æ›´æ–°Content-Length
    if converted_body != body:
        headers['content-length'] = str(len(converted_body))
    
    # æ‰“å°ç”¨æˆ·è¯·æ±‚ä¿¡æ¯ï¼ˆç²¾ç®€ç‰ˆï¼‰
    print(f"=== {datetime.now().strftime('%H:%M:%S')} {request.method} {path} ===")
    if is_openai_format and model_conversion_info:
        print(f"OpenAIæ ¼å¼è½¬æ¢: {model_conversion_info}")
    elif is_openai_format:
        print(f"OpenAIæ ¼å¼ â†’ Claudeæ ¼å¼ (è½¬æ¢å®Œæˆ)")
    elif is_codex_request:
        if model_conversion_info:
            print(f"Codexæ ¼å¼ (ç›´æ¥é€ä¼ ): {model_conversion_info}")
        else:
            print("Codexæ ¼å¼ (ç›´æ¥é€ä¼ )")
        print(f"Codexç›®æ ‡URL: {upstream_url}")
    elif model_conversion_info and not is_openai_format:
        print(f"Claudeæ ¼å¼ (ç›´æ¥é€ä¼ ): {model_conversion_info}")
    else:
        print(f"Claudeæ ¼å¼ (ç›´æ¥é€ä¼ )")
    
    # åˆ é™¤è¯¦ç»†çš„ä¸Šæ¸¸è¯·æ±‚è®°å½•
    pass

    # 5. å®šä¹‰è½¬æ¢æ ‡å¿—
    should_convert_to_openai = is_openai_client  # åªæœ‰OpenAIå®¢æˆ·ç«¯æ‰è½¬æ¢å“åº”æ ¼å¼
    
    # æ·»åŠ é‡è¯•æœºåˆ¶ - ä½¿ç”¨ç‹¬ç«‹clienté¿å…å¹¶å‘å†²çª
    # Claudeè¯·æ±‚çš„é‡è¯•æ¬¡æ•°ä»é…ç½®è¯»å–ï¼ˆé»˜è®¤4æ¬¡ï¼‰
    # Codexè¯·æ±‚çš„é‡è¯•æ¬¡æ•°å–å†³äºREAD_TIMEOUT_RETRY_CONFIGSé•¿åº¦
    if is_codex_request:
        max_retries = len(READ_TIMEOUT_RETRY_CONFIGS) if READ_TIMEOUT_RETRY_CONFIGS else 2
    else:
        # Claudeè¯·æ±‚ï¼šä»é…ç½®è¯»å–æœ€å¤§é‡è¯•æ¬¡æ•°
        max_retries = TimeoutConfig.get_max_retries()
    
    # æ³¨æ„ï¼šä¸´æ—¶æ€§é”™è¯¯ï¼ˆ400, 404, 429, 500, 502, 503, 520-524ï¼‰ä½¿ç”¨ç­–ç•¥é‡è¯•å¤„ç†
    # æŒç»­æ€§é”™è¯¯ï¼ˆ401, 403ï¼‰ä½¿ç”¨æ™ºèƒ½APIåˆ‡æ¢å¤„ç†ï¼ˆè¾¾åˆ°åˆ‡æ¢é˜ˆå€¼åï¼‰
    last_error = None
    retry_errors = []
    
    # Claudeè¯·æ±‚çš„é”™è¯¯è¿½è¸ªï¼ˆç”¨äºåœ¨é‡è¯•å¾ªç¯ç»“æŸåç»Ÿä¸€è®°å½•é”™è¯¯ï¼‰
    last_error_status_code = None  # æœ€åçš„HTTPçŠ¶æ€ç 
    last_error_strategy = None  # æœ€åçš„é”™è¯¯å¤„ç†ç­–ç•¥
    should_record_error_after_retry = False  # æ˜¯å¦åœ¨é‡è¯•ç»“æŸåè®°å½•é”™è¯¯
    
    for retry_attempt in range(max_retries):
        # ä¸ºæ¯æ¬¡é‡è¯•åˆ›å»ºç‹¬ç«‹çš„clientå®ä¾‹ï¼Œé¿å…è¿æ¥å¤ç”¨é—®é¢˜
        # åŒ…æ‹¬ç¬¬ä¸€æ¬¡ä¹Ÿä½¿ç”¨æ–°clientï¼Œç¡®ä¿ä¸å¤ç”¨å¯èƒ½æœ‰åè¿æ¥çš„å…¨å±€client
        # æ ¹æ®æ˜¯å¦ä¸ºéæµå¼è¯·æ±‚é€‰æ‹©åˆé€‚çš„è¶…æ—¶é…ç½®
        if is_codex_request:
            # Codexè¯·æ±‚ï¼šè¿æ¥30ç§’è¶…æ—¶ï¼ˆasyncio.wait_foræ§åˆ¶ï¼‰+ æµå¼æ€»è¶…æ—¶ï¼ˆæ‰‹åŠ¨è®¡æ—¶æ§åˆ¶ï¼‰
            # ç¦ç”¨httpxçš„readè¶…æ—¶ï¼Œå®Œå…¨ç”±æµå¼æ€»è¶…æ—¶æ§åˆ¶
            codex_timeout = httpx.Timeout(
                connect=TimeoutConfig.get_connect_timeout(),
                read=None,  # âœ… ç¦ç”¨readè¶…æ—¶ï¼Œç”±æµå¼æ€»è¶…æ—¶æ§åˆ¶
                write=TimeoutConfig.get_write_timeout(),
                pool=TimeoutConfig.get_pool_timeout()
            )
            retry_client = httpx.AsyncClient(timeout=codex_timeout, limits=limits)
            # æ˜¾ç¤º Codex è¶…æ—¶ä¿¡æ¯
            codex_base_timeout = TimeoutConfig.get_codex_base_timeout()
            with codex_timeout_lock:
                current_extra_seconds = codex_timeout_extra_seconds
            print(f"[Codexè¶…æ—¶é…ç½®] è¿æ¥è¶…æ—¶: {TimeoutConfig.get_codex_connect_timeout()}ç§’ | æµå¼æ€»è¶…æ—¶: {codex_base_timeout + current_extra_seconds}ç§’", file=sys.stderr)
            if current_extra_seconds > 0:
                print(f"[Codexè‡ªé€‚åº”è¶…æ—¶] æµå¼æ€»è¶…æ—¶è¯¦æƒ…: åŸºç¡€{codex_base_timeout}ç§’ + é¢å¤–{current_extra_seconds}ç§’", file=sys.stderr)
        elif should_convert_to_openai and not user_wants_stream:
            # éæµå¼è¯·æ±‚ä½¿ç”¨60ç§’è¶…æ—¶
            retry_client = httpx.AsyncClient(timeout=non_streaming_timeout, limits=limits)
            # æ˜¾ç¤º Claude éæµå¼è¶…æ—¶ä¿¡æ¯
            print(f"[Claudeè¶…æ—¶é…ç½®] è¿æ¥è¶…æ—¶: {TimeoutConfig.get_connect_timeout()}ç§’ | è¯»å–è¶…æ—¶: {TimeoutConfig.get_non_streaming_read_timeout()}ç§’", file=sys.stderr)
        else:
            # æµå¼è¯·æ±‚æˆ–éOpenAIè¯·æ±‚ä½¿ç”¨æ ‡å‡†è¶…æ—¶
            retry_client = httpx.AsyncClient(timeout=timeout, limits=limits)
            # æ˜¾ç¤º Claude æµå¼è¶…æ—¶ä¿¡æ¯
            print(f"[Claudeè¶…æ—¶é…ç½®] è¿æ¥è¶…æ—¶: {TimeoutConfig.get_connect_timeout()}ç§’ | æµå¼è¯»å–è¶…æ—¶: {TimeoutConfig.get_streaming_read_timeout()}ç§’", file=sys.stderr)
        
        try:
            # è®°å½•å‘APIå‰çš„åŸæ•°æ®ï¼ˆä»…åœ¨ç¬¬ä¸€æ¬¡å°è¯•æ—¶è®°å½•ï¼‰
            if retry_attempt == 0:
                log_original_data(request_id, body, headers, request.method, path, is_codex_request)
                
                # å¦‚æœå‘ç”Ÿäº†æ¨¡å‹è½¬æ¢ï¼Œè®°å½•è½¬æ¢åæ•°æ®ç”¨äºå¯¹æ¯”åˆ†æ
                if converted_body != body and model_conversion_info and original_data_logger:
                    original_data_logger.info("="*40)
                    original_data_logger.info(f"æ¨¡å‹è½¬æ¢å¯¹æ¯” - è¯·æ±‚ID: {request_id}")
                    original_data_logger.info(f"è½¬æ¢ä¿¡æ¯: {model_conversion_info}")
                    # ç›´æ¥è®°å½•è½¬æ¢åæ•°æ®ï¼Œå¤ç”¨ç°æœ‰å¤„ç†é€»è¾‘
                    log_original_data(f"{request_id}_è½¬æ¢å", converted_body, headers, request.method, path, is_codex_request)
            
            # è·å–å½“å‰APIé…ç½®
            current_config = get_current_codex_config() if is_codex_request else get_current_config()
            
            # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä¿®æ”¹é‡è¯•è¯·æ±‚å¤´
            retry_headers = headers.copy()
            if TimeoutConfig.get_modify_retry_headers():
                # å¼ºåˆ¶å…³é—­è¿æ¥å¤ç”¨ï¼Œè®©æ¯æ¬¡é‡è¯•éƒ½åƒæ–°è¯·æ±‚ä¸€æ ·ä½¿ç”¨å…¨æ–°è¿æ¥
                retry_headers['connection'] = 'close'
                # æ·»åŠ å”¯ä¸€æ ‡è¯†å’Œå®Œæ•´çš„é˜²ç¼“å­˜å¤´éƒ¨ï¼Œç¡®ä¿APIä¸ä½¿ç”¨ç¼“å­˜
                import random
                import time
                retry_rand = random.randint(1000,9999)
                retry_timestamp = int(time.time() * 1000)
                retry_headers['x-request-id'] = f"{request_id}-retry{retry_attempt}-{retry_rand}"
                retry_headers['cache-control'] = 'no-cache, no-store, must-revalidate'
                retry_headers['pragma'] = 'no-cache'
                retry_headers['expires'] = '0'
                retry_headers['x-cache-bypass'] = f'{retry_timestamp}-{retry_rand}'
                retry_headers['x-retry-count'] = str(retry_attempt + 1)

            # åº”ç”¨ cache_control æ•°é‡é™åˆ¶ï¼ˆå®é™…é™åˆ¶æ˜¯3ä¸ªï¼Œè€Œä¸æ˜¯æ–‡æ¡£è¯´çš„4ä¸ªï¼‰
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†cache_controlé™åˆ¶åŠŸèƒ½
            optimization_settings = config_mgr.get_optimization_settings()
            if optimization_settings.get("enable_cache_control_limit", True):
                try:
                    request_data_to_limit = json.loads(converted_body.decode('utf-8'))

                    # å…ˆç»Ÿè®¡cache_controlå—æ•°é‡
                    cache_count = 0
                    for item in request_data_to_limit.get("system", []):
                        if isinstance(item, dict) and "cache_control" in item:
                            cache_count += 1
                    for msg in request_data_to_limit.get("messages", []):
                        if isinstance(msg, dict):
                            content = msg.get("content", [])
                            if isinstance(content, list):
                                for c_item in content:
                                    if isinstance(c_item, dict) and "cache_control" in c_item:
                                        cache_count += 1

                    # åªæœ‰è¶…è¿‡3ä¸ªæ—¶æ‰æ‰“å°è¯Šæ–­ä¿¡æ¯å¹¶é™åˆ¶
                    if cache_count > 3:
                        print(f"ğŸ” [cache_controlè¯Šæ–­][{request_id}] æ£€æµ‹åˆ° {cache_count} ä¸ªcache_controlå—", file=sys.stderr)
                        limited_request_data = limit_cache_control_blocks(request_data_to_limit, max_blocks=3)
                        converted_body = json.dumps(limited_request_data, ensure_ascii=False).encode('utf-8')
                        # ä¿®æ”¹äº†è¯·æ±‚ä½“åï¼Œå¿…é¡»åˆ é™¤æ—§çš„ Content-Length å¤´ï¼Œè®© httpx é‡æ–°è®¡ç®—
                        # HTTP å¤´åç§°ä¸åŒºåˆ†å¤§å°å†™ï¼Œéœ€è¦é€ä¸€æ£€æŸ¥
                        headers_to_remove = [k for k in retry_headers.keys() if k.lower() == 'content-length']
                        for h in headers_to_remove:
                            del retry_headers[h]
                except Exception as e:
                    print(f"[cache_controlé™åˆ¶] åº”ç”¨å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹è¯·æ±‚: {e}", file=sys.stderr)

            # 6. ä»¥æµå¼æ¨¡å¼å‘ä¸Šæ¸¸å‘é€è¯·æ±‚ï¼ˆä½¿ç”¨è½¬æ¢åçš„è¯·æ±‚ä½“å’Œé‡è¯•ä¸“ç”¨headersï¼‰
            upstream_req = retry_client.build_request(
                method=request.method,
                url=upstream_url,
                headers=retry_headers,  # ä½¿ç”¨é‡è¯•ä¸“ç”¨çš„headerså‰¯æœ¬
                content=converted_body  # ä½¿ç”¨è½¬æ¢åçš„è¯·æ±‚ä½“
            )
            
            # Codexè¯·æ±‚ä½¿ç”¨30ç§’è¿æ¥è¶…æ—¶ï¼ˆåªé’ˆå¯¹è¿æ¥é˜¶æ®µï¼Œä¸å½±å“åç»­æµå¼è¯»å–ï¼‰
            if is_codex_request:
                import asyncio
                try:
                    upstream_resp = await asyncio.wait_for(
                        retry_client.send(upstream_req, stream=True),
                        timeout=TimeoutConfig.get_codex_connect_timeout()
                    )
                except asyncio.TimeoutError:
                    timeout_msg = f"[Codexè¿æ¥è¶…æ—¶][{request_id}] {TimeoutConfig.get_codex_connect_timeout()}ç§’å†…æœªæ”¶åˆ°å“åº”ï¼Œå‡†å¤‡é‡è¯•"
                    retry_errors.append(timeout_msg)
                    print(timeout_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°è¶…æ—¶ä¿¡æ¯
                    # è®°å½•Codexè¿æ¥è¶…æ—¶é”™è¯¯
                    msg = record_codex_error(codex_current_config_index, 503, silent=True)
                    if msg:
                        retry_errors.append(msg)
                        print(msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°é”™è¯¯è¯¦æƒ…
                    await retry_client.aclose()
                    # è½¬æ¢ä¸ºhttpx.ReadTimeoutä»¥å¤ç”¨ç°æœ‰é‡è¯•é€»è¾‘
                    raise httpx.ReadTimeout("Codex connection timeout: 30 seconds")
            else:
                upstream_resp = await retry_client.send(upstream_req, stream=True)
            
            # æ£€æŸ¥çŠ¶æ€ç æ˜¯å¦éœ€è¦ç­–ç•¥é‡è¯•ï¼ˆä¸´æ—¶æ€§é”™è¯¯ï¼Œå¿«é€Ÿæ¢å¤ï¼‰
            status_code = upstream_resp.status_code
            strategy_retry_status_codes = TimeoutConfig.get_strategy_retry_status_codes()
            
            # ä¸´æ—¶æ€§é”™è¯¯ï¼šä½¿ç”¨ç­–ç•¥é‡è¯•ï¼ˆå¿«é€Ÿå°è¯•å…¶ä»–APIï¼‰
            if (not is_codex_request) and status_code in strategy_retry_status_codes:
                print(f"[ç­–ç•¥é‡è¯•è§¦å‘][{request_id}] æ£€æµ‹åˆ°ä¸´æ—¶æ€§é”™è¯¯{status_code}ï¼Œå°†ä½¿ç”¨è¶…æ—¶é‡è¯•ç­–ç•¥", file=sys.stderr)
                # ä¿å­˜çŠ¶æ€ç ï¼Œåç»­åœ¨å¼‚å¸¸å¤„ç†å—å¤–ä½¿ç”¨ç­–ç•¥é‡è¯•
                # è¿™é‡Œå…ˆå…³é—­å“åº”ï¼Œåˆ¶é€ ä¸€ä¸ª"éœ€è¦ç­–ç•¥é‡è¯•"çš„çŠ¶æ€
                await upstream_resp.aclose()
                await retry_client.aclose()
                # æŠ›å‡ºç‰¹æ®Šæ ‡è®°ï¼Œåç»­æ•è·å¹¶ä½¿ç”¨ç­–ç•¥é‡è¯•
                raise httpx.HTTPStatusError(
                    f"Status {status_code} - Strategy Retry Needed",
                    request=upstream_req,
                    response=upstream_resp
                )
            
            # ä¸´æ—¶æ€§é”™è¯¯å¤„ç†ï¼šå†…éƒ¨é‡è¯•ï¼Œä¸è¿”å›ç»™ç”¨æˆ·ï¼ˆCodexå’ŒClaudeéƒ½é€‚ç”¨ï¼‰
            # ä»é…ç½®ä¸­è¯»å–å“ªäº›çŠ¶æ€ç éœ€è¦è§¦å‘APIåˆ‡æ¢
            strategies = config_mgr.get_error_handling_strategies()
            http_codes = strategies.get("http_status_codes", {})
            switch_api_codes = [int(code) for code, strategy in http_codes.items()
                              if strategy == "switch_api" and code != "default"]
            no_retry_codes = [int(code) for code, strategy in http_codes.items()
                            if strategy == "normal_retry" and code != "default"]
            
            # no_retryç­–ç•¥ï¼šè®°å½•é”™è¯¯ï¼Œå»¶æ—¶åè·³å‡ºé‡è¯•å¾ªç¯ï¼ˆCodexå’ŒClaudeéƒ½é€‚ç”¨ï¼‰
            if status_code in no_retry_codes:
                if is_codex_request:
                    # Codexè¯·æ±‚ï¼šè®°å½•é”™è¯¯
                    print(f"[ä¸é‡è¯•ç­–ç•¥][{request_id}] æ£€æµ‹åˆ°é”™è¯¯{status_code}ï¼Œå»¶æ—¶åè¿”å›é”™è¯¯ç»™ç”¨æˆ·", file=sys.stderr)
                    msg = record_codex_error(codex_current_config_index, status_code, silent=True)
                    if msg:
                        print(msg, file=sys.stderr)
                    # æ·»åŠ å»¶æ—¶
                    import asyncio
                    delay = 2
                    print(f"[ä¸é‡è¯•ç­–ç•¥][{request_id}] ç­‰å¾… {delay} ç§’åç»§ç»­...", file=sys.stderr)
                    await asyncio.sleep(delay)
                    # è·³å‡ºé‡è¯•å¾ªç¯ï¼Œè®©åç»­çš„æ­£å¸¸æµç¨‹å¤„ç†å“åº”ï¼ˆä¿ç•™usageä¿¡æ¯ï¼‰
                    break
                else:
                    # Claudeè¯·æ±‚ï¼šè®°å½•é”™è¯¯
                    print(f"[ä¸é‡è¯•ç­–ç•¥][{request_id}] æ£€æµ‹åˆ°é”™è¯¯{status_code}ï¼Œå»¶æ—¶åè¿”å›é”™è¯¯ç»™ç”¨æˆ·", file=sys.stderr)
                    msg = record_api_error(current_config_index, status_code, silent=True)
                    if msg:
                        print(msg, file=sys.stderr)
                    # æ·»åŠ å»¶æ—¶
                    import asyncio
                    delay = 2
                    print(f"[ä¸é‡è¯•ç­–ç•¥][{request_id}] ç­‰å¾… {delay} ç§’åç»§ç»­...", file=sys.stderr)
                    await asyncio.sleep(delay)
                    # è·³å‡ºé‡è¯•å¾ªç¯ï¼Œè®©åç»­çš„æ­£å¸¸æµç¨‹å¤„ç†å“åº”ï¼ˆä¿ç•™usageä¿¡æ¯ï¼‰
                    break
            
            if status_code in switch_api_codes:
                # æ ¹æ®è¯·æ±‚ç±»å‹é€‰æ‹©ä¸åŒçš„é”™è¯¯æç¤º
                request_type = "Codex" if is_codex_request else "Claude"
                error_msg = f"[{request_type}é”™è¯¯é‡è¯• {retry_attempt + 1}/{max_retries}][{request_id}] æ£€æµ‹åˆ°é”™è¯¯{status_code}ï¼Œå†…éƒ¨é‡è¯•"
                retry_errors.append(error_msg)
                print(error_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°é”™è¯¯ä¿¡æ¯
                
                # åˆå§‹åŒ–åˆ‡æ¢æ ‡å¿—
                switch_success = False
                
                # è®°å½•é”™è¯¯ï¼ˆæ ¹æ®è¯·æ±‚ç±»å‹ï¼‰
                if is_codex_request:
                    # Codexè¯·æ±‚ï¼šæ¯æ¬¡éƒ½è®°å½•é”™è¯¯ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    msg = record_codex_error(codex_current_config_index, status_code, silent=True)
                    if msg:
                        retry_errors.append(msg)
                        print(msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°é”™è¯¯è¯¦æƒ…
                # Claudeè¯·æ±‚ï¼šä¸åœ¨è¿™é‡Œè®°å½•é”™è¯¯ï¼Œæ”¹ä¸ºåœ¨é‡è¯•å¾ªç¯ç»“æŸåç»Ÿä¸€è®°å½•
                # æ›´æ–°é”™è¯¯è¿½è¸ªä¿¡æ¯
                else:
                    last_error_status_code = status_code
                    last_error_strategy = "switch_api"
                    should_record_error_after_retry = True
                
                # å°è¯•åˆ‡æ¢APIï¼ˆå¦‚æœé”™è¯¯æ¬¡æ•°>=é˜ˆå€¼ï¼Œæ ¹æ®è¯·æ±‚ç±»å‹ï¼‰
                if is_codex_request:
                    current_codex_api_index = codex_current_config_index
                    switch_success, new_codex_api_index = smart_codex_switch_api(current_codex_api_index, status_code)
                    
                    if switch_success:
                        switch_msg = f"[Codexé”™è¯¯é‡è¯•][{request_id}] å·²åˆ‡æ¢åˆ° {CODEX_CONFIGS[new_codex_api_index]['name']}"
                        retry_errors.append(switch_msg)
                        print(switch_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°åˆ‡æ¢ä¿¡æ¯
                else:
                    # Claudeè¯·æ±‚çš„APIåˆ‡æ¢
                    current_api_index = current_config_index
                    switch_success, new_api_index = smart_switch_api(current_api_index, status_code)
                    
                    if switch_success:
                        switch_msg = f"[Claudeé”™è¯¯é‡è¯•][{request_id}] å·²åˆ‡æ¢åˆ° {API_CONFIGS[new_api_index]['name']}"
                        retry_errors.append(switch_msg)
                        print(switch_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°åˆ‡æ¢ä¿¡æ¯
                
                # å…³é—­å½“å‰å“åº”å’Œå®¢æˆ·ç«¯
                await upstream_resp.aclose()
                await retry_client.aclose()
                
                # æ ¹æ®è¯·æ±‚ç±»å‹é‡æ–°æ„å»ºé…ç½®å’ŒURL
                if is_codex_request:
                    # è·å–å½“å‰Codexé…ç½®ï¼ˆå¯èƒ½å·²åˆ‡æ¢ï¼‰
                    current_codex_config = get_current_codex_config()
                    
                    # æ˜¾ç¤ºåˆ‡æ¢åçš„å®Œæ•´APIä¿¡æ¯ï¼ˆæ ¼å¼å’Œè¯·æ±‚å¼€å§‹æ—¶ä¸€è‡´ï¼‰
                    if switch_success:
                        print(f"\n{get_current_codex_info()}")
                    
                    # é‡æ–°æ„å»ºURLå’Œè®¤è¯ä¿¡æ¯
                    upstream_url = build_upstream_url(clean_path, request.url.query, is_openai_format, current_codex_config["base_url"])
                    headers['authorization'] = f'Bearer {current_codex_config["key"]}'
                else:
                    # Claudeè¯·æ±‚çš„é…ç½®é‡å»º
                    if switch_success:
                        # é‡æ–°éªŒè¯ç”¨æˆ·Keyï¼Œè·å–æ–°çš„çœŸå®Auth
                        is_valid, real_auth_header, error_msg = validate_and_replace_user_key(user_auth_header)
                        if is_valid:
                            headers['authorization'] = real_auth_header
                            # é‡æ–°æ„å»ºURLï¼ˆbase_urlå¯èƒ½å·²å˜åŒ–ï¼‰
                            upstream_url = build_upstream_url(clean_path, request.url.query, is_openai_format, base_url_override)
                            print(f"\n{get_current_api_info()}")  # æ˜¾ç¤ºåˆ‡æ¢åçš„APIä¿¡æ¯
                
                # ç»§ç»­ä¸‹ä¸€æ¬¡é‡è¯•
                continue

            # æ£€æŸ¥å“åº”çŠ¶æ€ç ï¼Œå†³å®šæ˜¯å¦ç»§ç»­é‡è¯•
            if upstream_resp.status_code < 400:
                # è¯·æ±‚æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                break
            else:
                # é”™è¯¯å“åº”ï¼šåªæœ‰æœ€åä¸€æ¬¡é‡è¯•æ‰è·³å‡ºï¼Œå¦åˆ™ç»§ç»­é‡è¯•
                if retry_attempt < max_retries - 1:
                    # è¿˜æœ‰é‡è¯•æœºä¼šï¼Œç»§ç»­é‡è¯•
                    error_msg = f"[é‡è¯• {retry_attempt + 1}/{max_retries}][{request_id}] æ£€æµ‹åˆ°é”™è¯¯{upstream_resp.status_code}ï¼Œç»§ç»­é‡è¯•"
                    retry_errors.append(error_msg)
                    print(error_msg, file=sys.stderr)
                    await upstream_resp.aclose()
                    await retry_client.aclose()
                    continue
                else:
                    # æœ€åä¸€æ¬¡é‡è¯•ï¼Œè·³å‡ºå¾ªç¯è¿”å›é”™è¯¯
                    break
            
        except (httpx.HTTPStatusError, httpx.RequestError) as e:
            last_error = e
            error_type_name = "çŠ¶æ€ç é”™è¯¯" if isinstance(e, httpx.HTTPStatusError) else "è¿æ¥é”™è¯¯"
            general_error_msg = f"[é‡è¯• {retry_attempt + 1}/{max_retries}][{request_id}] {error_type_name}: {e}"
            retry_errors.append(general_error_msg)
            print(general_error_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°é€šç”¨é”™è¯¯
            
            # å…³é—­å½“å‰çš„clientå®ä¾‹ï¼Œé¿å…çŠ¶æ€å¼‚å¸¸å½±å“åç»­é‡è¯•
            await retry_client.aclose()
            
            # ç‰¹æ®Šå¤„ç†ReadErrorï¼šæ ¹æ®é…ç½®å†³å®šå¤„ç†ç­–ç•¥
            if isinstance(e, httpx.ReadError):
                read_error_strategy = TimeoutConfig.get_network_error_strategy("ReadError")
                
                if is_codex_request:
                    # Codexè¯·æ±‚çš„ReadErrorï¼šæ¯æ¬¡éƒ½è®°å½•é”™è¯¯ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    retry_errors.append(f"[SSLè¯»å–é”™è¯¯][{request_id}] Codexæ£€æµ‹åˆ°SSLè¯»å–é”™è¯¯æˆ–è¿æ¥ä¸­æ–­")
                    msg = record_codex_error(codex_current_config_index, 503, silent=True)
                    if msg:
                        retry_errors.append(msg)
                # Claudeè¯·æ±‚çš„ReadErrorï¼šä¸åœ¨è¿™é‡Œè®°å½•é”™è¯¯ï¼Œæ”¹ä¸ºåœ¨é‡è¯•å¾ªç¯ç»“æŸåç»Ÿä¸€è®°å½•
                
                # ä¸ºnormal_retryç­–ç•¥è®¾ç½®é”™è¯¯è®°å½•æ ‡å¿—
                if (not is_codex_request) and read_error_strategy == "normal_retry":
                    last_error_status_code = 503
                    last_error_strategy = "normal_retry"
                    should_record_error_after_retry = True
                
                if (not is_codex_request) and read_error_strategy == "switch_api":
                    # é…ç½®ä¸ºswitch_apiç­–ç•¥ï¼šå¼ºåˆ¶åˆ‡æ¢API
                    read_error_msg = f"[SSLè¯»å–é”™è¯¯-åˆ‡æ¢API][{request_id}] æ£€æµ‹åˆ°SSLè¯»å–é”™è¯¯æˆ–è¿æ¥ä¸­æ–­ï¼Œå¼ºåˆ¶åˆ‡æ¢API"
                    retry_errors.append(read_error_msg)
                    print(read_error_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°ReadErroræ£€æµ‹
                    
                    # ReadErrorè§†ä¸ºä¸¥é‡è¿æ¥é”™è¯¯ï¼Œç›´æ¥è®°å½•é”™è¯¯å¹¶å°è¯•åˆ‡æ¢API
                    current_api_index = current_config_index
                    switch_success, new_api_index = smart_switch_api(current_api_index, 503)  # ä½¿ç”¨503é”™è¯¯ç è§¦å‘åˆ‡æ¢
                    if switch_success:
                        read_switch_msg = f"[SSLè¯»å–é”™è¯¯-åˆ‡æ¢APIæˆåŠŸ][{request_id}] APIåˆ‡æ¢æˆåŠŸï¼Œä½¿ç”¨æ–°APIé‡è¯•"
                        retry_errors.append(read_switch_msg)
                        print(read_switch_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°ReadErroråˆ‡æ¢æˆåŠŸ
                        # é‡æ–°æ„å»ºè¯·æ±‚å¤´å’ŒURLï¼Œä½¿ç”¨æ–°API
                        is_valid, real_auth_header, error_msg = validate_and_replace_user_key(user_auth_header)
                        if is_valid:
                            headers['authorization'] = real_auth_header
                            new_upstream_url = build_upstream_url(clean_path, request.url.query, is_openai_format, base_url_override)
                            
                            # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä¿®æ”¹é‡è¯•è¯·æ±‚å¤´
                            read_error_retry_headers = headers.copy()
                            if TimeoutConfig.get_modify_retry_headers():
                                read_error_retry_headers['connection'] = 'close'
                                import random
                                import time
                                read_error_rand = random.randint(1000,9999)
                                read_error_timestamp = int(time.time() * 1000)
                                read_error_retry_headers['x-request-id'] = f"{request_id}-readerror-{retry_attempt + 1}-{read_error_rand}"
                                read_error_retry_headers['cache-control'] = 'no-cache, no-store, must-revalidate'
                                read_error_retry_headers['pragma'] = 'no-cache'
                                read_error_retry_headers['expires'] = '0'
                                read_error_retry_headers['x-cache-bypass'] = f'{read_error_timestamp}-{read_error_rand}'
                                read_error_retry_headers['x-retry-count'] = str(retry_attempt + 1)
                        
                        try:
                            # ä½¿ç”¨æ–°çš„é‡è¯•å®¢æˆ·ç«¯
                            read_error_retry_client = httpx.AsyncClient(timeout=timeout, limits=limits)
                            read_error_upstream_req = read_error_retry_client.build_request(
                                method=request.method,
                                url=new_upstream_url,
                                headers=read_error_retry_headers,
                                content=converted_body
                            )
                            upstream_resp = await read_error_retry_client.send(read_error_upstream_req, stream=True)
                            retry_client = read_error_retry_client  # æ›´æ–°é‡è¯•å®¢æˆ·ç«¯å¼•ç”¨
                            read_status_msg = f"[SSLè¯»å–é”™è¯¯-åˆ‡æ¢API][{request_id}] æ–°APIå“åº”çŠ¶æ€ç : {upstream_resp.status_code}"
                            retry_errors.append(read_status_msg)
                            print(read_status_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°æ–°APIçŠ¶æ€ç 
                            # åªæœ‰æˆåŠŸå“åº”ï¼ˆ< 400ï¼‰æ‰è·³å‡ºé‡è¯•å¾ªç¯ï¼Œé”™è¯¯å“åº”ç»§ç»­é‡è¯•
                            if upstream_resp.status_code < 400:
                                retry_errors.clear()
                                break
                            else:
                                read_error_status_msg = f"[SSLè¯»å–é”™è¯¯-åˆ‡æ¢API][{request_id}] æ–°APIä»è¿”å›é”™è¯¯{upstream_resp.status_code}ï¼Œç»§ç»­é‡è¯•"
                                retry_errors.append(read_error_status_msg)
                                print(read_error_status_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°æ–°APIé”™è¯¯
                                await upstream_resp.aclose()
                                await read_error_retry_client.aclose()
                                # ä¸breakï¼Œç»§ç»­ä¸‹ä¸€æ¬¡é‡è¯•
                        except Exception as read_error_retry_exception:
                            retry_errors.append(f"[SSLè¯»å–é”™è¯¯-åˆ‡æ¢APIå¤±è´¥][{request_id}] æ–°APIé‡è¯•ä¹Ÿå¤±è´¥: {read_error_retry_exception}")
                            await read_error_retry_client.aclose()
                    else:
                        read_fail_msg = f"[SSLè¯»å–é”™è¯¯-åˆ‡æ¢APIå¤±è´¥][{request_id}] APIåˆ‡æ¢å¤±è´¥ï¼Œç»§ç»­æ­£å¸¸é‡è¯•æµç¨‹"
                        retry_errors.append(read_fail_msg)
                        print(read_fail_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°ReadErroråˆ‡æ¢å¤±è´¥
            
            # ç‰¹æ®Šå¤„ç†ConnectErrorï¼šæ ¹æ®é…ç½®å†³å®šå¤„ç†ç­–ç•¥
            if isinstance(e, httpx.ConnectError):
                connect_error_strategy = TimeoutConfig.get_network_error_strategy("ConnectError")
                
                if is_codex_request:
                    # Codexè¯·æ±‚çš„ConnectErrorï¼šæ¯æ¬¡éƒ½è®°å½•é”™è¯¯ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    retry_errors.append(f"[è¿æ¥å¤±è´¥][{request_id}] Codexæ£€æµ‹åˆ°è¿æ¥é”™è¯¯")
                    msg = record_codex_error(codex_current_config_index, 503, silent=True)
                    if msg:
                        retry_errors.append(msg)
                # Claudeè¯·æ±‚çš„ConnectErrorï¼šä¸åœ¨è¿™é‡Œè®°å½•é”™è¯¯ï¼Œæ”¹ä¸ºåœ¨é‡è¯•å¾ªç¯ç»“æŸåç»Ÿä¸€è®°å½•
                
                # ä¸ºnormal_retryç­–ç•¥è®¾ç½®é”™è¯¯è®°å½•æ ‡å¿—
                if (not is_codex_request) and connect_error_strategy == "normal_retry":
                    last_error_status_code = 503
                    last_error_strategy = "normal_retry"
                    should_record_error_after_retry = True
                
                if (not is_codex_request) and connect_error_strategy == "switch_api":
                    # é…ç½®ä¸ºswitch_apiç­–ç•¥ï¼šå¼ºåˆ¶åˆ‡æ¢API
                    connect_error_msg = f"[è¿æ¥å¤±è´¥-åˆ‡æ¢API][{request_id}] æ£€æµ‹åˆ°è¿æ¥é”™è¯¯ï¼Œå¼ºåˆ¶åˆ‡æ¢API"
                    retry_errors.append(connect_error_msg)
                    print(connect_error_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°ConnectErroræ£€æµ‹
                    
                    # ConnectErrorè§†ä¸ºä¸¥é‡è¿æ¥é”™è¯¯ï¼Œç›´æ¥è®°å½•é”™è¯¯å¹¶å°è¯•åˆ‡æ¢API
                    current_api_index = current_config_index
                    switch_success, new_api_index = smart_switch_api(current_api_index, 503)  # ä½¿ç”¨503é”™è¯¯ç è§¦å‘åˆ‡æ¢
                    if switch_success:
                        connect_switch_msg = f"[è¿æ¥å¤±è´¥-åˆ‡æ¢APIæˆåŠŸ][{request_id}] APIåˆ‡æ¢æˆåŠŸï¼Œä½¿ç”¨æ–°APIé‡è¯•"
                        retry_errors.append(connect_switch_msg)
                        print(connect_switch_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°ConnectErroråˆ‡æ¢æˆåŠŸ
                        # é‡æ–°æ„å»ºè¯·æ±‚å¤´å’ŒURLï¼Œä½¿ç”¨æ–°API
                        is_valid, real_auth_header, error_msg = validate_and_replace_user_key(user_auth_header)
                        if is_valid:
                            headers['authorization'] = real_auth_header
                            new_upstream_url = build_upstream_url(clean_path, request.url.query, is_openai_format, base_url_override)
                            
                            # ä½¿ç”¨å…¨æ–°headerså‰¯æœ¬ï¼Œå¼ºåˆ¶æ–­å¼€æ—§è¿æ¥
                            connect_error_retry_headers = headers.copy()
                            if TimeoutConfig.get_modify_retry_headers():
                                connect_error_retry_headers['connection'] = 'close'
                                import random
                                import time
                                connect_error_rand = random.randint(1000,9999)
                                connect_error_timestamp = int(time.time() * 1000)
                                connect_error_retry_headers['x-request-id'] = f"{request_id}-connecterror-{retry_attempt + 1}-{connect_error_rand}"
                                connect_error_retry_headers['cache-control'] = 'no-cache, no-store, must-revalidate'
                                connect_error_retry_headers['pragma'] = 'no-cache'
                                connect_error_retry_headers['expires'] = '0'
                                connect_error_retry_headers['x-cache-bypass'] = f'{connect_error_timestamp}-{connect_error_rand}'
                                connect_error_retry_headers['x-retry-count'] = str(retry_attempt + 1)
                        
                        try:
                            # ä½¿ç”¨æ–°çš„é‡è¯•å®¢æˆ·ç«¯
                            connect_error_retry_client = httpx.AsyncClient(timeout=timeout, limits=limits)
                            connect_error_upstream_req = connect_error_retry_client.build_request(
                                method=request.method,
                                url=new_upstream_url,
                                headers=connect_error_retry_headers,
                                content=converted_body
                            )
                            upstream_resp = await connect_error_retry_client.send(connect_error_upstream_req, stream=True)
                            retry_client = connect_error_retry_client  # æ›´æ–°é‡è¯•å®¢æˆ·ç«¯å¼•ç”¨
                            connect_status_msg = f"[è¿æ¥å¤±è´¥-åˆ‡æ¢API][{request_id}] æ–°APIå“åº”çŠ¶æ€ç : {upstream_resp.status_code}"
                            retry_errors.append(connect_status_msg)
                            print(connect_status_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°æ–°APIçŠ¶æ€ç 
                            # åªæœ‰æˆåŠŸå“åº”ï¼ˆ< 400ï¼‰æ‰è·³å‡ºé‡è¯•å¾ªç¯ï¼Œé”™è¯¯å“åº”ç»§ç»­é‡è¯•
                            if upstream_resp.status_code < 400:
                                retry_errors.clear()
                                break
                            else:
                                connect_error_status_msg = f"[è¿æ¥å¤±è´¥-åˆ‡æ¢API][{request_id}] æ–°APIä»è¿”å›é”™è¯¯{upstream_resp.status_code}ï¼Œç»§ç»­é‡è¯•"
                                retry_errors.append(connect_error_status_msg)
                                print(connect_error_status_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°æ–°APIé”™è¯¯
                                await upstream_resp.aclose()
                                await connect_error_retry_client.aclose()
                                # ä¸breakï¼Œç»§ç»­ä¸‹ä¸€æ¬¡é‡è¯•
                        except Exception as connect_error_retry_exception:
                            retry_errors.append(f"[è¿æ¥å¤±è´¥-åˆ‡æ¢APIå¤±è´¥][{request_id}] æ–°APIé‡è¯•ä¹Ÿå¤±è´¥: {connect_error_retry_exception}")
                            await connect_error_retry_client.aclose()
                    else:
                        connect_fail_msg = f"[è¿æ¥å¤±è´¥-åˆ‡æ¢APIå¤±è´¥][{request_id}] APIåˆ‡æ¢å¤±è´¥ï¼Œç»§ç»­æ­£å¸¸é‡è¯•æµç¨‹"
                        retry_errors.append(connect_fail_msg)
                        print(connect_fail_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°ConnectErroråˆ‡æ¢å¤±è´¥
            
            # ç‰¹æ®Šå¤„ç†ç½‘ç»œé”™è¯¯å’ŒHTTPStatusErrorï¼šæ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä½¿ç”¨ç­–ç•¥é‡è¯•
            is_read_timeout = isinstance(e, httpx.ReadTimeout)
            is_strategy_status = isinstance(e, httpx.HTTPStatusError) and "Strategy Retry Needed" in str(e)
            # æ£€æŸ¥å…¶ä»–ç½‘ç»œé”™è¯¯æ˜¯å¦é…ç½®ä¸ºstrategy_retry
            is_read_error_strategy = isinstance(e, httpx.ReadError) and TimeoutConfig.get_network_error_strategy("ReadError") == "strategy_retry"
            is_connect_error_strategy = isinstance(e, httpx.ConnectError) and TimeoutConfig.get_network_error_strategy("ConnectError") == "strategy_retry"
            # ReadTimeoutæ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä½¿ç”¨ç­–ç•¥é‡è¯•
            is_read_timeout_strategy = is_read_timeout and TimeoutConfig.get_network_error_strategy("ReadTimeout") == "strategy_retry"
            
            if (is_read_timeout_strategy or is_read_error_strategy or is_connect_error_strategy or is_strategy_status) and not is_codex_request:
                # è¯†åˆ«é”™è¯¯ç±»å‹
                if is_read_timeout_strategy:
                    error_type = "è¯»å–è¶…æ—¶"
                elif is_read_error_strategy:
                    error_type = "SSLè¯»å–é”™è¯¯"
                elif is_connect_error_strategy:
                    error_type = "è¿æ¥å¤±è´¥"
                else:
                    error_type = "ä¸´æ—¶æ€§çŠ¶æ€ç "
                strategy_detect_msg = f"[ç­–ç•¥é‡è¯•][{request_id}] æ£€æµ‹åˆ°{error_type}ï¼Œå°è¯•ç¬¬{retry_attempt + 1}ä¸ªç­–ç•¥"
                retry_errors.append(strategy_detect_msg)
                print(strategy_detect_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°ç­–ç•¥é‡è¯•æ£€æµ‹
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„é‡è¯•ç­–ç•¥
                if retry_attempt < len(READ_TIMEOUT_RETRY_CONFIGS):
                    retry_config = READ_TIMEOUT_RETRY_CONFIGS[retry_attempt]
                    strategy_use_msg = f"[ç­–ç•¥é‡è¯•][{request_id}] ä½¿ç”¨ç­–ç•¥: {retry_config['name']}"
                    retry_errors.append(strategy_use_msg)
                    print(strategy_use_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°ä½¿ç”¨ç­–ç•¥
                    
                    # æ„å»ºé‡è¯•URLï¼ˆä¸build_upstream_urlå‡½æ•°é€»è¾‘ä¿æŒä¸€è‡´ï¼‰
                    temp_upstream_url = f"{retry_config['base_url']}/{clean_path}"
                    
                    if request.url.query:
                        if is_openai_format:
                            temp_upstream_url += f"?{request.url.query}&beta=true"
                        else:
                            temp_upstream_url += f"?{request.url.query}"
                    elif is_openai_format:
                        temp_upstream_url += "?beta=true"
                    
                    # æ„å»ºä¸´æ—¶è¯·æ±‚å¤´ï¼Œä½¿ç”¨ç­–ç•¥é…ç½®çš„key
                    temp_headers = headers.copy()
                    temp_headers['authorization'] = f"Bearer {retry_config['key']}"
                    if TimeoutConfig.get_modify_retry_headers():
                        temp_headers['connection'] = 'close'
                        # æ·»åŠ å®Œæ•´çš„é˜²ç¼“å­˜å¤´éƒ¨ï¼Œç¡®ä¿ReadTimeouté‡è¯•æ—¶APIä¸ä½¿ç”¨ç¼“å­˜
                        import time
                        temp_rand = random.randint(1000,9999)
                        temp_timestamp = int(time.time() * 1000)
                        temp_headers['x-request-id'] = f"{request_id}-readtimeout-{retry_attempt + 1}-{temp_rand}"
                        temp_headers['cache-control'] = 'no-cache, no-store, must-revalidate'
                        temp_headers['pragma'] = 'no-cache'
                        temp_headers['expires'] = '0'
                        temp_headers['x-cache-bypass'] = f'{temp_timestamp}-{temp_rand}'
                        temp_headers['x-retry-count'] = str(retry_attempt + 1)
                    
                    # ä½¿ç”¨ç­–ç•¥é‡è¯•ä¸“ç”¨çš„è¶…æ—¶é…ç½®ï¼ˆ200ç§’è¯»å–è¶…æ—¶ï¼‰
                    extended_timeout = TimeoutConfig.get_strategy_retry_timeout()
                    temp_client = httpx.AsyncClient(timeout=extended_timeout, limits=limits)
                    try:
                        temp_upstream_req = temp_client.build_request(
                            method=request.method,
                            url=temp_upstream_url,
                            headers=temp_headers,
                            content=converted_body
                        )
                        upstream_resp = await temp_client.send(temp_upstream_req, stream=True)
                        strategy_status_msg = f"[ç­–ç•¥é‡è¯•][{request_id}] {retry_config['name']} å“åº”çŠ¶æ€ç : {upstream_resp.status_code}"
                        retry_errors.append(strategy_status_msg)
                        print(strategy_status_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°ç­–ç•¥å“åº”çŠ¶æ€ç 
                        
                        # åªæœ‰æˆåŠŸå“åº”ï¼ˆ< 400ï¼‰æ‰è·³å‡ºé‡è¯•å¾ªç¯ï¼Œé”™è¯¯å“åº”ç»§ç»­é‡è¯•
                        if upstream_resp.status_code < 400:
                            retry_errors.clear()
                            retry_client = temp_client
                            break
                        else:
                            strategy_error_msg = f"[ç­–ç•¥é‡è¯•][{request_id}] {retry_config['name']} ä»è¿”å›é”™è¯¯{upstream_resp.status_code}ï¼Œç»§ç»­é‡è¯•"
                            retry_errors.append(strategy_error_msg)
                            print(strategy_error_msg, file=sys.stderr)  # â† ç«‹å³æ‰“å°ç­–ç•¥é”™è¯¯
                            await upstream_resp.aclose()
                            await temp_client.aclose()
                            # ä¸breakï¼Œç»§ç»­ä¸‹ä¸€æ¬¡é‡è¯•
                        
                    except Exception as strategy_error:
                        error_type = type(strategy_error).__name__
                        error_msg = str(strategy_error) or "æ— é”™è¯¯ä¿¡æ¯"
                        strategy_fail_msg1 = f"[ç­–ç•¥é‡è¯•][{request_id}] {retry_config['name']} å¤±è´¥"
                        strategy_fail_msg2 = f"[ç­–ç•¥é‡è¯•][{request_id}] é”™è¯¯ç±»å‹: {error_type}"
                        strategy_fail_msg3 = f"[ç­–ç•¥é‡è¯•][{request_id}] é”™è¯¯è¯¦æƒ…: {error_msg}"
                        retry_errors.append(strategy_fail_msg1)
                        retry_errors.append(strategy_fail_msg2)
                        retry_errors.append(strategy_fail_msg3)
                        print(strategy_fail_msg1, file=sys.stderr)  # â† ç«‹å³æ‰“å°ç­–ç•¥å¤±è´¥
                        print(strategy_fail_msg2, file=sys.stderr)
                        print(strategy_fail_msg3, file=sys.stderr)
                        retry_errors.append(f"[ç­–ç•¥é‡è¯•][{request_id}] å°è¯•çš„URL: {temp_upstream_url}")
                        retry_errors.append(f"[ç­–ç•¥é‡è¯•][{request_id}] ä½¿ç”¨çš„Key: {retry_config['key'][:20]}...")
                        
                        # ç‰¹æ®Šæ£€æŸ¥ï¼šå¦‚æœæ˜¯httpsè¿æ¥é—®é¢˜ï¼Œç»™å‡ºå»ºè®®
                        if "https://anyrouter.top" in temp_upstream_url:
                            if "timeout" in error_msg.lower() or isinstance(strategy_error, (httpx.ReadTimeout, httpx.ConnectTimeout)):
                                retry_errors.append(f"[è¯»å–è¶…æ—¶-ç­–ç•¥é‡è¯•][{request_id}] æç¤º: anyrouter.topå¯èƒ½ç½‘ç»œå»¶è¿Ÿè¾ƒé«˜ï¼Œè€ƒè™‘æ£€æŸ¥ç½‘ç»œè¿æ¥")
                            elif "ssl" in error_msg.lower() or "certificate" in error_msg.lower():
                                retry_errors.append(f"[è¯»å–è¶…æ—¶-ç­–ç•¥é‡è¯•][{request_id}] æç¤º: anyrouter.topå¯èƒ½æœ‰SSLè¯ä¹¦é—®é¢˜")
                        
                        await temp_client.aclose()
                        # ç»§ç»­ä¸‹ä¸€ä¸ªé‡è¯•ç­–ç•¥
                else:
                    retry_errors.append(f"[è¯»å–è¶…æ—¶-ç­–ç•¥é‡è¯•][{request_id}] å·²è¶…å‡ºé¢„å®šä¹‰ç­–ç•¥æ•°é‡ï¼Œå›åˆ°æ­£å¸¸é‡è¯•é€»è¾‘")
                
                # Claudeè¯·æ±‚ï¼šå¦‚æœæ‰§è¡Œåˆ°è¿™é‡Œï¼Œè¯´æ˜å½“å‰çš„strategy_retryå°è¯•å¤±è´¥äº†
                # æ›´æ–°é”™è¯¯è¿½è¸ªä¿¡æ¯ï¼ˆä½†ä¸ç«‹å³è®°å½•ï¼Œç­‰æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥åç»Ÿä¸€è®°å½•ï¼‰
                if not is_codex_request:
                    last_error_strategy = "strategy_retry"
                    should_record_error_after_retry = True
            
            if retry_attempt < max_retries - 1:
                # è¿˜æœ‰é‡è¯•æœºä¼šï¼Œä½¿ç”¨é€’å¢å»¶è¿Ÿï¼ˆæŒ‡æ•°é€€é¿ï¼‰è®©ç½‘ç»œçŠ¶æ€æœ‰æ—¶é—´æ¢å¤
                import asyncio
                delay = 2 ** retry_attempt  # 1, 2, 4, 8ç§’çš„é€’å¢å»¶è¿Ÿ
                retry_errors.append(f"[{request_id}] ç­‰å¾… {delay} ç§’åé‡è¯•...")
                await asyncio.sleep(delay)
                continue
            else:
                # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥ï¼Œè¾“å‡ºæ‰€æœ‰æ”¶é›†çš„é”™è¯¯ä¿¡æ¯
                for err in retry_errors:
                    print(err, file=sys.stderr)
                
                # Claudeè¯·æ±‚ï¼šåœ¨æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥åï¼Œç»Ÿä¸€è®°å½•é”™è¯¯
                if not is_codex_request and should_record_error_after_retry:
                    if last_error_strategy == "switch_api" and last_error_status_code:
                        # switch_apiç­–ç•¥ï¼šé‡è¯•max_retriesæ¬¡éƒ½å¤±è´¥ï¼Œè®°å½•+1æ¬¡é”™è¯¯
                        msg = record_api_error(current_config_index, last_error_status_code, silent=True)
                        if msg:
                            print(msg, file=sys.stderr)
                    elif last_error_strategy == "strategy_retry":
                        # strategy_retryç­–ç•¥ï¼šæ‰€æœ‰å¤‡ç”¨èŠ‚ç‚¹éƒ½å¤±è´¥ï¼Œè®°å½•+1æ¬¡é”™è¯¯
                        msg = record_api_error(current_config_index, 503, silent=True)
                        if msg:
                            print(msg, file=sys.stderr)
                    elif last_error_strategy == "normal_retry" and last_error_status_code:
                        # normal_retryç­–ç•¥ï¼šé‡è¯•max_retriesæ¬¡éƒ½å¤±è´¥ï¼Œè®°å½•+1æ¬¡é”™è¯¯
                        msg = record_api_error(current_config_index, last_error_status_code, silent=True)
                        if msg:
                            print(msg, file=sys.stderr)
                
                import traceback
                error_message = f"Proxy Error: Could not connect to upstream server at {upstream_url}. Exception: {e}"
                print(f"[{request_id}] {error_message}", file=sys.stderr)
                print(f"[{request_id}] è¿æ¥é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}", file=sys.stderr)
                print(f"[{request_id}] è¯·æ±‚æ–¹æ³•: {request.method}, ç›®æ ‡URL: {upstream_url}", file=sys.stderr)
                print(f"[{request_id}] è¯·æ±‚å¤´: {dict(headers)}", file=sys.stderr)
                
                from fastapi.responses import Response
                
                # switch_apiç­–ç•¥ï¼šä¸ç«‹å³è¿”å›é”™è¯¯ï¼Œå°è¯•åˆ‡æ¢æ‰€æœ‰å¯ç”¨API
                strategies = config_mgr.get_error_handling_strategies()
                http_codes = strategies.get("http_status_codes", {})
                switch_api_codes = [int(code) for code, strategy in http_codes.items()
                                  if strategy == "switch_api" and code != "default"]
                
                # å¦‚æœé…ç½®äº†switch_apiç­–ç•¥ï¼Œå°è¯•æ‰©å±•é‡è¯•
                if len(switch_api_codes) > 0:
                    extended_retry_success = False
                    max_api_count = len(CODEX_CONFIGS) if is_codex_request else len(API_CONFIGS)
                    extended_switch_count = 0
                    max_extended_switches = max_api_count * 3  # æ¯ä¸ªAPIæœ€å¤šå°è¯•3æ¬¡
                    
                    print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] ä¸»é‡è¯•å¾ªç¯å¤±è´¥ï¼Œå¼€å§‹å°è¯•å…¶ä»–å¯ç”¨API...", file=sys.stderr)
                    
                    while extended_switch_count < max_extended_switches:
                        # å°è¯•åˆ‡æ¢API
                        if is_codex_request:
                            switch_success, new_index = smart_codex_switch_api(codex_current_config_index, 503)
                        else:
                            switch_success, new_index = smart_switch_api(current_config_index, 503)
                        
                        if not switch_success:
                            print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] æ— æ³•åˆ‡æ¢åˆ°æ–°APIï¼Œæ‰€æœ‰APIå·²å°è¯•", file=sys.stderr)
                            break
                        
                        extended_switch_count += 1
                        print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] ç¬¬{extended_switch_count}æ¬¡APIåˆ‡æ¢", file=sys.stderr)
                        
                        # é‡æ–°æ„å»ºè¯·æ±‚
                        try:
                            if is_codex_request:
                                current_codex_config = get_current_codex_config()
                                print(f"\n{get_current_codex_info()}")
                                upstream_url = build_upstream_url(clean_path, request.url.query, is_openai_format, current_codex_config["base_url"])
                                headers['authorization'] = f'Bearer {current_codex_config["key"]}'
                                
                                codex_timeout = httpx.Timeout(
                                    connect=TimeoutConfig.get_connect_timeout(),
                                    read=None,
                                    write=TimeoutConfig.get_write_timeout(),
                                    pool=TimeoutConfig.get_pool_timeout()
                                )
                                extended_client = httpx.AsyncClient(timeout=codex_timeout, limits=limits)
                            else:
                                is_valid, real_auth_header, error_msg = validate_and_replace_user_key(user_auth_header)
                                if is_valid:
                                    headers['authorization'] = real_auth_header
                                    upstream_url = build_upstream_url(clean_path, request.url.query, is_openai_format, base_url_override)
                                    print(f"\n{get_current_api_info()}")
                                else:
                                    print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] éªŒè¯Keyå¤±è´¥: {error_msg}", file=sys.stderr)
                                    break
                                
                                if should_convert_to_openai and not user_wants_stream:
                                    extended_client = httpx.AsyncClient(timeout=non_streaming_timeout, limits=limits)
                                else:
                                    extended_client = httpx.AsyncClient(timeout=timeout, limits=limits)
                            
                            # å‘é€è¯·æ±‚
                            extended_headers = headers.copy()
                            if TimeoutConfig.get_modify_retry_headers():
                                extended_headers['connection'] = 'close'
                                import random, time
                                ext_rand = random.randint(1000,9999)
                                ext_timestamp = int(time.time() * 1000)
                                extended_headers['x-request-id'] = f"{request_id}-extended-{extended_switch_count}-{ext_rand}"
                                extended_headers['cache-control'] = 'no-cache, no-store, must-revalidate'
                                extended_headers['pragma'] = 'no-cache'
                                extended_headers['expires'] = '0'
                                extended_headers['x-cache-bypass'] = f'{ext_timestamp}-{ext_rand}'
                            
                            extended_req = extended_client.build_request(
                                method=request.method,
                                url=upstream_url,
                                headers=extended_headers,
                                content=converted_body
                            )
                            
                            if is_codex_request:
                                import asyncio
                                try:
                                    extended_resp = await asyncio.wait_for(
                                        extended_client.send(extended_req, stream=True),
                                        timeout=TimeoutConfig.get_codex_connect_timeout()
                                    )
                                except asyncio.TimeoutError:
                                    print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] Codexè¿æ¥è¶…æ—¶", file=sys.stderr)
                                    await extended_client.aclose()
                                    continue
                            else:
                                extended_resp = await extended_client.send(extended_req, stream=True)
                            
                            print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] å“åº”çŠ¶æ€ç : {extended_resp.status_code}", file=sys.stderr)
                            
                            # æ£€æŸ¥å“åº”
                            if extended_resp.status_code < 400:
                                # æˆåŠŸï¼ä½¿ç”¨è¿™ä¸ªå“åº”
                                print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] æˆåŠŸï¼ä½¿ç”¨æ–°APIå“åº”", file=sys.stderr)
                                upstream_resp = extended_resp
                                retry_client = extended_client
                                extended_retry_success = True
                                retry_errors.clear()  # æ¸…ç©ºé”™è¯¯åˆ—è¡¨
                                break
                            else:
                                # å¤±è´¥ï¼Œç»§ç»­å°è¯•å…¶ä»–API
                                print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] APIè¿”å›é”™è¯¯{extended_resp.status_code}ï¼Œç»§ç»­å°è¯•å…¶ä»–API", file=sys.stderr)
                                if is_codex_request:
                                    record_codex_error(codex_current_config_index, extended_resp.status_code, silent=True)
                                else:
                                    record_api_error(current_config_index, extended_resp.status_code, silent=True)
                                await extended_resp.aclose()
                                await extended_client.aclose()
                                continue
                        
                        except Exception as extended_error:
                            print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] æ‰©å±•é‡è¯•å¼‚å¸¸: {extended_error}", file=sys.stderr)
                            if is_codex_request:
                                record_codex_error(codex_current_config_index, 503, silent=True)
                            else:
                                record_api_error(current_config_index, 503, silent=True)
                            await extended_client.aclose()
                            continue
                    
                    # å¦‚æœæ‰©å±•é‡è¯•æˆåŠŸï¼Œä¸è¿”å›é”™è¯¯ï¼Œç»§ç»­æ­£å¸¸æµç¨‹
                    if not extended_retry_success:
                        print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] æ‰€æœ‰APIå‡å·²å°è¯•ï¼Œä»ç„¶å¤±è´¥", file=sys.stderr)
                        return Response(content=error_message, status_code=502)
                else:
                    # éswitch_apiç­–ç•¥ï¼Œç›´æ¥è¿”å›é”™è¯¯
                    return Response(content=error_message, status_code=502)
    
    # ç¡®ä¿å…³é—­é‡è¯•åˆ›å»ºçš„clientå®ä¾‹ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    if 'retry_client' in locals() and retry_client != client:
        # å»¶è¿Ÿå…³é—­ï¼Œç¡®ä¿å“åº”å¤„ç†å®Œæˆåå†å…³é—­
        pass  # åç»­åœ¨finallyå—ä¸­å¤„ç†
    
    # åˆ é™¤è¯¦ç»†çš„ä¸Šæ¸¸å“åº”è®°å½•
    
    # æ£€æŸ¥ä¸Šæ¸¸å“åº”çŠ¶æ€ç ï¼Œå¤„ç†é”™è¯¯æƒ…å†µ
    if upstream_resp.status_code < 400:
        # è¯·æ±‚æˆåŠŸï¼Œé‡ç½®å½“å‰APIçš„é”™è¯¯è®¡æ•°
        if not is_codex_request:
            current_api_index = current_config_index
            if (api_status[current_api_index]["error_count"] > 0 or
                api_status[current_api_index]["cooldown_until"] is not None):
                api_status[current_api_index].update({
                    "error_count": 0,
                    "cooldown_until": None,
                    "status": "normal"
                })
                print(f"[{datetime.now().strftime('%H:%M:%S')}] API {API_CONFIGS[current_api_index]['name']} è¯·æ±‚æˆåŠŸï¼Œå®Œå…¨é‡ç½®çŠ¶æ€", file=sys.stderr)
        else:
            # Codexè¯·æ±‚æˆåŠŸï¼Œé‡ç½®é”™è¯¯è®¡æ•°
            current_codex_index = codex_current_config_index
            if current_codex_index < len(CODEX_CONFIGS) and current_codex_index in codex_api_status:
                if (codex_api_status[current_codex_index]["error_count"] > 0 or
                    codex_api_status[current_codex_index]["cooldown_until"] is not None):
                    codex_api_status[current_codex_index].update({
                        "error_count": 0,
                        "cooldown_until": None,
                        "status": "normal"
                    })
                    print(f"[{datetime.now().strftime('%H:%M:%S')}] Codex {CODEX_CONFIGS[current_codex_index]['name']} è¯·æ±‚æˆåŠŸï¼Œå®Œå…¨é‡ç½®çŠ¶æ€", file=sys.stderr)
    else:
        # é‡è¯•å¾ªç¯æ­£å¸¸ç»“æŸä½†è¯·æ±‚å¤±è´¥ï¼ˆstatus_code >= 400ï¼‰
        # å¯¹äºswitch_apiç­–ç•¥ï¼Œå…ˆå°è¯•æ‰©å±•é‡è¯•ï¼Œåªæœ‰æ‰€æœ‰APIéƒ½å¤±è´¥åæ‰è®°å½•é”™è¯¯
        strategies = config_mgr.get_error_handling_strategies()
        http_codes = strategies.get("http_status_codes", {})
        switch_api_codes = [int(code) for code, strategy in http_codes.items()
                          if strategy == "switch_api" and code != "default"]
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯switch_apiç­–ç•¥çš„é”™è¯¯
        if upstream_resp.status_code in switch_api_codes and len(switch_api_codes) > 0:
            extended_retry_success = False
            max_api_count = len(CODEX_CONFIGS) if is_codex_request else len(API_CONFIGS)
            extended_switch_count = 0
            max_extended_switches = max_api_count * 3  # æ¯ä¸ªAPIæœ€å¤šå°è¯•3æ¬¡
            
            print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] æ£€æµ‹åˆ°switch_apié”™è¯¯{upstream_resp.status_code}ï¼Œå¼€å§‹å°è¯•å…¶ä»–å¯ç”¨API...", file=sys.stderr)
            
            # ä¿å­˜é”™è¯¯çŠ¶æ€ç 
            failed_status_code = upstream_resp.status_code
            
            # å…³é—­å½“å‰å¤±è´¥çš„å“åº”
            await upstream_resp.aclose()
            
            while extended_switch_count < max_extended_switches:
                # å°è¯•åˆ‡æ¢API
                if is_codex_request:
                    switch_success, new_index = smart_codex_switch_api(codex_current_config_index, failed_status_code)
                else:
                    switch_success, new_index = smart_switch_api(current_config_index, failed_status_code)
                
                if not switch_success:
                    print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] æ— æ³•åˆ‡æ¢åˆ°æ–°APIï¼Œæ‰€æœ‰APIå·²å°è¯•", file=sys.stderr)
                    break
                
                extended_switch_count += 1
                print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] ç¬¬{extended_switch_count}æ¬¡APIåˆ‡æ¢", file=sys.stderr)
                
                # é‡æ–°æ„å»ºè¯·æ±‚
                try:
                    if is_codex_request:
                        current_codex_config = get_current_codex_config()
                        print(f"\n{get_current_codex_info()}")
                        upstream_url = build_upstream_url(clean_path, request.url.query, is_openai_format, current_codex_config["base_url"])
                        headers['authorization'] = f'Bearer {current_codex_config["key"]}'
                        
                        codex_timeout = httpx.Timeout(
                            connect=TimeoutConfig.get_connect_timeout(),
                            read=None,
                            write=TimeoutConfig.get_write_timeout(),
                            pool=TimeoutConfig.get_pool_timeout()
                        )
                        extended_client = httpx.AsyncClient(timeout=codex_timeout, limits=limits)
                    else:
                        is_valid, real_auth_header, error_msg = validate_and_replace_user_key(user_auth_header)
                        if is_valid:
                            headers['authorization'] = real_auth_header
                            upstream_url = build_upstream_url(clean_path, request.url.query, is_openai_format, base_url_override)
                            print(f"\n{get_current_api_info()}")
                        else:
                            print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] éªŒè¯Keyå¤±è´¥: {error_msg}", file=sys.stderr)
                            break
                        
                        if should_convert_to_openai and not user_wants_stream:
                            extended_client = httpx.AsyncClient(timeout=non_streaming_timeout, limits=limits)
                        else:
                            extended_client = httpx.AsyncClient(timeout=timeout, limits=limits)
                    
                    # å‘é€è¯·æ±‚
                    extended_headers = headers.copy()
                    if TimeoutConfig.get_modify_retry_headers():
                        extended_headers['connection'] = 'close'
                        import random, time
                        ext_rand = random.randint(1000,9999)
                        ext_timestamp = int(time.time() * 1000)
                        extended_headers['x-request-id'] = f"{request_id}-extended-{extended_switch_count}-{ext_rand}"
                        extended_headers['cache-control'] = 'no-cache, no-store, must-revalidate'
                        extended_headers['pragma'] = 'no-cache'
                        extended_headers['expires'] = '0'
                        extended_headers['x-cache-bypass'] = f'{ext_timestamp}-{ext_rand}'
                    
                    extended_req = extended_client.build_request(
                        method=request.method,
                        url=upstream_url,
                        headers=extended_headers,
                        content=converted_body
                    )
                    
                    if is_codex_request:
                        import asyncio
                        try:
                            extended_resp = await asyncio.wait_for(
                                extended_client.send(extended_req, stream=True),
                                timeout=TimeoutConfig.get_codex_connect_timeout()
                            )
                        except asyncio.TimeoutError:
                            print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] Codexè¿æ¥è¶…æ—¶", file=sys.stderr)
                            await extended_client.aclose()
                            continue
                    else:
                        extended_resp = await extended_client.send(extended_req, stream=True)
                    
                    print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] å“åº”çŠ¶æ€ç : {extended_resp.status_code}", file=sys.stderr)
                    
                    # æ£€æŸ¥å“åº”
                    if extended_resp.status_code < 400:
                        # æˆåŠŸï¼ä½¿ç”¨è¿™ä¸ªå“åº”
                        print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] æˆåŠŸï¼ä½¿ç”¨æ–°APIå“åº”", file=sys.stderr)
                        upstream_resp = extended_resp
                        retry_client = extended_client
                        extended_retry_success = True
                        retry_errors.clear()  # æ¸…ç©ºé”™è¯¯åˆ—è¡¨
                        break
                    elif extended_resp.status_code in switch_api_codes:
                        # ä»ç„¶æ˜¯switch_apié”™è¯¯ï¼Œç»§ç»­å°è¯•å…¶ä»–API
                        print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] APIè¿”å›é”™è¯¯{extended_resp.status_code}ï¼Œç»§ç»­å°è¯•å…¶ä»–API", file=sys.stderr)
                        if is_codex_request:
                            record_codex_error(codex_current_config_index, extended_resp.status_code, silent=True)
                        else:
                            record_api_error(current_config_index, extended_resp.status_code, silent=True)
                        await extended_resp.aclose()
                        await extended_client.aclose()
                        continue
                    else:
                        # ä¸åŒç±»å‹çš„é”™è¯¯ï¼Œåœæ­¢æ‰©å±•é‡è¯•
                        print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] APIè¿”å›éswitch_apié”™è¯¯{extended_resp.status_code}ï¼Œåœæ­¢æ‰©å±•é‡è¯•", file=sys.stderr)
                        upstream_resp = extended_resp
                        retry_client = extended_client
                        break
                
                except Exception as extended_error:
                    print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] æ‰©å±•é‡è¯•å¼‚å¸¸: {extended_error}", file=sys.stderr)
                    if is_codex_request:
                        record_codex_error(codex_current_config_index, 503, silent=True)
                    else:
                        record_api_error(current_config_index, 503, silent=True)
                    await extended_client.aclose()
                    continue
            
            # å¦‚æœæ‰©å±•é‡è¯•å¤±è´¥ï¼Œç»§ç»­è®°å½•é”™è¯¯
            if not extended_retry_success:
                print(f"[switch_apiæ‰©å±•é‡è¯•][{request_id}] æ‰€æœ‰APIå‡å·²å°è¯•ï¼Œä»ç„¶å¤±è´¥ï¼Œè®°å½•é”™è¯¯", file=sys.stderr)
        
        # è®°å½•é”™è¯¯ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
        if not is_codex_request and should_record_error_after_retry and upstream_resp.status_code >= 400:
            if last_error_strategy == "switch_api" and last_error_status_code:
                # switch_apiç­–ç•¥ï¼šé‡è¯•max_retriesæ¬¡éƒ½å¤±è´¥ï¼Œè®°å½•+1æ¬¡é”™è¯¯
                msg = record_api_error(current_config_index, last_error_status_code, silent=True)
                if msg:
                    print(msg, file=sys.stderr)
            elif last_error_strategy == "strategy_retry":
                # strategy_retryç­–ç•¥ï¼šæ‰€æœ‰å¤‡ç”¨èŠ‚ç‚¹éƒ½å¤±è´¥ï¼Œè®°å½•+1æ¬¡é”™è¯¯
                msg = record_api_error(current_config_index, 503, silent=True)
                if msg:
                    print(msg, file=sys.stderr)
            elif last_error_strategy == "normal_retry" and last_error_status_code:
                # normal_retryç­–ç•¥ï¼šé‡è¯•max_retriesæ¬¡éƒ½å¤±è´¥ï¼Œè®°å½•+1æ¬¡é”™è¯¯
                msg = record_api_error(current_config_index, last_error_status_code, silent=True)
                if msg:
                    print(msg, file=sys.stderr)
    
    if upstream_resp.status_code >= 400:
        error_msg = f"ä¸Šæ¸¸APIè¿”å›é”™è¯¯çŠ¶æ€ç : {upstream_resp.status_code}"
        
        # HTTPçŠ¶æ€ç é”™è¯¯å¤„ç†
        
        # å¤„ç†æŒç»­æ€§è®¤è¯/æƒé™é”™è¯¯ï¼Œå°è¯•æ™ºèƒ½åˆ‡æ¢APIå¹¶é‡è¯•
        # æ³¨æ„ï¼šä¸´æ—¶æ€§é”™è¯¯ï¼ˆ400, 404, 429, 500, 502, 503, 520-524ï¼‰å·²ç”±ç­–ç•¥é‡è¯•å¤„ç†
        if (not is_codex_request) and upstream_resp.status_code in [401, 403]:
            # è·å–å½“å‰APIç´¢å¼•
            current_api_index = current_config_index
            
            # å°è¯•æ™ºèƒ½åˆ‡æ¢API
            switch_success, new_api_index = smart_switch_api(current_api_index, upstream_resp.status_code)
            
            if switch_success:
                
                # é‡æ–°æ„å»ºè¯·æ±‚å¤´ï¼Œä½¿ç”¨æ–°çš„API key
                is_valid, real_auth_header, error_msg = validate_and_replace_user_key(user_auth_header)
                if is_valid:
                    headers['authorization'] = real_auth_header
                    
                    # é‡æ–°æ„å»ºè¯·æ±‚URLä½¿ç”¨æ–°API
                    try:
                        await upstream_resp.aclose()  # å…³é—­åŸæœ‰è¿æ¥
                        
                        # é‡æ–°æ„å»ºURLä½¿ç”¨æ–°API (åŠ¨æ€å¤´éƒ¨å·²è‡ªåŠ¨é¿å…ç¼“å­˜)
                        new_upstream_url = build_upstream_url(clean_path, request.url.query, is_openai_format, base_url_override)
                        
                        # è·å–é‡è¯•APIé…ç½®
                        retry_config = get_current_config()
                        
                        # APIåˆ‡æ¢é‡è¯•ä¹Ÿè¦ä½¿ç”¨å…¨æ–°headerså‰¯æœ¬ï¼Œå¼ºåˆ¶æ–­å¼€æ—§è¿æ¥
                        api_switch_headers = headers.copy()
                        if TimeoutConfig.get_modify_retry_headers():
                            api_switch_headers['connection'] = 'close'
                            # æ·»åŠ å®Œæ•´çš„é˜²ç¼“å­˜å¤´éƒ¨ï¼Œç¡®ä¿APIåˆ‡æ¢é‡è¯•æ—¶ä¸ä½¿ç”¨ç¼“å­˜
                            import time
                            api_switch_rand = random.randint(1000,9999)
                            api_switch_timestamp = int(time.time() * 1000)
                            api_switch_headers['x-request-id'] = f"{request_id}-apiswitch-{api_switch_rand}"
                            api_switch_headers['cache-control'] = 'no-cache, no-store, must-revalidate'
                            api_switch_headers['pragma'] = 'no-cache'
                            api_switch_headers['expires'] = '0'
                            api_switch_headers['x-cache-bypass'] = f'{api_switch_timestamp}-{api_switch_rand}'
                        
                        upstream_req = retry_client.build_request(
                            method=request.method,
                            url=new_upstream_url,
                            headers=api_switch_headers,  # ä½¿ç”¨APIåˆ‡æ¢ä¸“ç”¨headers
                            content=converted_body
                        )
                        upstream_resp = await retry_client.send(upstream_req, stream=True)
                        
                        
                        # å¦‚æœé‡è¯•æˆåŠŸï¼Œç»§ç»­æ­£å¸¸å¤„ç†
                        if upstream_resp.status_code < 400:
                            # è®°å½•æˆåŠŸåˆ‡æ¢åˆ°æ—¥å¿—
                            if ENABLE_FULL_LOG and full_logger:
                                full_logger.info(f"é”™è¯¯é‡è¯•æˆåŠŸ - çŠ¶æ€ç : {upstream_resp.status_code} - ä½¿ç”¨: {API_CONFIGS[new_api_index]['name']}")
                        else:
                            pass
                    except Exception as retry_error:
                        pass
                else:
                    pass
            else:
                pass
        # å¦‚æœä»ç„¶æ˜¯é”™è¯¯çŠ¶æ€ç ï¼Œæ‰§è¡ŒåŸæœ‰é”™è¯¯å¤„ç†é€»è¾‘
        if upstream_resp.status_code >= 400:
            # å¯¹äºOpenAIå®¢æˆ·ç«¯ï¼Œè½¬æ¢é”™è¯¯å“åº”æ ¼å¼
            if should_convert_to_openai:
                try:
                    # è¯»å–é”™è¯¯å“åº”å†…å®¹
                    error_content = await upstream_resp.aread()
                    error_text = error_content.decode('utf-8', errors='ignore')
                    
                    # æ„é€ OpenAIæ ¼å¼çš„é”™è¯¯å“åº”
                    openai_error = {
                        "error": {
                            "message": f"Upstream API error (status {upstream_resp.status_code}): {error_text}",
                            "type": "upstream_error",
                            "code": "api_error"
                        }
                    }
                    
                    if ENABLE_FULL_LOG and full_logger:
                        full_logger.error(f"ä¸Šæ¸¸APIé”™è¯¯ - çŠ¶æ€ç : {upstream_resp.status_code}")
                        full_logger.error(f"é”™è¯¯å†…å®¹: {error_text}")
                        full_logger.error(f"è¯·æ±‚ID: {request_id} - å¤„ç†å¤±è´¥")
                        full_logger.error("="*80)
                        # æ£€æŸ¥å¹¶ä¿®å‰ªæ—¥å¿—æ–‡ä»¶å¤§å°
                        trim_log_file(LOG_FILE_PATH)
                    
                    return JSONResponse(
                        content=openai_error,
                        status_code=upstream_resp.status_code,
                        headers={"content-type": "application/json"}
                    )
                except Exception as error_process_error:
                    print(f"å¤„ç†ä¸Šæ¸¸é”™è¯¯å“åº”æ—¶å‡ºé”™: {error_process_error}", file=sys.stderr)

    # 7. æ ¹æ®ç”¨æˆ·åŸå§‹è¯·æ±‚å†³å®šå“åº”å¤„ç†æ–¹å¼
    if should_convert_to_openai and not user_wants_stream:
        # ç”¨æˆ·è¦æ±‚éæµå¼å“åº”ï¼Œéœ€è¦æ”¶é›†å®Œæ•´æµå¼æ•°æ®ç„¶åè½¬æ¢ä¸ºJSON
        try:
            # æ”¶é›†æ‰€æœ‰æµå¼æ•°æ®
            all_chunks = []
            async for chunk in upstream_resp.aiter_raw():
                all_chunks.append(chunk)
            
            # åˆå¹¶æ‰€æœ‰æ•°æ®
            complete_response = b''.join(all_chunks)
            response_text = complete_response.decode('utf-8', errors='ignore')
            
            
            # ã€é”™è¯¯æ£€æµ‹ã€‘ä½¿ç”¨å¢å¼ºçš„é”™è¯¯æ£€æµ‹åŠŸèƒ½
            is_error, error_info, decompressed_content = detect_compressed_error(response_text.encode('utf-8'))
            
            # å¦‚æœæ£€æµ‹åˆ°é”™è¯¯ï¼Œä½¿ç”¨ç»Ÿä¸€é”™è¯¯å¤„ç†å‡½æ•°
            if is_error and not is_codex_request:
                handle_detected_error(request_id, error_info, decompressed_content, "éæµå¼")
            
            # è§£ææµå¼æ•°æ®å¹¶æå–å†…å®¹
            full_content = ""
            lines = response_text.split('\n')
            
            for line in lines:
                if line.startswith('data: ') and line != 'data: [DONE]':
                    try:
                        json_str = line[6:]  # ç§»é™¤ 'data: '
                        claude_data = json.loads(json_str)
                        
                        # æå–æ–‡æœ¬å†…å®¹
                        if claude_data.get("type") == "content_block_delta":
                            delta = claude_data.get("delta", {})
                            if delta.get("type") == "text_delta":
                                full_content += delta.get("text", "")
                                
                    except json.JSONDecodeError:
                        continue
            
            # æ„é€ æ ‡å‡†OpenAI JSONå“åº”
            openai_response = {
                "id": "chatcmpl-adapter",
                "object": "chat.completion",
                "created": int(time.time()),
                "model": original_request_data.get("model", "gpt-4"),
                "choices": [
                    {
                        "index": 0,
                        "message": {
                            "role": "assistant",
                            "content": full_content
                        },
                        "finish_reason": "stop"
                    }
                ],
                "usage": {
                    "prompt_tokens": 0,
                    "completion_tokens": 0,
                    "total_tokens": 0
                }
            }
            
            # æ„å»ºå“åº”ä¿¡æ¯æ˜¾ç¤º
            response_info = f"å“åº”: {upstream_resp.status_code}"
            if model_conversion_info:
                response_info += f" | {model_conversion_info}"
            response_info += " | Claude â†’ OpenAIæ ¼å¼"
            
            print(response_info)
            
            # è®°å½•å®Œæ•´è¾“å‡ºæ•°æ®ï¼ˆéæµå¼å“åº”ï¼‰
            log_original_response(request_id, all_chunks, is_codex_request)

            # âœ… å®æ—¶ç»Ÿè®¡tokenä½¿ç”¨é‡ï¼ˆéæµå¼å“åº”ï¼‰
            if stats_mgr and all_chunks:
                try:
                    usage_data = extract_usage_from_chunks(all_chunks, is_codex_request)
                    if usage_data:
                        # è·å–æ¨¡å‹åç§°
                        model_name = "unknown"
                        try:
                            if 'user_model' in locals():
                                model_name = user_model
                            elif body:
                                request_data = json.loads(body.decode('utf-8'))
                                model_name = request_data.get('model', 'unknown')
                        except:
                            pass

                        # è®°å½•ç»Ÿè®¡æ•°æ®
                        stats_mgr.record_usage(
                            model=model_name,
                            usage_data=usage_data,
                            request_id=request_id
                        )
                except Exception as stats_error:
                    pass

            return JSONResponse(
                content=openai_response,
                status_code=upstream_resp.status_code,
                headers={"content-type": "application/json"}
            )
            
        except Exception as e:
            print(f"éæµå¼å“åº”è½¬æ¢å‡ºé”™: {e}", file=sys.stderr)
            error_response = {
                "error": {
                    "message": f"Response conversion failed: {str(e)}",
                    "type": "conversion_error"
                }
            }
            return JSONResponse(content=error_response, status_code=500)

    # 8. æµå¼å“åº”å¤„ç†ï¼ˆç”¨æˆ·è¦æ±‚æµå¼æˆ–éOpenAIå®¢æˆ·ç«¯ï¼‰  
    response_chunks = []
    is_stream_started = False
    
    async def stream_generator():
        nonlocal is_stream_started
        global codex_timeout_extra_seconds, codex_success_count
        connection_interrupted = False  # è¿æ¥ä¸­æ–­æ ‡å¿—
        line_buffer = ""  # ç¼“å†²åŒºç”¨äºå¤„ç†TCPåˆ†åŒ…çš„SSEæµ
        
        # Codexæµå¼è¯»å–æ€»è¶…æ—¶ï¼ˆåŸºç¡€è¶…æ—¶ + é¢å¤–è¶…æ—¶ç§’æ•°ï¼‰
        stream_total_timeout = None
        stream_start_time = None
        stream_aiter = None
        
        if is_codex_request:
            import time
            import asyncio
            codex_base_timeout = TimeoutConfig.get_codex_base_timeout()
            with codex_timeout_lock:
                current_extra_seconds = codex_timeout_extra_seconds
            stream_total_timeout = codex_base_timeout + current_extra_seconds
            stream_start_time = time.time()
            # è·å–å¼‚æ­¥è¿­ä»£å™¨
            stream_aiter = upstream_resp.aiter_raw().__aiter__()
        else:
            stream_aiter = upstream_resp.aiter_raw().__aiter__()
        
        try:
            while True:
                try:
                    # Codexè¯·æ±‚ä½¿ç”¨ç²¾ç¡®çš„asyncioè¶…æ—¶æ§åˆ¶
                    if is_codex_request:
                        # è®¡ç®—å‰©ä½™æ—¶é—´
                        elapsed = time.time() - stream_start_time
                        remaining = stream_total_timeout - elapsed
                        
                        if remaining <= 0:
                            # å·²ç»è¶…æ—¶
                            connection_interrupted = True
                            print(f"\n[Codexæµå¼è¶…æ—¶] æ€»æ—¶é—´{elapsed:.1f}ç§’è¶…è¿‡{stream_total_timeout}ç§’", file=sys.stderr)
                            
                            # è®°å½•Codexæµå¼è¶…æ—¶é”™è¯¯
                            record_codex_error(codex_current_config_index, 503)
                            
                            codex_increment = TimeoutConfig.get_codex_timeout_increment()
                            with codex_timeout_lock:
                                codex_timeout_extra_seconds += codex_increment
                                codex_success_count = 0
                                new_timeout = codex_timeout_extra_seconds
                            codex_base_timeout = TimeoutConfig.get_codex_base_timeout()
                            print(f"[Codexè‡ªé€‚åº”è¶…æ—¶] ä¸‹æ¬¡æµå¼è¶…æ—¶å¢åŠ åˆ° {codex_base_timeout + new_timeout}ç§’", file=sys.stderr)
                            raise httpx.ReadTimeout(f"Codex stream total timeout: {elapsed:.1f}s > {stream_total_timeout}s")
                        
                        # ä½¿ç”¨asyncio.wait_forç²¾ç¡®æ§åˆ¶æ¯æ¬¡chunkç­‰å¾…çš„è¶…æ—¶
                        try:
                            chunk = await asyncio.wait_for(stream_aiter.__anext__(), timeout=remaining)
                        except asyncio.TimeoutError:
                            # asyncioè¶…æ—¶ï¼Œç²¾ç¡®åˆ°å‰©ä½™æ—¶é—´
                            elapsed = time.time() - stream_start_time
                            connection_interrupted = True
                            print(f"\n[Codexæµå¼è¶…æ—¶] æ€»æ—¶é—´{elapsed:.1f}ç§’è¾¾åˆ°{stream_total_timeout}ç§’é™åˆ¶ï¼ˆç²¾ç¡®æ£€æµ‹ï¼‰", file=sys.stderr)
                            
                            # è®°å½•Codexæµå¼ç²¾ç¡®è¶…æ—¶é”™è¯¯
                            record_codex_error(codex_current_config_index, 503)
                            
                            codex_increment = TimeoutConfig.get_codex_timeout_increment()
                            with codex_timeout_lock:
                                codex_timeout_extra_seconds += codex_increment
                                codex_success_count = 0
                                new_timeout = codex_timeout_extra_seconds
                            codex_base_timeout = TimeoutConfig.get_codex_base_timeout()
                            print(f"[Codexè‡ªé€‚åº”è¶…æ—¶] ä¸‹æ¬¡æµå¼è¶…æ—¶å¢åŠ åˆ° {codex_base_timeout + new_timeout}ç§’", file=sys.stderr)
                            raise httpx.ReadTimeout(f"Codex stream total timeout (precise): {elapsed:.1f}s >= {stream_total_timeout}s")
                    else:
                        # éCodexè¯·æ±‚ï¼Œæ­£å¸¸è¿­ä»£
                        chunk = await stream_aiter.__anext__()
                    
                except StopAsyncIteration:
                    # æµå¼è¯»å–æ­£å¸¸ç»“æŸ
                    break
                # ä¿å­˜å“åº”å—
                response_chunks.append(chunk)
                
                # ç¬¬ä¸€æ¬¡æ”¶åˆ°æ•°æ®æ—¶æ‰“å°å“åº”ä¿¡æ¯ï¼ˆç²¾ç®€ç‰ˆï¼‰
                if not is_stream_started:
                    is_stream_started = True
                    
                    # ã€é”™è¯¯æ£€æµ‹ã€‘ä½¿ç”¨å¢å¼ºçš„é”™è¯¯æ£€æµ‹åŠŸèƒ½
                    is_error, error_info, decompressed_content = detect_compressed_error(chunk)
                    
                    chunk_text = chunk.decode('utf-8', errors='ignore')
                    
                    # å¦‚æœæ£€æµ‹åˆ°é”™è¯¯ï¼Œä½¿ç”¨ç»Ÿä¸€é”™è¯¯å¤„ç†å‡½æ•°
                    if is_error and not is_codex_request:
                        handle_detected_error(request_id, error_info, decompressed_content, "æµå¼")
                    
                    response_info = f"å“åº”: {upstream_resp.status_code}"
                    if model_conversion_info:
                        response_info += f" | {model_conversion_info}"
                    response_info += " | "
                    print(response_info, end="")
                    if should_convert_to_openai:
                        print("Claude â†’ OpenAIæ ¼å¼ï¼ˆä½¿ç”¨ç¼“å†²åŒºå¤„ç†TCPåˆ†åŒ…ï¼‰")
                    else:
                        # æ ¹æ®è¯·æ±‚ç±»å‹æ˜¾ç¤ºå¯¹åº”çš„åŸå§‹æ ¼å¼
                        format_name = "CodexåŸå§‹æ ¼å¼" if is_codex_request else "ClaudeåŸå§‹æ ¼å¼"
                        print(format_name)
                    sys.stdout.flush()
                
                # å¤„ç†å“åº”æ•°æ®è½¬æ¢
                processed_chunk = chunk
                
                # åªæœ‰OpenAIå®¢æˆ·ç«¯æ‰è½¬æ¢å“åº”æ ¼å¼
                if should_convert_to_openai:
                    content_type = str(upstream_resp.headers.get("content-type", ""))
                    
                    if "text/event-stream" in content_type:
                        # æµå¼å“åº”è½¬æ¢ï¼ˆä½¿ç”¨ç¼“å†²åŒºå¤„ç†TCPåˆ†åŒ…ï¼‰
                        try:
                            chunk_text = chunk.decode('utf-8', errors='ignore')
                            line_buffer += chunk_text  # ç´¯ç§¯åˆ°ç¼“å†²åŒº
                            
                            converted_lines = []
                            
                            # å¤„ç†ç¼“å†²åŒºä¸­çš„å®Œæ•´è¡Œ
                            while '\n' in line_buffer:
                                line, line_buffer = line_buffer.split('\n', 1)
                                line = line.strip()
                                
                                if not line:
                                    continue
                                    
                                if line.startswith('data: ') and line != 'data: [DONE]':
                                    try:
                                        json_str = line[6:]  # ç§»é™¤ 'data: '
                                        claude_data = json.loads(json_str)
                                        openai_data = convert_response_to_openai(claude_data)
                                        converted_lines.append(f'data: {json.dumps(openai_data, separators=(",", ":"))}')
                                        
                                        # OpenAIå“åº”æ•°æ®æ”¶é›†åŠŸèƒ½å·²åˆ é™¤
                                        
                                    except json.JSONDecodeError as e:
                                        # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸å®Œæ•´çš„JSONï¼ˆè€Œéæ ¼å¼é”™è¯¯ï¼‰
                                        json_str_stripped = json_str.rstrip()
                                        # å¦‚æœçœ‹èµ·æ¥åƒå®Œæ•´JSONï¼ˆä»¥}ç»“å°¾ï¼‰ä½†ä»è§£æå¤±è´¥ï¼Œå¯èƒ½æ˜¯æ ¼å¼é”™è¯¯
                                        if json_str_stripped.endswith('}') or json_str_stripped.endswith(']'):
                                            print(f"JSONæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡æ­¤è¡Œ: {e}, å†…å®¹: {line[:100]}", file=sys.stderr)
                                            continue  # è·³è¿‡è¿™ä¸ªé”™è¯¯è¡Œ
                                        else:
                                            # å¯èƒ½æ˜¯ä¸å®Œæ•´çš„JSONï¼Œæ”¾å›ç¼“å†²åŒºç­‰å¾…æ›´å¤šæ•°æ®
                                            line_buffer = line + '\n' + line_buffer
                                            break
                                elif line == 'data: [DONE]':
                                    converted_lines.append('data: [DONE]')
                                elif line.startswith('event:'):
                                    # è¿‡æ»¤æ‰Claudeç‰¹æœ‰çš„äº‹ä»¶ç±»å‹ï¼Œåªä¿ç•™å…¼å®¹OpenAIçš„
                                    continue
                                else:
                                    if line:  # åªæ·»åŠ éç©ºè¡Œ
                                        converted_lines.append(line)
                            
                            # åªæœ‰å½“æœ‰å®Œæ•´çš„è½¬æ¢è¡Œæ—¶æ‰è¾“å‡º
                            if converted_lines:
                                processed_chunk = ('\n'.join(converted_lines) + '\n').encode('utf-8')
                            else:
                                # å¦‚æœæ²¡æœ‰å®Œæ•´çš„è¡Œï¼Œæš‚æ—¶ä¸è¾“å‡ºï¼Œç­‰å¾…æ›´å¤šæ•°æ®
                                continue
                                
                        except Exception as convert_error:
                            # è½¬æ¢å‡ºé”™æ—¶è¯¦ç»†æ‰“å°ï¼Œä½†åœæ­¢è½¬æ¢ä»¥é¿å…æ ¼å¼æ··ä¹±
                            import traceback
                            print(f"\næµå¼å“åº”è½¬æ¢å‡ºé”™: {convert_error}", file=sys.stderr)
                            print(f"è½¬æ¢é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}", file=sys.stderr)
                            # åˆ é™¤åŸå§‹chunkå†…å®¹è®°å½•
                            # å¦‚æœæ˜¯OpenAIå®¢æˆ·ç«¯ä½†è½¬æ¢å¤±è´¥ï¼Œå‘é€é”™è¯¯å“åº”åé€€å‡º
                            if should_convert_to_openai:
                                error_chunk = 'data: {"error": {"message": "Response conversion failed", "type": "conversion_error"}}\n\ndata: [DONE]\n'
                                yield error_chunk.encode('utf-8')
                                return
                            processed_chunk = chunk  # éOpenAIå®¢æˆ·ç«¯ä½¿ç”¨åŸå§‹å—
                    else:
                        # éæµå¼å“åº”è½¬æ¢ï¼ˆJSONå“åº”ï¼‰
                        try:
                            chunk_text = chunk.decode('utf-8', errors='ignore')
                            if chunk_text.strip():
                                claude_data = json.loads(chunk_text)
                                openai_data = convert_response_to_openai(claude_data)
                                processed_chunk = json.dumps(openai_data, separators=(",", ":"), ensure_ascii=False).encode('utf-8')
                                
                                # éæµå¼å“åº”è½¬æ¢è®°å½•åŠŸèƒ½å·²åˆ é™¤
                                
                        except json.JSONDecodeError:
                            # ä¸æ˜¯å®Œæ•´çš„JSONï¼Œå¯èƒ½æ˜¯åˆ†å—ä¼ è¾“ï¼Œä¿æŒåŸæ ·
                            pass
                        except Exception as convert_error:
                            # è½¬æ¢å‡ºé”™æ—¶è¯¦ç»†æ‰“å°ï¼Œä½†åœæ­¢è½¬æ¢ä»¥é¿å…æ ¼å¼æ··ä¹±
                            import traceback
                            print(f"\nJSONå“åº”è½¬æ¢å‡ºé”™: {convert_error}", file=sys.stderr)
                            print(f"è½¬æ¢é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}", file=sys.stderr)
                            # åˆ é™¤åŸå§‹chunkå†…å®¹è®°å½•
                            # å¦‚æœæ˜¯OpenAIå®¢æˆ·ç«¯ä½†è½¬æ¢å¤±è´¥ï¼Œè¿”å›é”™è¯¯JSON
                            if should_convert_to_openai:
                                error_response = {
                                    "error": {
                                        "message": "Response conversion failed",
                                        "type": "conversion_error"
                                    }
                                }
                                processed_chunk = json.dumps(error_response, separators=(",", ":")).encode('utf-8')
                            else:
                                processed_chunk = chunk
                
                # ç²¾ç®€çš„æ•°æ®å—æ˜¾ç¤ºï¼ˆç§»é™¤è¯¦ç»†æ‰“å°ï¼‰
                # åªåœ¨è°ƒè¯•æ—¶éœ€è¦æ—¶æ‰æ‰“å°å…·ä½“å†…å®¹
                
                try:
                    yield processed_chunk  # è¿”å›å¤„ç†åçš„æ•°æ®å—
                except (ConnectionResetError, BrokenPipeError, ConnectionAbortedError) as conn_error:
                    # å®¢æˆ·ç«¯æ–­å¼€è¿æ¥ï¼Œæ­£å¸¸é€€å‡º
                    print(f"\nå®¢æˆ·ç«¯æ–­å¼€è¿æ¥: {conn_error}", file=sys.stderr)
                    return
            
            # async forå¾ªç¯ç»“æŸï¼Œå¤„ç†ç¼“å†²åŒºä¸­å‰©ä½™çš„æ•°æ®
            if should_convert_to_openai and line_buffer.strip():
                try:
                    remaining_lines = line_buffer.strip().split('\n')
                    converted_lines = []
                    
                    for line in remaining_lines:
                        line = line.strip()
                        if not line:
                            continue
                            
                        if line.startswith('data: ') and line != 'data: [DONE]':
                            try:
                                json_str = line[6:]
                                claude_data = json.loads(json_str)
                                openai_data = convert_response_to_openai(claude_data)
                                converted_lines.append(f'data: {json.dumps(openai_data, separators=(",", ":"))}')
                            except json.JSONDecodeError:
                                print(f"ç¼“å†²åŒºå‰©ä½™æ•°æ®æ— æ³•è§£æ: {line[:100]}", file=sys.stderr)
                        elif line == 'data: [DONE]':
                            converted_lines.append('data: [DONE]')
                        elif not line.startswith('event:'):
                            if line:
                                converted_lines.append(line)
                    
                    if converted_lines:
                        final_chunk = ('\n'.join(converted_lines) + '\n').encode('utf-8')
                        yield final_chunk
                except Exception as e:
                    print(f"å¤„ç†å‰©ä½™ç¼“å†²åŒºæ•°æ®æ—¶å‡ºé”™: {e}", file=sys.stderr)
                    
        except Exception as e:
            import traceback
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ReadTimeoutå¼‚å¸¸ï¼Œç›´æ¥è½¬æ¢ä¸ºè¿æ¥é”™è¯¯
            if isinstance(e, httpx.ReadTimeout):
                connection_interrupted = True
                error_msg = str(e)
                print(f"\næµå¤„ç†è¶…æ—¶: {e}", file=sys.stderr)
                
                # Codexè¯·æ±‚è¶…æ—¶æ—¶ï¼Œå¢åŠ è¶…æ—¶æ—¶é—´ï¼ˆä½†å¦‚æœæ˜¯æµå¼æ€»è¶…æ—¶ï¼Œå·²ç»åœ¨ä¸Šé¢å¤„ç†è¿‡äº†ï¼‰
                if is_codex_request and "Codex stream total timeout" not in error_msg:
                    # è¿™æ˜¯httpxåŸç”Ÿçš„ReadTimeoutï¼ˆæ¯æ¬¡è¯»å–è¶…æ—¶ï¼‰ï¼Œä¸æ˜¯æµå¼æ€»è¶…æ—¶
                    
                    # è®°å½•Codexè¯»å–è¶…æ—¶é”™è¯¯
                    record_codex_error(codex_current_config_index, 503)
                    
                    codex_increment = TimeoutConfig.get_codex_timeout_increment()
                    with codex_timeout_lock:
                        codex_timeout_extra_seconds += codex_increment
                        codex_success_count = 0  # é‡ç½®æˆåŠŸè®¡æ•°
                        new_timeout = codex_timeout_extra_seconds
                    codex_base_timeout = TimeoutConfig.get_codex_base_timeout()
                    print(f"[Codexè‡ªé€‚åº”è¶…æ—¶] è¶…æ—¶å¤±è´¥ï¼Œä¸‹æ¬¡è¶…æ—¶å¢åŠ åˆ° {codex_base_timeout + new_timeout}ç§’", file=sys.stderr)
                
                # æŠ›å‡ºç‰¹æ®Šå¼‚å¸¸ç”¨äºå¤–å±‚é‡è¯•æ£€æµ‹
                raise ConnectionError(f"Stream read timeout: {e}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è¿æ¥ä¸­æ–­ç›¸å…³çš„é”™è¯¯
            error_str = str(e).lower()
            connection_errors = [
                'peer closed connection',
                'incomplete chunked read',
                'remoteprotocolerror',
                'connection reset',
                'broken pipe',
                'connection aborted'
            ]
            
            is_connection_error = any(err in error_str for err in connection_errors)
            if is_connection_error:
                connection_interrupted = True
                print(f"\næµå¤„ç†è¿æ¥ä¸­æ–­: {e}", file=sys.stderr)
                # æŠ›å‡ºç‰¹æ®Šå¼‚å¸¸ç”¨äºå¤–å±‚é‡è¯•æ£€æµ‹
                raise ConnectionError(f"Stream connection interrupted: {e}")
            else:
                print(f"\næµå¤„ç†å¼‚å¸¸: {e}", file=sys.stderr)
                print(f"å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}", file=sys.stderr)
                print(f"å·²å¤„ç†çš„å“åº”å—æ•°é‡: {len(response_chunks)}", file=sys.stderr)
                if upstream_resp:
                    print(f"ä¸Šæ¸¸å“åº”çŠ¶æ€: {upstream_resp.status_code}", file=sys.stderr)
                    print(f"ä¸Šæ¸¸å“åº”å¤´: {dict(upstream_resp.headers)}", file=sys.stderr)
        finally:
            # Codexè¯·æ±‚æˆåŠŸæ—¶ï¼Œå¢åŠ æˆåŠŸè®¡æ•°ï¼ˆåªæœ‰åœ¨æœ‰é¢å¤–è¶…æ—¶æ—¶æ‰éœ€è¦è®¡æ•°å’Œé‡ç½®ï¼‰
            if is_codex_request and not connection_interrupted:
                with codex_timeout_lock:
                    if codex_timeout_extra_seconds > 0:
                        codex_success_count += 1
                        current_count = codex_success_count
                        print(f"\n[Codexè‡ªé€‚åº”è¶…æ—¶] è¯·æ±‚æˆåŠŸ (è¿ç»­{current_count}/3æ¬¡)", file=sys.stderr)
                        
                        # è¿ç»­3æ¬¡æˆåŠŸï¼Œé‡ç½®è¶…æ—¶
                        if codex_success_count >= 3:
                            print(f"[Codexè‡ªé€‚åº”è¶…æ—¶] è¿ç»­3æ¬¡æˆåŠŸï¼Œé‡ç½®è¶…æ—¶è‡³é»˜è®¤ 60ç§’", file=sys.stderr)
                            codex_timeout_extra_seconds = 0
                            codex_success_count = 0
            
            # ç¡®ä¿å…³é—­retry_clientï¼Œé¿å…clientçŠ¶æ€ç´¯ç§¯
            if 'retry_client' in locals():
                try:
                    await retry_client.aclose()
                except Exception as close_error:
                    print(f"å…³é—­retry_clientæ—¶å‡ºé”™: {close_error}", file=sys.stderr)
            
            # ç®€åŒ–çš„å®Œæˆè®°å½•
            if ENABLE_FULL_LOG and full_logger:
                try:
                    full_logger.info(f"è¯·æ±‚ID: {request_id} - å¤„ç†å®Œæˆ")
                    full_logger.info("="*40)
                    trim_log_file(LOG_FILE_PATH)
                except Exception as log_error:
                    print(f"è®°å½•å®Œæˆæ—¥å¿—æ—¶å‡ºé”™: {log_error}", file=sys.stderr)
            
            # è®°å½•å®Œæ•´è¾“å‡ºæ•°æ®
            log_original_response(request_id, response_chunks, is_codex_request)

            # âœ… å®æ—¶ç»Ÿè®¡tokenä½¿ç”¨é‡
            if stats_mgr and response_chunks:
                try:
                    usage_data = extract_usage_from_chunks(response_chunks, is_codex_request)
                    if usage_data:
                        # è·å–æ¨¡å‹åç§°
                        model_name = "unknown"
                        try:
                            if 'user_model' in locals():
                                model_name = user_model
                            elif body:
                                request_data = json.loads(body.decode('utf-8'))
                                model_name = request_data.get('model', 'unknown')
                        except:
                            pass

                        # è®°å½•ç»Ÿè®¡æ•°æ®
                        stats_mgr.record_usage(
                            model=model_name,
                            usage_data=usage_data,
                            request_id=request_id
                        )
                except Exception as stats_error:
                    pass

            # OpenAIå“åº”æ—¥å¿—åŠŸèƒ½å·²åˆ é™¤
            
            # ç²¾ç®€çš„å®Œæˆä¿¡æ¯ - è¿æ¥ä¸­æ–­æ—¶ä¸è¾“å‡ºå®Œæˆä¿¡æ¯
            if response_chunks and not connection_interrupted:
                completion_info = " âœ“ å®Œæˆ"
                if model_conversion_info:
                    completion_info = f" âœ“ å®Œæˆ [{model_conversion_info}]"
                # æ·»åŠ Codexè¯·æ±‚çš„å®é™…ç”¨æ—¶
                if is_codex_request and 'stream_start_time' in locals():
                    actual_elapsed = time.time() - stream_start_time
                    completion_info += f" (è€—æ—¶: {actual_elapsed:.1f}ç§’)"
                print(completion_info)
                print("=" * 50)  # ç»“æŸåˆ†éš”çº¿
            elif connection_interrupted:
                print(f"\nâŒ è¿æ¥ä¸­æ–­ - æµå¤„ç†æœªå®Œæˆ (å·²å¤„ç† {len(response_chunks)} ä¸ªå“åº”å—)", file=sys.stderr)
                print("=" * 50)  # ç»“æŸåˆ†éš”çº¿
            # ç¡®ä¿ä¸Šæ¸¸è¿æ¥æ­£ç¡®å…³é—­
            try:
                await upstream_resp.aclose()
            except Exception as close_error:
                print(f"å…³é—­ä¸Šæ¸¸è¿æ¥æ—¶å‡ºé”™: {close_error}", file=sys.stderr)

    # -------------------------------------------------------------------
    # æ ¸å¿ƒä¿®æ”¹ç‚¹: å¤„ç†å“åº”å¤´ï¼Œç‰¹åˆ«æ˜¯Content-Length
    # -------------------------------------------------------------------
    
    # æ·»åŠ æµå¤„ç†é‡è¯•æœºåˆ¶
    max_stream_retries = 1  # ç¦ç”¨æµé‡è¯•ï¼Œé¿å…é‡å¤å‘é€ï¼ˆä¸»é‡è¯•é€»è¾‘å·²è¶³å¤Ÿï¼‰
    for stream_retry_count in range(max_stream_retries):
        try:
            response_headers = dict(upstream_resp.headers)
            
            # å¦‚æœè¿›è¡Œäº†OpenAIæ ¼å¼è½¬æ¢ï¼Œéœ€è¦ç§»é™¤Content-Lengthè®©FastAPIè‡ªåŠ¨å¤„ç†
            if should_convert_to_openai and "content-length" in response_headers:
                del response_headers["content-length"]  # è®©FastAPIè‡ªåŠ¨å¤„ç†Content-Length

            return StreamingResponse(
                content=stream_generator(),
                status_code=upstream_resp.status_code,
                headers=response_headers,
                media_type=upstream_resp.headers.get("content-type")
            )
            
        except ConnectionError as ce:
            print(f"[æµé‡è¯• {stream_retry_count + 1}/{max_stream_retries}][{request_id}] æ£€æµ‹åˆ°è¿æ¥ä¸­æ–­: {ce}", file=sys.stderr)
            
            if stream_retry_count < max_stream_retries - 1:
                # è¿˜æœ‰é‡è¯•æœºä¼šï¼Œé‡æ–°å‘èµ·è¯·æ±‚
                try:
                    await upstream_resp.aclose()  # å…³é—­å½“å‰è¿æ¥
                    
                    # é‡æ–°å‘èµ·è¯·æ±‚ï¼ˆä½¿ç”¨å…¨æ–°headersï¼Œå¼ºåˆ¶æ–­å¼€æ—§è¿æ¥ï¼‰
                    # æ ¹æ®è¯·æ±‚ç±»å‹é€‰æ‹©åˆé€‚çš„è¶…æ—¶é…ç½®
                    if is_codex_request:
                        # Codexæµé‡è¯•ï¼šç¦ç”¨readè¶…æ—¶ï¼Œç”±æµå¼æ€»è¶…æ—¶æ§åˆ¶
                        codex_timeout = httpx.Timeout(
                            connect=TimeoutConfig.get_connect_timeout(),
                            read=None,  # âœ… ç¦ç”¨readè¶…æ—¶ï¼Œç”±æµå¼æ€»è¶…æ—¶æ§åˆ¶
                            write=TimeoutConfig.get_write_timeout(),
                            pool=TimeoutConfig.get_pool_timeout()
                        )
                        new_client = httpx.AsyncClient(timeout=codex_timeout, limits=limits)
                        codex_base_timeout = TimeoutConfig.get_codex_base_timeout()
                        with codex_timeout_lock:
                            current_extra_seconds = codex_timeout_extra_seconds
                        print(f"[æµé‡è¯•][Codexè¶…æ—¶é…ç½®] è¿æ¥è¶…æ—¶: {TimeoutConfig.get_codex_connect_timeout()}ç§’ | æµå¼æ€»è¶…æ—¶: {codex_base_timeout + current_extra_seconds}ç§’", file=sys.stderr)
                    elif should_convert_to_openai and not user_wants_stream:
                        # éæµå¼è¯·æ±‚ä½¿ç”¨60ç§’è¶…æ—¶
                        new_client = httpx.AsyncClient(timeout=non_streaming_timeout, limits=limits)
                    else:
                        # æµå¼è¯·æ±‚ä½¿ç”¨æ ‡å‡†è¶…æ—¶
                        new_client = httpx.AsyncClient(timeout=timeout, limits=limits)
                    try:
                        # æµé‡è¯•ä¹Ÿè¦ä½¿ç”¨å…¨æ–°headerså‰¯æœ¬ï¼Œé¿å…è¿æ¥å¤ç”¨
                        stream_retry_headers = headers.copy()
                        if TimeoutConfig.get_modify_retry_headers():
                            stream_retry_headers['connection'] = 'close'
                            # æ·»åŠ å®Œæ•´çš„é˜²ç¼“å­˜å¤´éƒ¨ï¼Œç¡®ä¿æµé‡è¯•æ—¶APIä¸ä½¿ç”¨ç¼“å­˜
                            import time
                            stream_retry_rand = random.randint(1000,9999)
                            stream_retry_timestamp = int(time.time() * 1000)
                            stream_retry_headers['x-request-id'] = f"{request_id}-stream-retry{stream_retry_count}-{stream_retry_rand}"
                            stream_retry_headers['cache-control'] = 'no-cache, no-store, must-revalidate'
                            stream_retry_headers['pragma'] = 'no-cache'
                            stream_retry_headers['expires'] = '0'
                            stream_retry_headers['x-cache-bypass'] = f'{stream_retry_timestamp}-{stream_retry_rand}'
                            stream_retry_headers['x-retry-count'] = str(stream_retry_count + 1)
                        
                        new_upstream_req = new_client.build_request(
                            method=request.method,
                            url=upstream_url,
                            headers=stream_retry_headers,  # ä½¿ç”¨æµé‡è¯•ä¸“ç”¨headers
                            content=converted_body
                        )
                        
                        # Codexæµé‡è¯•ä¹Ÿä½¿ç”¨30ç§’è¿æ¥è¶…æ—¶
                        if is_codex_request:
                            import asyncio
                            try:
                                upstream_resp = await asyncio.wait_for(
                                    new_client.send(new_upstream_req, stream=True),
                                    timeout=TimeoutConfig.get_codex_connect_timeout()
                                )
                            except asyncio.TimeoutError:
                                print(f"[Codexæµé‡è¯•è¿æ¥è¶…æ—¶][{request_id}] {TimeoutConfig.get_codex_connect_timeout()}ç§’å†…æœªæ”¶åˆ°å“åº”", file=sys.stderr)
                                
                                # è®°å½•Codexæµé‡è¯•è¿æ¥è¶…æ—¶é”™è¯¯
                                record_codex_error(codex_current_config_index, 503)
                                
                                await new_client.aclose()
                                raise httpx.ReadTimeout("Codex stream retry connection timeout: 30 seconds")
                        else:
                            upstream_resp = await new_client.send(new_upstream_req, stream=True)
                        
                        print(f"[æµé‡è¯• {stream_retry_count + 1}/{max_stream_retries}][{request_id}] é‡æ–°å»ºç«‹è¿æ¥æˆåŠŸ", file=sys.stderr)
                        
                        # é‡ç½®æµå¤„ç†ç›¸å…³å˜é‡
                        response_chunks = []
                        is_stream_started = False
                        
                        # ç­‰å¾…é…ç½®çš„æ—¶é—´åé‡è¯•
                        import asyncio
                        await asyncio.sleep(TimeoutConfig.get_stream_retry_wait())
                        continue
                    finally:
                        # ç¡®ä¿å…³é—­new_clientè¿æ¥
                        await new_client.aclose()
                    
                except Exception as retry_error:
                    print(f"[æµé‡è¯• {stream_retry_count + 1}/{max_stream_retries}][{request_id}] é‡è¿å¤±è´¥: {retry_error}", file=sys.stderr)
                    continue
            
            # æœ€åä¸€æ¬¡é‡è¯•å¤±è´¥ï¼Œè¿”å›é”™è¯¯å“åº”
            from fastapi.responses import Response
            return Response(content=f"Stream processing failed after {max_stream_retries} retries: {ce}", status_code=502)

if __name__ == "__main__":
    import uvicorn
    import logging
    
    # é…ç½®æ—¥å¿—çº§åˆ«ï¼Œå‡å°‘ä¸å¿…è¦çš„è¾“å‡º
    logging.getLogger("uvicorn").setLevel(logging.WARNING)
    logging.getLogger("uvicorn.access").setLevel(logging.WARNING)
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("httpcore").setLevel(logging.WARNING)
    
    # æ˜¾ç¤ºå½“å‰APIé…ç½®çŠ¶æ€
    print("\n" + "=" * 60)
    print("Claude Code API Server Startup")
    print("=" * 60)
    print("APIè½®åŠ¨é…ç½®:")
    
    # æ˜¾ç¤ºæŒ‰ä¼˜å…ˆçº§æ’åºçš„ä¸»API
    primary_apis = [cfg for cfg in API_CONFIGS if cfg.get('type', 'primary') == 'primary']
    if primary_apis:
        print("  ä¸»APIï¼ˆæŒ‰é…ç½®ä¼˜å…ˆçº§é¡ºåºï¼‰:")
        for rank, config in enumerate(primary_apis, start=1):
            print(f"    ä¼˜å…ˆçº§#{rank}: {config['name']} | {config['base_url']}")
            print(f"      Key: {config['key'][:20]}...")

    # æ˜¾ç¤ºå¤‡ç”¨APIï¼ˆtype=backupï¼‰
    backup_apis = [cfg for cfg in API_CONFIGS if cfg.get('type') == 'backup']
    if backup_apis:
        print("  å¤‡ç”¨APIï¼ˆå…¨å‘¨å¯ç”¨ï¼‰:")
        for config in backup_apis:
            print(f"    {config['name']}: {config['base_url']}")
            print(f"      Key: {config['key'][:20]}...")

    print("è½®åŠ¨è¯´æ˜: ä¸»APIæŒ‰é…ç½®é¡ºåºè‡ªåŠ¨é€‰ç”¨ï¼Œä¸»APIä¸å¯ç”¨æ—¶é¡ºå»¶ä¸‹ä¸€ä¼˜å…ˆçº§")
    print("æ¢å¤è¯´æ˜: ä¸»APIæ¢å¤åè‡ªåŠ¨åˆ‡å›ï¼Œé…åˆé”™è¯¯è®¡æ•°å’Œå†·å´ç›‘æ§")
    print("æ”¯æŒæ ¼å¼: OpenAIæ ¼å¼è‡ªåŠ¨è½¬æ¢ä¸ºClaudeæ ¼å¼")
    print(f"æ—¥å¿—åŠŸèƒ½: å·²å¯ç”¨APIè¾“å…¥è¾“å‡ºæ—¥å¿—ï¼Œæœ€å¤§{MAX_LOG_SIZE/1024/1024:.0f}MB")
    # print("ğŸ”„ æ–°åŠŸèƒ½: å¯åŠ¨æ—¶APIå¥åº·æ£€æŸ¥ï¼Œ4/5/6/9/10/11ç‚¹å®šæ—¶å¥åº·æ£€æŸ¥ï¼ˆä½¿ç”¨OpenAIâ†’Claudeæ ¼å¼ï¼Œclaude-sonnet-4-5-20250929æ¨¡å‹ï¼‰")  # ã€å·²æ³¨é‡Šã€‘å¥åº·æ£€æŸ¥åŠŸèƒ½
    print("é”™è¯¯æ£€æµ‹: å¢å¼ºé”™è¯¯æ£€æµ‹ï¼Œå³ä½¿200çŠ¶æ€ä¹Ÿæ£€æŸ¥å“åº”å†…å®¹ï¼Œæ”¯æŒå‹ç¼©é”™è¯¯è§£æ")
    print("ç«¯å£: 5101")
    print("=" * 60 + "\n")
    
    # ç¡®ä¿ä¾èµ–å·²å®‰è£…: pip install "fastapi[all]" httpx
    # ä½¿ç”¨ç«¯å£5101ï¼Œç¦ç”¨access log
    uvicorn.run(app, host="0.0.0.0", port=5101, access_log=False, log_level="warning")

















